@article{Pearson1895,
abstract = {In statistics, the Pearson product-moment correlation coefficient (/ˈpɪərsɨn/) (sometimes referred to as the PPMCC or PCC or Pearson's r) is a measure of the linear correlation (dependence) between two variables X and Y. It was developed by Karl Pearson from a related idea introduced by Francis Galton in the 1880s},
annote = {Detta {\"{a}}r visserligen den artikel som gett upphov till Pearsons korrelationscoefficient men h{\"{a}}rifr{\aa}n h{\"{a}}nvisas till Galtons formel s{\aa} egentligen var det inte helt nytt.

V{\"{a}}ldigt kort note som egentligen {\"{a}}r del av l{\"{a}}ngre paper som inte han f{\"{a}}rdigst{\"{a}}llas pga h{\"{a}}lsoproblem.},
author = {Pearson, Karl},
doi = {10.1098/rspl.1895.0041},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pearson - 1895 - Note on Regression and Inheritance in the Case of Two Parents.pdf:pdf},
isbn = {0370-1662},
issn = {0370-1662},
journal = {Proceedings of the Royal Society of London (1854-1905)},
keywords = {article1},
mendeley-tags = {article1},
pages = {240--242},
title = {{Note on Regression and Inheritance in the Case of Two Parents}},
volume = {58},
year = {1895}
}
@article{Pearson1896,
annote = {http://www.amstat.org/publications/jse/v9n3/stanton.html

Tycks mena att detta {\"{a}}r k{\"{a}}llan vari {\&}quot;r{\&}quot; anv{\"{a}}nders f{\"{o}}rsta g{\aa}ngen!?},
author = {Pearson, Karl},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pearson - 1896 - Mathematical Contributions to the Theory of Evolution. III. Regression, Heredity, and Panmixia.pdf:pdf},
journal = {Philosophical transactions of the royal society A},
keywords = {article1},
mendeley-tags = {article1},
title = {{Mathematical Contributions to the Theory of Evolution. III. Regression, Heredity, and Panmixia}},
volume = {187},
year = {1896}
}
@article{Student1908,
abstract = {His question was answered by Messrs Yule and Hooker and Professor Edgeworth, all of whom considered that Mr Hooker was probably safe in taking'HO as his limit of significance for a sample of 21. They did not, however, answer Dr Shaw's question in any more ...},
author = {Student},
file = {:C$\backslash$:/Users/eribu/Downloads/student1908.pdf:pdf},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {2-3},
pages = {302--310},
title = {{Probable Error of a Correlation Coefficient}},
url = {http://biomet.oxfordjournals.org/cgi/doi/10.1093/biomet/6.2-3.302 papers2://publication/doi/10.1093/biomet/6.2-3.302},
volume = {6},
year = {1908}
}
@article{Soper1913,
author = {Soper, H. E.},
doi = {10.1093/biomet/9.1-2.91},
file = {:C$\backslash$:/Users/eribu/Downloads/2331802.pdf:pdf},
issn = {00063444},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {1-2},
pages = {91--115},
title = {{On the peobable error of the correlation coefficient to a second approximation}},
volume = {9},
year = {1913}
}
@article{Fisher1915,
abstract = {508 Distribution of the Correlation Coeffeients of Samples In the second of these two papers the more difficult problem of the frequency distribution of the correlation coefficient is attempted. For samples of 2 the frequency},
author = {Fisher, R.a.},
doi = {10.2307/2331838},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fisher, Fisher - 1915 - Frequency distribution of the values of the correlation coefficient in samples from an indefinitely large popula.pdf:pdf},
isbn = {0006-3444},
issn = {00063444},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {507--521},
title = {{Frequency distribution of the values of the correlation coefficient in samples from an indefinitely large population}},
url = {http://biomet.oxfordjournals.org/cgi/reprint/10/4/507.pdf},
volume = {10},
year = {1915}
}
@article{Coop1916,
author = {{Soper, HE and Young, AW and Cave, BM and Lee, Alice and Pearson}, Karl},
file = {:C$\backslash$:/Users/eribu/Downloads/2331830.pdf:pdf},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {328--413},
title = {{On the Distribution of the Correlation Coefficient in Small Samples. Appendix II to the Papers of "Student" and R. A. Fisher}},
volume = {11},
year = {1916}
}
@misc{Fisher1921,
abstract = {This is the second of three papers dealing with the sampling errors of correlation coefficients covering the cases (i) "The frequency distribution of the values of the correlation coeffricient in samples from an indefinitely large population", Biometrika, 1915.},
author = {Fisher, R A},
booktitle = {Metron},
file = {:C$\backslash$:/Users/eribu/Downloads/14.pdf:pdf},
keywords = {article1},
mendeley-tags = {article1},
number = {1-32},
pages = {205--235},
title = {{On the probable error of a coefficient of correlation deduced from a small samlpe}},
volume = {1},
year = {1921}
}
@misc{Fisher1924,
abstract = {Reproduced with permission of Metron 35 THE DISTRIBUTION OF THE PARTIAL CORRELATION COEFFICIENT .1. The theoretical . distribution In ascertaining the exact distribution iu random samples to which the correlation coefficient between two normally distributed vari{\^{a}}tes is ...},
author = {Fisher, R a},
booktitle = {Metron},
file = {:C$\backslash$:/Users/eribu/Downloads/35.pdf:pdf},
keywords = {article1},
mendeley-tags = {article1},
number = {3-4},
pages = {329--332},
title = {{The distribution of the partial correlation coefficient}},
volume = {3},
year = {1924}
}
@article{Fisher1928,
author = {Fisher, R A},
file = {:C$\backslash$:/Users/eribu/Downloads/654.full.pdf:pdf},
journal = {Proceedings of the Royal Society of London A: Mathematical, Physical and Engineering Sciences},
keywords = {article1},
mendeley-tags = {article1},
month = {dec},
number = {788},
pages = {654--673},
title = {{The General Sampling Distribution of the Multiple Correlation Coefficient}},
url = {http://rspa.royalsocietypublishing.org/content/121/788/654.abstract},
volume = {121},
year = {1928}
}
@article{Ezekei1929,
author = {Ezekei, Mordecai},
file = {:C$\backslash$:/Users/eribu/Downloads/2277015.pdf:pdf},
isbn = {0521773628},
journal = {Journal of the American Statistical Association},
keywords = {article1},
mendeley-tags = {article1},
number = {165},
pages = {99--104},
title = {{The Application of the Theory of Error to Multiple and Curvilinear Correlation}},
volume = {24},
year = {1929}
}
@article{Larson1931,
abstract = {A study is made, on 800 cases, of the shrinkage attendant upon using a regression equation derived from one group to predict the criterion scores of a second group. It is found that "the theoretically expected shrinkage of R as derived by the multiple correlation formula is a fact." The shrinkage increases as the number of variables increases and as the size of R decreases. The Smith formula for shrinkage-deduction parallels the empirical findings, but consistently yields higher values. The results upon increase in number of test variables suggest that test batteries may have definite limitations in size. (PsycINFO Database Record (c) 2006 APA, all rights reserved). © 1931 American Psychological Association.},
author = {Larson, S C},
doi = {10.1037/h0072400},
file = {:C$\backslash$:/Users/eribu/Downloads/edu{\_}22{\_}1{\_}45.pdf.pdf:pdf},
issn = {00220663 (ISSN)},
journal = {Journal of Educational Psychology},
keywords = {BIOMETRY AND STATISTICS,CORRELATION, MULTIPLE, SHRINKAGE,MULTIPLE,SHRINKAGE,article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {1},
pages = {45--55},
title = {{The shrinkage of the coefficient of multiple correlation}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0007318509{\&}partnerID=40{\&}md5=dc19e2f8fac696f27cb88e10bc8d38fe},
volume = {22},
year = {1931}
}
@article{Wherry1931,
abstract = {44¿ hORMULA POR (6) ?*.< *>' » егог NM and since 2 , by (2) above, we have s0 equa we have {\^{}} (7) -г f N(lt?z) f i-p2 1 N equal to (1 - {\^{}} 2 ), which is, exactly, the BB Smith (1). This has been widely used during the last few},
author = {Wherry, R},
file = {:C$\backslash$:/Users/eribu/Downloads/2957681.pdf:pdf},
journal = {The annals of mathematical statistics},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {4},
pages = {440--457},
title = {{A new formula for predicting the shrinkage of the coefficient of multiple correlation}},
url = {http://www.jstor.org/stable/2957681$\backslash$npapers2://publication/uuid/F3D4916B-BB98-4094-A459-DF4387AC9610},
volume = {2},
year = {1931}
}
@article{Wishart1931,
author = {Wishart, Author J and Kondo, T and Elderton, E M},
file = {:C$\backslash$:/Users/eribu/Downloads/2332101.pdf:pdf},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {3/4},
pages = {353--376},
title = {{The Mean and Second Moment Coefficient of the Multiple Correlation Coefficient, in Samples from a Normal Population}},
volume = {22},
year = {1931}
}
@article{Nair1941,
author = {Nair, A N Krishnan},
file = {:C$\backslash$:/Users/eribu/Downloads/ref{\_}till{\_}coop1916/25047705.pdf:pdf},
journal = {The Indian Journal of Statistics},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {383--400},
title = {{Distribution of Students 't' and the Correlation Coefficient in Samples from Non-Normal Populations}},
volume = {5},
year = {1941}
}
@article{Gayen1951,
author = {Gayen, A. K.},
file = {:C$\backslash$:/Users/eribu/Downloads/2332329.pdf:pdf},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {1/2},
pages = {219--247},
title = {{The Frequency Distribution of the Product-Moment Correlation Coefficient in Random Samples of Any Size Drawn from Non-Normal Universes}},
volume = {38},
year = {1951}
}
@article{Cowden1952,
abstract = {Abstract A partial correlation coefficient which is also a multiple correlation coefficient is discussed. Its relationship with other well-known coefficients is explained. Computational methods for computing the estimating equation and the correlation coefficient are suggested. * The writer wishes to thank Professors Harold Hotelling, George E. Nicholson, and John H. Smith for critically reading the manuscript and offering valuable comments. Professor Hotelling indicated the method of computation which he had suggested in an unpublished paper (see note 5). Professor Smith called the writer's attention to some of the earlier references to the subject in the literature. Since the first draft of this paper was written (June, 1951), it has been learned that Professor C. Horace Hamilton, of the North Carolina State College of Agriculture and Engineering, has written an article entitled ?Population Pressure and Other Factors Affecting Net Rural-Urban Migration,? in which the coefficient of multiple-partial correlation is used. This article appears in Social Forces, 30 (December, 1951), pp. 209?15. The formula used is that attributed by the present writer to John H. Smith (see note 7.)$\backslash$nAbstract A partial correlation coefficient which is also a multiple correlation coefficient is discussed. Its relationship with other well-known coefficients is explained. Computational methods for computing the estimating equation and the correlation coefficient are suggested. * The writer wishes to thank Professors Harold Hotelling, George E. Nicholson, and John H. Smith for critically reading the manuscript and offering valuable comments. Professor Hotelling indicated the method of computation which he had suggested in an unpublished paper (see note 5). Professor Smith called the writer's attention to some of the earlier references to the subject in the literature. Since the first draft of this paper was written (June, 1951), it has been learned that Professor C. Horace Hamilton, of the North Carolina State College of Agriculture and Engineering, has written an article entitled ?Population Pressure and Other Factors Affecting Net Rural-Urban Migration,? in which the coefficient of multiple-partial correlation is used. This article appears in Social Forces, 30 (December, 1951), pp. 209?15. The formula used is that attributed by the present writer to John H. Smith (see note 7.)},
author = {Cowden, Dudley J.},
doi = {10.1080/01621459.1952.10501183},
file = {:C$\backslash$:/Users/eribu/Downloads/2281314.pdf:pdf},
isbn = {01621459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {259},
pages = {442--456},
title = {{The Multiple-Partial Correlation Coefficient}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1952.10501183},
volume = {47},
year = {1952}
}
@article{Hotelling1953,
author = {Hotelling, Harold},
file = {:C$\backslash$:/Users/eribu/Downloads/2983768.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series B (Methodological),},
keywords = {article1},
mendeley-tags = {article1},
number = {2},
pages = {296--193--232},
title = {{New Light on the Correlation Coefficient and its Transforms Author(s): Harold Hotelling}},
volume = {15},
year = {1953}
}
@article{Olkin1958,
abstract = {This paper deals with the unbiased estimation of the correlation of two variates having a bivariate normal distribution (Sec. 2), and of the intraclass correlation, i.e., the common correlation coefficient of a {\$}p{\$}-variate normal distribution with equal variances and equal covariances (Sec. 3). In both cases, the estimator has the following properties. It is a function of a complete sufficient statistic and is therefore the unique (except for sets of probability zero) minimum variance unbiased estimator. Its range is the region of possible values of the estimated quantity. It is a strictly increasing function of the usual estimator differing from it only by terms of order {\$}1/n{\$} and consequently having the same asymptotic distribution. Since the unbiased estimators are cumbersome in form in that they are expressed as series or integrals, tables are included giving the unbiased estimators as functions of the usual estimators. In Sec. 4 we give an unbiased estimator of the squared multiple correlation. It ha...},
author = {Olkin, Ingram and Pratt, J.W.},
doi = {10.2307/2237306},
file = {:C$\backslash$:/Users/eribu/Downloads/2237306.pdf:pdf},
issn = {00034851},
journal = {The annals of mathematical statistics},
keywords = {article1},
mendeley-tags = {article1},
number = {1},
pages = {201--211},
title = {{Unbiased estimation of certain correlation coefficients}},
url = {http://www.jstor.org/pss/2237306$\backslash$nhttp://www.jstor.org/stable/10.2307/2237306},
volume = {29},
year = {1958}
}
@article{Seber1963,
author = {Seber, G A F},
file = {:C$\backslash$:/Users/eribu/Downloads/Seber1963.pdf:pdf},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {3},
pages = {542--544},
title = {{The Non-Central Chi-Squared and Beta Distributions}},
volume = {50},
year = {1963}
}
@article{Kramer1963,
abstract = {The purpose of this paper is to present tables for the construction of confidence limits on the multiple correlation coefficient when sampling from a k-variate normal population. Ezekiel and Fox [3, pp. 296-8] prepared charts which serve this purpose when k is eight or less. The tables in this paper are for cases involving values of k that are larger than eight. Some brief historical comment is also given, and (in the next to the last paragraph) an illustration of the use of the tables.},
author = {Kramer, K H},
doi = {10.2307/2283334},
file = {:C$\backslash$:/Users/eribu/Downloads/2283334.pdf:pdf},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {article1},
mendeley-tags = {article1},
number = {304},
pages = {1082--1085},
publisher = {[American Statistical Association, Taylor {\&} Francis, Ltd.]},
title = {{Tables for Constructing Confidence Limits on the Multiple Correlation Coefficient}},
url = {http://www.jstor.org/stable/2283334},
volume = {58},
year = {1963}
}
@article{Park1964,
author = {Park, John H Jr},
file = {:C$\backslash$:/Users/eribu/Downloads/2238295.pdf:pdf},
journal = {The Annals of Mathematical Statistics},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {1583--1593},
title = {{Variations of the Non-central t and Beta Distributions}},
volume = {35},
year = {1964}
}
@article{Ruben1966,
author = {Ruben, Harold},
file = {:C$\backslash$:/Users/eribu/Downloads/2984445.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series B (Methodological),},
keywords = {article1},
mendeley-tags = {article1},
number = {3},
pages = {513--525},
title = {{Some New Results on the Coefficient of the Sample Correlation Distribution}},
volume = {28},
year = {1966}
}
@article{Hogben1968,
author = {Hogben, David},
doi = {10.6028/jres.072B.007},
file = {:C$\backslash$:/Users/eribu/Downloads/jresv72Bn1p33{\_}A1b.pdf:pdf},
issn = {0098-8979},
journal = {Journal of Research of the National Bureau of Standards, Section B: Mathematical Sciences},
keywords = {anal ysis of variance,article1,calibrali on,co rrelation coeffi cie,degrees of free dom,di s-,e,fix ed vari abl,nonce ntral beta variabl,noncentrality,nt,q variate,tribution},
mendeley-tags = {article1},
number = {1},
pages = {33},
title = {{The distribution of the sample correlation coefficient with one variable fixed}},
volume = {72B},
year = {1968}
}
@article{Kymn1968,
author = {Kymn, Kern O .},
file = {:C$\backslash$:/Users/eribu/Downloads/1909612.pdf:pdf},
journal = {Econometrica},
keywords = {article1},
mendeley-tags = {article1},
number = {1},
pages = {187--189},
title = {{The Distribution of the Sample Correlation Coefficient Under the Null Hypothesis}},
volume = {36},
year = {1968}
}
@article{Warren1971,
abstract = {A quantitative study is made of the bias in the usual estimate of the linear correlation coefficient and of the relative efficiency of the estimated regression, when a certain type of selective sampling is employed. A good compromise seems difficult to obtain and it is the author's thesis that the simultaneous presentation of regression equations and correlation coefficients is, in a sense, contradictory.},
author = {Warren, W. G.},
doi = {10.2307/2346463},
file = {:C$\backslash$:/Users/eribu/Downloads/2346463.pdf:pdf},
issn = {00359254},
journal = {Applied Statistics},
keywords = {article1},
mendeley-tags = {article1},
number = {2},
pages = {148},
title = {{Correlation or Regression: Bias or Precision}},
url = {http://www.jstor.org/stable/2346463$\backslash$nhttp://www.jstor.org/stable/10.2307/2346463?origin=crossref},
volume = {20},
year = {1971}
}
@article{Kowalski1972,
abstract = {Samples from non-normal bivariate distributions are simulated and the densities of the sample product-moment correlation coefficient, r, estimated and compared with the corresponding normal theory densities. The results are contrasted with the literature on the subject and an attempt is made to reconcile some of the earlier conflicting conclusions regarding the robustness of the distribution of r.},
author = {Kowalski, Charles J.},
doi = {10.2307/2346598},
file = {:C$\backslash$:/Users/eribu/Downloads/2346598.pdf:pdf},
issn = {00359254},
journal = {Journal of the Royal Statistical Society},
keywords = {article1,density estimation,distribution of correlation coefficient,non-normality,robustness,transformations},
mendeley-tags = {article1},
number = {1},
pages = {1--12},
title = {{On the Effects of Non-Normality on the Distribution of the Sample Product-Moment Correlation Coefficient}},
url = {http://www.jstor.org/stable/10.2307/2346598?origin=crossref},
volume = {21},
year = {1972}
}
@article{Crocker1972,
annote = {doi: 10.1080/00031305.1972.10477345},
author = {Crocker, Douglas C},
doi = {10.1080/00031305.1972.10477345},
file = {:C$\backslash$:/Users/eribu/Downloads/2683460.pdf:pdf},
issn = {0003-1305},
journal = {The American Statistician},
keywords = {article1},
mendeley-tags = {article1},
month = {apr},
number = {2},
pages = {31--33},
publisher = {Taylor {\&} Francis},
title = {{Some Interpretations of the Multiple Correlation Coefficient}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00031305.1972.10477345},
volume = {26},
year = {1972}
}
@article{Montgomery1973,
author = {Montgomery, David B and Morrison, Donald G},
file = {:C$\backslash$:/Users/eribu/Downloads/2978351.pdf:pdf},
journal = {The Journal of Finance},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {1009--1013},
title = {{A Note on Adjusting R2}},
volume = {28},
year = {1973}
}
@article{Barrett1974,
abstract = {Many scientists find the coefficient of determination (squared multiple correlation coefficient) a useful index in regression analyses. As with most indices, however, too much can be read into the coefficient of determination. Some scientists use it as a measure of “usefulness” or “goodness of fit” of a regression equation. Actuzlly the coefficient of determination only partially measures the usefulness of a regression equation; it also only partially measures goodness of fit in the sense of how close data points fit the regression surface. Examples are given illustrating the limits of the coefficient of determination and suggesting that graphs and confidence intervals me needed in a more complete evaluation of a regression equation.},
author = {Barrett, James P},
doi = {10.1080/00031305.1974.10479056},
file = {:C$\backslash$:/Users/eribu/Downloads/2683523.pdf:pdf},
isbn = {00031305},
issn = {0003-1305},
journal = {The American Statistician},
keywords = {article1},
mendeley-tags = {article1},
month = {feb},
number = {1},
pages = {19--20},
title = {{The Coefficient of Determination—Some Limitations}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00031305.1974.10479056},
volume = {28},
year = {1974}
}
@article{Konishi1978,
author = {Konishi, Sandnori},
file = {:C$\backslash$:/Users/eribu/Downloads/2335923.pdf:pdf},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {3},
pages = {654--656},
title = {{An Approximation to the Distribution of the Sample Correlation Coefficient}},
volume = {65},
year = {1978}
}
@article{Claudy1978,
author = {Claudy, J. G.},
doi = {10.1177/014662167800200414},
file = {:C$\backslash$:/Users/eribu/Downloads/Applied Psychological Measurement-1978-Claudy-595-607.pdf:pdf},
issn = {0146-6216},
journal = {Applied Psychological Measurement},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {595--607},
title = {{Multiple Regression and Validity Estimation in One Sample}},
volume = {2},
year = {1978}
}
@article{Alam1979,
author = {Alam, Kursheed},
file = {:C$\backslash$:/Users/eribu/Downloads/ADA048126.pdf:pdf},
journal = {Naval Research Logistics Quarterl},
keywords = {article1},
mendeley-tags = {article1},
pages = {237--330},
title = {{Distribution of sample correlation coefficients}},
volume = {26},
year = {1979}
}
@article{Cattin1980,
abstract = {There are two ways to estimate the predictive power of a regression model: a cross-validation procedure and a formula. A number of formulas have been derived. A review of the literature leads to four (unbiased or least biased) formulas, each one appropriate depending on whether the predictor variables are fixed or random and on the measure needed, that is, a measure of the absolute error (the mean squared error of prediction) or of the relative error (the cross-validated multiple correlation). The advantages of these formulas over cross-validation are that they are less cumbersome to use and that they produce more precise estimates. The conditions under which it is appropriate to use these formulas are discussed as well as their use for comparing the predictive power of regression, subjective and equal weights. [ABSTRACT FROM AUTHOR]},
author = {Cattin, Philippe},
doi = {10.1037//0021-9010.65.4.407},
file = {:C$\backslash$:/Users/eribu/Downloads/apl{\_}65{\_}4{\_}407.pdf.pdf:pdf},
issn = {0021-9010},
journal = {Journal of Applied Psychology},
keywords = {ANALYSIS of variance,CORRELATION (Statistics),MATHEMATICAL statistics,REGRESSION analysis,article1},
mendeley-tags = {article1},
number = {4},
pages = {407--414},
title = {{Estimation of the Predictive Power of a Regression Model}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=bth{\&}AN=5133443{\&}site=ehost-live{\&}scope=site},
volume = {65},
year = {1980}
}
@article{Huberty1980,
author = {Huberty, Carl J and Mourad, Salah A},
file = {:C$\backslash$:/Users/eribu/Downloads/Educational and Psychological Measurement-1980-Huberty-101-12.pdf:pdf},
journal = {Educational and Psychological Measurement},
keywords = {article1},
mendeley-tags = {article1},
pages = {101--112},
title = {{Estimation in multiple correlation/prediction}},
volume = {40},
year = {1980}
}
@article{Kvalseth1985,
abstract = {Abstract The coefficient of determination (R 2) is perhaps the single most extensively used measure of goodness of fit for regression models. It is also widely misused. The primary source of the problem is that except for linear models with an intercept term, the several alternative R 2 statistics are not generally equivalent. This article discusses various considerations and potential pitfalls in using the R 2's. Specific points are exemplified by means of empirical data. A new resistant statistic is also introduced.},
author = {Kv{\aa}lseth, Tarald O.},
doi = {10.1080/00031305.1985.10479448},
file = {:C$\backslash$:/Users/eribu/Downloads/2683704.pdf:pdf},
isbn = {0003-1305},
issn = {0003-1305},
journal = {American Statistician},
keywords = {article1,coefficient},
mendeley-tags = {article1},
number = {4},
pages = {279--285},
title = {{Cautionary Note about R2}},
url = {http://dx.doi.org/10.1080/00031305.1985.10479448},
volume = {39},
year = {1985}
}
@article{Ozer1985,
abstract = {Contends that both the interpretation of an effect size and the actual estimation of a coefficient of determination are partially theory-dependent. Two theoretical models for the variables cases are considered. In a variety of circumstances where the square of the correlation is used, the required assumptions are not tenable. In the alternate model, the absolute value of the correlation provides a coefficient of determination. The correlation coefficient is recommended for use as an effect-size indicator, because evaluating effect size in terms of variance accounted for may lead to interpretations that grossly underestimate the magnitude of a relation. (25 ref) (PsycINFO Database Record (c) 2010 APA )},
author = {Ozer, Daniel J.},
doi = {10.1037/0033-2909.97.2.307},
file = {:C$\backslash$:/Users/eribu/Downloads/bul{\_}97{\_}2{\_}307.pdf.pdf:pdf},
isbn = {0033-2909},
issn = {0033-2909},
journal = {Psychological Bulletin},
keywords = {article1},
mendeley-tags = {article1},
number = {2},
pages = {307--315},
title = {{Correlation and the coefficient of determination.}},
volume = {97},
year = {1985}
}
@article{Wood1986,
author = {Wood, Robert},
doi = {10.1080/0141192860120303},
file = {:C$\backslash$:/Users/eribu/Downloads/Think Before you Square Correlations or do anything with them.pdf:pdf},
isbn = {0141192860},
issn = {0141-1926},
journal = {British Educational Research Journal},
keywords = {article1},
mendeley-tags = {article1},
number = {3},
pages = {249--255},
title = {{Think Before you Square Correlations—or do anything with them}},
url = {http://doi.wiley.com/10.1080/0141192860120303},
volume = {12},
year = {1986}
}
@article{Helland1987,
abstract = {The coefficient of determination (or squared multiple correlation coefficient) R2 is a common output from computer regression packages. We argue first that this statistic can be interpreted as an estimator of a population parameter only when the regressors are random. In such a model the variation of R2 is discussed, and a simple approximate confidence interval for the population coefficient of determination is proposed. Its use is illustrated on data from computerized tomography investigation of pigs.},
author = {Helland, Inge S},
doi = {10.2307/2531949},
file = {:C$\backslash$:/Users/eribu/Downloads/2531949.pdf:pdf},
issn = {0006341X, 15410420},
journal = {Biometrics},
keywords = {article1},
mendeley-tags = {article1},
number = {1},
pages = {61--69},
publisher = {[Wiley, International Biometric Society]},
title = {{On the Interpretation and Use of R2 in Regression Analysis}},
url = {http://www.jstor.org/stable/2531949},
volume = {43},
year = {1987}
}
@article{Rodgers1988,
abstract = {In 1885, Sir Francis Galton first defined the term "regression" and completed the theory of bivariate correlation. A decade later, Karl Pearson developed the index that we still use to measure correlation, Pearson's r. Our article is written in recognition of the 100th anniversary of Galton's first discussion of regression and correlation. We begin with a brief history. Then we present 13 different formulas, each of which represents a different computational and conceptual definition of r. Each formula suggests a different way of thinking about this index, from algebraic, geometric, and trigonometric settings. We show that Pearson's r (or simple functions of r) may variously be thought of as a special type of mean, a special type of variance, the ratio of two means, the ratio of two variances, the slope of a line, the cosine of an angle, and the tangent to an ellipse, and may be looked at from several other interesting perspectives.},
archivePrefix = {arXiv},
arxivId = {Rodgers, J. L., {\&} Nicewander, W. A. (2008). Thirteen Ways to Look at the Correlation Coefficient, 42(1), 59–66.},
author = {Rodgers, Joseph Lee and Nicewander, W. Alan},
doi = {10.2307/2685263},
eprint = {Rodgers, J. L., {\&} Nicewander, W. A. (2008). Thirteen Ways to Look at the Correlation Coefficient, 42(1), 59–66.},
file = {:C$\backslash$:/Users/eribu/Downloads/2685263.pdf:pdf},
isbn = {00031305},
issn = {00031305},
journal = {The American Statistician},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {1},
pages = {59 -- 66},
pmid = {2685263},
title = {{Thirteen Ways to Look at the Correlation Coefficient}},
url = {http://www.jstor.org/stable/2685263},
volume = {42},
year = {1988}
}
@article{Hawkins1989,
abstract = {Hogg, RV, and Craig, AT (1978), Introduction to Mathematical Sta- tistics (4th ed.), New York: Macmillan. Pitman, EG (1939), "A Note on Normal CorTelation," Biomnetrika, 31, 9-12. Snedecor, GW, and Cochran, WG (1980), Statistical Methods (7th ed.), Ames: Iowa State},
author = {Hawkins, D},
doi = {10.2307/2685369},
file = {:C$\backslash$:/Users/eribu/Downloads/2685369.pdf:pdf},
issn = {00031305},
journal = {American Statistician},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {235--237},
title = {{Using U statistics to derive the asymptotic distribution of Fisher's Z statistic}},
url = {http://www.jstor.org/stable/2685369$\backslash$npapers3://publication/uuid/25473EA2-360A-4031-870D-0A90BCE030FF},
volume = {43},
year = {1989}
}
@article{Nagelkerke1991,
abstract = {A generalization of the coefficient of determination R2 to general regression models is discussed. A modification of an earlier definition to allow for discrete models is proposed.},
author = {Nagelkerke, N. J D},
doi = {10.1093/biomet/78.3.691},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nagelkerke - 1991 - A note on a general definition of the coefficient of determination.pdf:pdf},
isbn = {0006-3444},
issn = {00063444},
journal = {Biometrika},
keywords = {Discrete probability,Log likelihood,Multiple correlation coefficient,Regression model,Residual variation,article1},
mendeley-tags = {article1},
number = {3},
pages = {691--692},
pmid = {339},
title = {{A note on a general definition of the coefficient of determination}},
volume = {78},
year = {1991}
}
@article{Greco1992,
author = {Greco, Luigi},
file = {:C$\backslash$:/Users/eribu/Downloads/ref{\_}till{\_}coop1916/art{\%}3A10.1007{\%}2FBF02589036.pdf:pdf},
journal = {J. ltaL Statist. Soc.},
keywords = {article1,correlation coefficient,normal bi-variate popula-,probability distributions},
mendeley-tags = {article1},
pages = {289--294},
title = {{THE PROBABILITY INTEGRAL OF THE SAMPLE CORRELATION COEFFICIENT Ik- {\~{}}}},
volume = {2},
year = {1992}
}
@article{Efron1997,
abstract = {A study investigates the error rate of a rule for predicting future responses constructed from a training set of data. Results are nonparametric and apply to any possible prediction rule.},
annote = {Handlar om Bootstrap .632+ (vilket kanske {\"{a}}nnu inte {\"{a}}r helt relevant f{\"{o}}r oss).

Utv{\"{a}}rderar p{\aa} 24 olika modeller presenteade i tabell. Varierar sample size och dimensionality som vi. Dock stor skillnad att det baseras p{\aa} classification och inte regression. 

Anv{\"{a}}nder mindre samlpe sizes {\"{a}}n vi och fler variabler (st{\"{o}}rre p).

Har inte l{\"{a}}st s{\aa} noggrant d{\aa} den inte k{\"{a}}nns helt relevant och {\"{a}}r ganska teoretisk med mkt notation etc.},
author = {Efron, B. and Tibshirani, R.},
doi = {10.1080/01621459.1997.10474007},
file = {:C$\backslash$:/Users/eribu/Downloads/01621459{\%}2E1997{\%}2E10474007.pdf:pdf},
isbn = {0162-1459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {article1,classification,cross-validation bootstrap,prediction rule},
mendeley-tags = {article1},
number = {438},
pages = {548},
pmid = {370},
title = {{Improvements on cross-validation: The .632 plus bootstrap method}},
volume = {92},
year = {1997}
}
@article{ShigekazuNakagawa1997,
author = {{Shigekazu Nakagawa}, Naoto Niki},
file = {:C$\backslash$:/Users/eribu/Downloads/110001235586.pdf:pdf},
keywords = {article1,mixed conductors,p-t-x,perovskites,thermodynamic stability},
mendeley-tags = {article1},
number = {97},
title = {{Distribution of the sample correlation coefficient for nonnormal populations}},
volume = {2738},
year = {1997}
}
@article{KepplingerHansMathiasHabermeier1995,
author = {Raju, Nambury S and Bilgic, Reyhan and Edwards, Jack E and Fleer, Paul F},
file = {:C$\backslash$:/Users/eribu/Downloads/Applied Psychological Measurement-1997-Raju-291-305.pdf:pdf},
journal = {Applied Psychological Measurement},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {291--305},
title = {{Methodology Review: Estimation of population validity and cross-validity, and the use of equal weights in prediction}},
volume = {21},
year = {1997}
}
@article{Algina1999,
abstract = {Four methods for constructing 100(1 - alpha){\%} confidence intervals$\backslash$nfor the population squared multiple correlation coefficient (rho(2))$\backslash$nwere compared. In one method the confidence interval was constructed$\backslash$nby using the distribution of R-2. Provided rho(2) > 0 the coverage$\backslash$nprobability for this method is exactly 1 - alpha when the data are$\backslash$nmultivariate normal. The other three methods are based on results$\backslash$nin Olkin and Finn (1995) and are approximate. Results show that each$\backslash$nof the approximate methods works very poorly for some combinations$\backslash$nof rho(2). The method based on the distribution of R-2 is recommended.},
author = {Algina, James},
doi = {10.1207/S15327906MBR3404{\_}5},
file = {:C$\backslash$:/Users/eribu/Downloads/A Comparison of Methods for Constructing Confidence Intervals for the Squared Multiple Correlation Coefficient.pdf:pdf},
issn = {0027-3171},
journal = {Multivariate Behavioral Research},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {4},
pages = {493--504},
title = {{A Comparison of Methods for Constructing Confidence Intervals for the Squared Multiple Correlation Coefficient}},
url = {http://www.tandfonline.com/doi/abs/10.1207/S15327906MBR3404{\_}5},
volume = {34},
year = {1999}
}
@article{Raju1999,
abstract = {An empirical monte carlo study was performed using predictor and criterion data from 84,808 U.S. Air Force enlistees. 501 samples were drawn for each of seven sample size conditions: 25, 40, 60, 80, 100, 150, and 200. Using an eight-predictor model, 500 estimates for each of 9 validity and 11 cross-validity estimation procedures were generated for each sample size condition. These estimates were then compared to the actual squared population validity and cross-validity in terms of mean bias and mean squared bias. For the regression models determined using ordinary least squares, the Ezekiel procedure produced the most accurate estimates of squared population validity (followed by the Smith and the Wherry procedures), and Burket’s formula resulted in the best estimates of squared population cross-validity. Other analyses compared the coefficients determined by traditional empirical cross-validation and equal weights; equal weights resulted in no loss of predictive accuracy and less shrinkage. Numerous issues for future basic research on validation and cross-validation are identified.},
author = {Raju, N S and Bilgic, R and Edwards, J E and Fleer, P F},
doi = {10.1177/01466219922031220},
file = {:C$\backslash$:/Users/eribu/Downloads/Applied Psychological Measurement-1999-Raju-99-115.pdf:pdf},
isbn = {0146-6216},
issn = {0146-6216},
journal = {Applied Psychological Measurement},
keywords = {article1},
mendeley-tags = {article1},
number = {2},
pages = {99--115},
title = {{Accuracy of Population Validity and Cross-Validity Estimation: An Empirical Comparison of Formula-Based, Traditional Empirical, and Equal Weights Procedures}},
url = {http://apm.sagepub.com/content/23/2/99},
volume = {23},
year = {1999}
}
@article{Steyerberg2001,
abstract = {The performance of a predictive model is overestimated when simply determined on the sample of subjects that was used to construct the model. Several internal validation methods are available that aim to provide a more accurate estimate of model performance in new subjects. We evaluated several variants of split-sample, cross-validation and bootstrapping methods with a logistic regression model that included eight predictors for 30-day mortality after an acute myocardial infarction. Random samples with a size between n = 572 and n = 9165 were drawn from a large data set (GUSTO-I; n = 40,830; 2851 deaths) to reflect modeling in data sets with between 5 and 80 events per variable. Independent performance was determined on the remaining subjects. Performance measures included discriminative ability, calibration and overall accuracy. We found that split-sample analyses gave overly pessimistic estimates of performance, with large variability. Cross-validation on 10{\%} of the sample had low bias and low variability, but was not suitable for all performance measures. Internal validity could best be estimated with bootstrapping, which provided stable estimates with low bias. We conclude that split-sample validation is inefficient, and recommend bootstrapping for estimation of internal validity of a predictive logistic regression model.},
annote = {Tipsad av Szilard.

fokuserad p{\aa} logistisk regression.

Utg{\aa}r fr{\aa}n praktiskt exempel med hj{\"{a}}rtattack. 
V{\aa}r ansats {\"{a}}r mer teoretisk/generell.
J{\"{a}}mf{\"{o}}r med olika EPV-v{\"{a}}rden och stratifiering.
Resamplar 500 ggr.
stepwise model selection med 8 predektorer.

Utv{\"{a}}rderar flera olika m{\"{a}}tv{\"{a}}rden, inkl R2 (dock Negelkerke).

Olika metoder men inte jack-knife.

F{\aa}r delvis samma slutsats som vi ang {\"{o}}verskattning med cv.},
author = {Steyerberg, Ewout W and Harrell, Frank E and Borsboom, Gerard J.J.M and Eijkemans, M.J.C and Vergouwe, Yvonne and Habbema, J.Dik F},
doi = {10.1016/S0895-4356(01)00341-9},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Steyerberg et al. - 2001 - Internal validation of predictive models.pdf:pdf},
issn = {08954356},
journal = {Journal of Clinical Epidemiology},
keywords = {Bootstrapping,Internal validation,Logistic regression analysis,Predictive models,article1,harrell,statistics},
mendeley-tags = {article1,harrell,statistics},
month = {aug},
number = {8},
pages = {774--781},
title = {{Internal validation of predictive models}},
url = {http://www.sciencedirect.com/science/article/pii/S0895435601003419},
volume = {54},
year = {2001}
}
@article{Breiman2001,
abstract = {There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commit-ment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current prob-lems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.},
annote = {Denna artikel {\"{a}}r kritisk mot modellering och f{\"{o}}redrar i likhet med Kuhn att utg{\aa} fr{\aa}n accuracy meassure, inte model validering, d{\aa} detta ofta inte l{\aa}ter sig g{\"{o}}ras s{\aa} l{\"{a}}tt.

Inneh{\aa}ller ocks{\aa} kommentarer fr{\aa}n ett flertal auktoriteter p{\aa} omr{\aa}det samt d{\"{a}}refter ett avslutande svar fr{\aa}n f{\"{o}}rfattaren.},
author = {Breiman, Leo},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Breiman - 2001 - Statistical Modeling The Two Cultures.pdf:pdf},
journal = {Statistical Science},
keywords = {article1,statistics},
mendeley-tags = {article1,statistics},
number = {3},
pages = {199--231},
title = {{Statistical Modeling: The Two Cultures}},
volume = {16},
year = {2001}
}
@article{Yin2001,
abstract = {Abstract The effectiveness of various analytical formulas for estimating R 2 shrinkage in multiple regression analysis was investigated. Two categories of formulas were identified: estimators of the squared population multiple correlation coefficient ($\rho$2) and those of the squared population cross-validity coefficient ($\rho$c 2). The authors conducted a Monte Carlo experiment to investigate the effectiveness of the analytical formulas for estimating R 2 shrinkage, with 4 fully crossed factors (squared population multiple correlation coefficient, number of predictors, sample size, and degree of multicollinearity) and 500 replications in each cell. The results indicated that the most widely used Wherry formula (in both SAS and SPSS) is probably not the most effective analytical formula for estimating $\rho$2. Instead, the Pratt formula and the Browne formula outperformed other analytical formulas in estimating $\rho$2 and $\rho$c 2, respectively.},
author = {Yin, Ping and Fan, Xitao},
doi = {10.1080/00220970109600656},
file = {:C$\backslash$:/Users/eribu/Downloads/Estimating R 2 Shrinkage in Multiple Regression A Comparison of Different Analytical Methods.pdf:pdf},
isbn = {0022097010960},
issn = {0022-0973},
journal = {The Journal of Experimental Education},
keywords = {Cross-validation,Monte Carlo method,R 1 shrinkage,article1,multiple regression,statistical bias},
mendeley-tags = {article1},
number = {2},
pages = {203--224},
title = {{Estimating R 2 Shrinkage in Multiple Regression: A Comparison of Different Analytical Methods}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00220970109600656},
volume = {69},
year = {2001}
}
@article{Algina2001,
abstract = {The increase in the squared multiple correlation coefficient (DeltaR(2))$\backslash$nassociated with a variable in a regression equation is a commonly$\backslash$nused measure of importance in regression analysis. The probability$\backslash$nthat an asymptotic confidence interval will include Delta rho (2)$\backslash$nwas investigated. With sample sizes typically used in regression$\backslash$nanalyses, when Delta rho (2) = 0.00 and the confidence level is .95$\backslash$nor greater, the probability will be at least .999. For Delta rho$\backslash$n(2) greater than or equal to .01 and a confidence level of .95 or$\backslash$ngreater, the probability will be smaller than the nominal confidence$\backslash$nlevel. For Delta rho (2) greater than or equal to .05 and a confidence$\backslash$nlevel of .95, tables are provided for the sample size necessary for$\backslash$nthe probability to be at least .925 and to be at least .94.},
author = {Algina, J. and Moulder, B. C.},
doi = {10.1177/00131640121971400},
file = {:C$\backslash$:/Users/eribu/Downloads/Educational and Psychological Measurement-2001-Algina-633-49.pdf:pdf},
issn = {0013-1644},
journal = {Educational and Psychological Measurement},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {4},
pages = {633--649},
title = {{Sample Sizes for Confidence Intervals on the Increase in the Squared Multiple Correlation Coefficient}},
volume = {61},
year = {2001}
}
@article{Zimmerman2003,
author = {Zimmerman, Donald W and Zumbo, Bruno D and Williams, Richard H},
file = {:C$\backslash$:/Users/eribu/Downloads/9.ZUMBO.pdf:pdf},
issn = {02112159},
journal = {Transformation},
keywords = {article1},
mendeley-tags = {article1},
number = {1},
pages = {133--158},
title = {{Bias in estimation and hypothesis testing of correlation}},
url = {http://redalyc.uaemex.mx/redalyc/html/169/16924109/16924109.html$\backslash$nhttp://www.uv.es/psicologica/articulos1.03/9.ZUMBO.pdf},
volume = {24},
year = {2003}
}
@article{Croux2003,
abstract = {Many robust regression estimators are defined by minimizing a measure of spread of the residuals. An accompanying R{\^{}}2-measure, or multiple correlation coefficient, is then easily obtained. In this paper, local robustness properties of these robust R{\^{}}2-coefficients are investigated. It is also shown how confidence intervals for the population multiple correlation coefficient can be constructed in the case of multivariate normality.},
author = {Croux, Christophe and Dehon, Catherine},
doi = {10.1007/s00362-003-0158-7},
file = {:C$\backslash$:/Users/eribu/Downloads/rsquared.pdf:pdf},
issn = {0932-5026},
journal = {Statistical Papers},
keywords = {R{\^{}}2 measure,article1,influence function,multiple correlation,multiple correlation coefficient,regression analysis,robustness},
mendeley-tags = {article1,multiple correlation},
number = {3},
pages = {315--334},
title = {{Estimators of the multiple correlation coefficient: Local robustness and confidence intervals}},
url = {http://www.springerlink.com/index/jl8n427176112777.pdf$\backslash$nhttp://www.springerlink.com/index/10.1007/s00362-003-0158-7},
volume = {44},
year = {2003}
}
@article{Zimmerman2003a,
abstract = {This study examined bias in the sample correlation coefficient, r, and its correction by unbiased estimators. Computer simulations revealed that the expected value of correlation coefficients in samples from a normal population is slightly less than the population correlation, {\&}{\#}961;, and that the bias is almost eliminated by an estimator suggested by R.A. Fisher and is more completely eliminated by a related estimator recommended by Olkin and Pratt. Transformation of initial scores to ranks and calculation of the Spearman rank correlation, rS, produces somewhat greater bias. Type I error probabilities of significance tests of zero correlation based on the Student t statistic and exact tests based on critical values of rS obtained from permutations remain fairly close to the significance level for normal and several non-normal distributions. However, significance tests of non-zero values of correlation based on the r to Z transformation are grossly distorted for distributions that violate bivariate normality. Also, significance tests of non-zero values of rS based on the r to Z transformation are distorted even for normal distributions.},
author = {Zimmerman, D and Zumbo, B and Williams, R},
file = {:C$\backslash$:/Users/eribu/Downloads/9.ZUMBO.pdf:pdf},
issn = {02112159},
journal = {Psicologica},
keywords = {article1},
mendeley-tags = {article1},
number = {24},
pages = {133--158},
title = {{Bias in Estimation and Hypothesis Testing of Correlation}},
url = {http://www.redalyc.org/articulo.oa?id=16924109SL},
volume = {24},
year = {2003}
}
@article{Fu2005,
abstract = {MOTIVATION: Estimation of misclassification error has received increasing attention in clinical diagnosis and bioinformatics studies, especially in small sample studies with microarray data. Current error estimation methods are not satisfactory because they either have large variability (such as leave-one-out cross-validation) or large bias (such as resubstitution and leave-one-out bootstrap). While small sample size remains one of the key features of costly clinical investigations or of microarray studies that have limited resources in funding, time and tissue materials, accurate and easy-to-implement error estimation methods for small samples are desirable and will be beneficial.$\backslash$n$\backslash$nRESULTS: A bootstrap cross-validation method is studied. It achieves accurate error estimation through a simple procedure with bootstrap resampling and only costs computer CPU time. Simulation studies and applications to microarray data demonstrate that it performs consistently better than its competitors. This method possesses several attractive properties: (1) it is implemented through a simple procedure; (2) it performs well for small samples with sample size, as small as 16; (3) it is not restricted to any particular classification rules and thus applies to many parametric or non-parametric methods.},
author = {Fu, Wenjiang J. and Carroll, Raymond J. and Wang, Suojin},
doi = {10.1093/bioinformatics/bti294},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fu, Carroll, Wang - 2005 - Estimating misclassification error with small samples via bootstrap cross-validation.pdf:pdf},
isbn = {1367-4803 (Print)$\backslash$r1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
keywords = {article1},
mendeley-tags = {article1},
pmid = {15691862},
title = {{Estimating misclassification error with small samples via bootstrap cross-validation}},
year = {2005}
}
@article{FarzipoorSean2005,
abstract = {In some of the papers on data envelopment analysis (DEA), there have been explained that if correlation coefficient between each pair of input (output) vectors is strong and positive, one of the input (output) vector could be omitted. The objective of this paper is to determine correlation coefficient threshold that beyond which omission of one or more input vectors have no statistically significant effect on the efficiency mean. The threshold identification in terms of some of the DEA models including CCR, CCRCSW, BCC and BCCCSW are performed. To analyze the data, analysis of variance (ANOVA) is used. ?? 2004 Published by Elsevier Inc.},
author = {{Farzipoor Sean}, R. and Memariani, A. and Lotfi, F. Hosseinzadeh},
doi = {10.1016/j.amc.2003.12.117},
file = {:C$\backslash$:/Users/eribu/Downloads/1-s2.0-S0096300304001067-main.pdf:pdf},
isbn = {0096-3003},
issn = {00963003},
journal = {Applied Mathematics and Computation},
keywords = {Analysis of variance,Correlation coefficient,Data envelopment analysis,article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {2},
pages = {503--521},
title = {{The effect of correlation coefficient among multiple input vectors on the efficiency mean in data envelopment analysis}},
volume = {162},
year = {2005}
}
@book{Faraway2005,
abstract = {The book focuses on the practice of regression and analysis of variance. It clearly demonstrates the different methods available and in which situations each one applies. It covers all of the standard topics, from the basics of estimation to missing data, factorial designs, and block designs, but it also includes discussion of topics, such as model uncertainty, rarely addressed in books of this type. The presentation incorporates an abundance of examples that clarify both the use of each technique and the conclusions one can draw from the results.},
author = {Faraway, Julian J.},
booktitle = {Library},
isbn = {1584884258},
keywords = {article1},
mendeley-tags = {article1},
pages = {1--229},
title = {{Linear Models with R}},
url = {http://www.stat.lsa.umich.edu/{~}faraway/LMR/},
year = {2005}
}
@article{FarzipoorSean2005a,
abstract = {In some of the papers on data envelopment analysis (DEA), there have been explained that if correlation coefficient between each pair of input (output) vectors is strong and positive, one of the input (output) vector could be omitted. The objective of this paper is to determine correlation coefficient threshold that beyond which omission of one or more input vectors have no statistically significant effect on the efficiency mean. The threshold identification in terms of some of the DEA models including CCR, CCRCSW, BCC and BCCCSW are performed. To analyze the data, analysis of variance (ANOVA) is used. ?? 2004 Published by Elsevier Inc.},
author = {{Farzipoor Sean}, R. and Memariani, A. and Lotfi, F. Hosseinzadeh},
doi = {10.1016/j.amc.2003.12.117},
file = {:C$\backslash$:/Users/eribu/Downloads/1-s2.0-S0096300304001067-main.pdf:pdf},
isbn = {0096-3003},
issn = {00963003},
journal = {Applied Mathematics and Computation},
keywords = {Analysis of variance,Correlation coefficient,Data envelopment analysis,article1},
mendeley-tags = {article1},
number = {2},
pages = {503--521},
title = {{The effect of correlation coefficient among multiple input vectors on the efficiency mean in data envelopment analysis}},
volume = {162},
year = {2005}
}
@article{Bioinformatics2006,
abstract = {Background: Cross-validation (CV) is an effective method for estimating the prediction error of a classifier. Some recent articles have proposed methods for optimizing classifiers by choosing classifier parameter values that minimize the CV error estimate. We have evaluated the validity of using the CV error estimate of the optimized classifier as an estimate of the true error expected on independent data. Results: We used CV to optimize the classification parameters for two kinds of classifiers; Shrunken Centroids and Support Vector Machines (SVM). Random training datasets were created, with no difference in the distribution of the features between the two classes. Using these "null" datasets, we selected classifier parameter values that minimized the CV error estimate. 10-fold CV was used for Shrunken Centroids while Leave-One-Out-CV (LOOCV) was used for the SVM. Independent test data was created to estimate the true error. With "null" and "non null" (with differential expression between the classes) data, we also tested a nested CV procedure, where an inner CV loop is used to perform the tuning of the parameters while an outer CV is used to compute an estimate of the error. The CV error estimate for the classifier with the optimal parameters was found to be a substantially biased estimate of the true error that the classifier would incur on independent data. Even though there is no real difference between the two classes for the "null" datasets, the CV error estimate for the Shrunken Centroid with the optimal parameters was less than 30{\%} on 18.5{\%} of simulated training data-sets. For SVM with optimal parameters the estimated error rate was less than 30{\%} on 38{\%} of "null" data-sets. Performance of the optimized classifiers on the independent test set was no better than chance. The nested CV procedure reduces the bias considerably and gives an estimate of the error that is very close to that obtained on the independent testing set for both Shrunken Centroids and SVM classifiers for "null" and "non-null" data distributions. Conclusion: We show that using CV to compute an error estimate for a classifier that has itself been tuned using CV gives a significantly biased estimate of the true error. Proper use of CV for estimating true error of a classifier developed using a well defined algorithm requires that all steps of the algorithm, including classifier parameter tuning, be repeated in each CV loop. A nested CV procedure provides an almost unbiased estimate of the true error.},
author = {Bioinformatics, Bmc and Varma, Sudhir and Simon, Richard},
doi = {10.1186/1471-2105-7-91},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bioinformatics, Varma, Simon - 2006 - Bias in error estimation when using cross-validation for model selection.pdf:pdf},
journal = {BMC Bioinformatics},
keywords = {article1},
mendeley-tags = {article1},
number = {7},
title = {{Bias in error estimation when using cross-validation for model selection}},
url = {http://www.biomedcentral.com/1471-2105/7/91},
volume = {7},
year = {2006}
}
@article{Asuero2006,
abstract = {Correlation and regression are different, but not mutually exclusive, techniques. Roughly, regression is used for prediction (which does not extrapolate beyond the data used in the analysis) whereas correlation is used to determine the degree of association. There situations in which the x variable is not fixed or readily chosen by the experimenter, but instead is a random covariate to the y variable. This paper shows the relationships between the coefficient of determination, the multiple correlation coefficient, the covariance, the correlation coefficient and the coefficient of alienation, for the case of two related variables x and y. It discusses the uses of the correlation coefficient r, either as a way to infer correlation, or to test linearity. A number of graphical examples are provided as well as examples of actual chemical applications. The paper recommends the use of z Fisher transformation instead of r values because r is not normally distributed but z is (at least in approximation). For either correlation or for regression models, the same expressions are valid, although they differ significantly in meaning. Correlation and regression are different, but not mutually exclusive, techniques. Roughly, regression is used for prediction (which does not extrapolate beyond the data used in the analysis) whereas correlation is used to determine the degree of association. There situations in which the x variable is not fixed or readily chosen by the experimenter, but instead is a random covariate to the y variable. This paper shows the relationships between the coefficient of determination, the multiple correlation coefficient, the covariance, the correlation coefficient and the coefficient of alienation, for the case of two related variables x and y. It discusses the uses of the correlation coefficient r, either as a way to infer correlation, or to test linearity. A number of graphical examples are provided as well as examples of actual chemical applications. The paper recommends the use of z Fisher transformation instead of r values because r is not normally distributed but z is (at least in approximation). For either correlation or for regression models, the same expressions are valid, although they differ significantly in meaning.},
author = {Asuero, a. G. and Sayago, A. and Gonz{\'{a}}lez, a. G.},
doi = {10.1080/10408340500526766},
file = {:C$\backslash$:/Users/eribu/Downloads/The Correlation Coefficient An Overview.pdf:pdf},
isbn = {1040-8347},
issn = {1040-8347},
journal = {Critical Reviews in Analytical Chemistry},
keywords = {article1,cause and effect,correlation coefficient,covariance,inference,lineariy,multiple correlation,multiple correlation coefficient,significance tests},
mendeley-tags = {article1,multiple correlation},
number = {July},
pages = {41--59},
pmid = {19702027},
title = {{The Correlation Coefficient: An Overview}},
volume = {36},
year = {2006}
}
@article{Wang2007,
abstract = {In this study the authors investigated the use of 5 (i.e., Claudy, Ezekiel, Olkin-Pratt, Pratt, and Smith) R[squared] correction formulas with the Pearson r[squared]. The authors estimated adjustment bias and precision under 6 x 3 x 6 conditions (i.e., population $\rho$ values of 0.0, 0.1, 0.3, 0.5, 0.7, and 0.9; population shapes normal, skewness = kurtosis = 1, and skewness = -1.5 with kurtosis = 3.5; ns = 10, 20, 40, 60, 100, and 200 respectively). Results indicate that the sample Pearson r[squared] is marginally biased at small sample sizes and small population effect sizes, and that the Ezekiel and the Smith R[squared] corrections work well in controlling this bias. (Contains 5 tables.)},
author = {Wang, Zhongmiao and Thompson, Bruce},
doi = {10.3200/JEXE.75.2.109-125},
file = {:C$\backslash$:/Users/eribu/Downloads/Is the Pearson r 2 Biased and if So What Is the Best Correction Formula.pdf:pdf},
issn = {0022-0973},
journal = {The Journal of Experimental Education},
keywords = {article1},
mendeley-tags = {article1},
number = {2},
pages = {109--125},
title = {{Is the Pearson r 2 Biased, and if So, What Is the Best Correction Formula?}},
volume = {75},
year = {2007}
}
@article{Zou2007,
abstract = {Confidence intervals are widely accepted as a preferred way to present study results. They encompass significance tests and provide an estimate of the magnitude of the effect. However, comparisons of correlations still rely heavily on significance testing. The persistence of this practice is caused primarily by the lack of simple yet accurate procedures that can maintain coverage at the nominal level in a nonlopsided manner. The purpose of this article is to present a general approach to constructing approximate confidence intervals for differences between (a) 2 independent correlations, (b) 2 overlapping correlations, (c) 2 nonoverlapping correlations, and (d) 2 independent R2s. The distinctive feature of this approach is its acknowledgment of the asymmetry of sampling distributions for single correlations. This approach requires only the availability of confidence limits for the separate correlations and, for correlated correlations, a method for taking into account the dependency between correlations. These closed-form procedures are shown by simulation studies to provide very satisfactory results in small to moderate sample sizes. The proposed approach is illustrated with worked examples. (PsycINFO Database Record (c) 2013 APA, all rights reserved)(journal abstract)},
address = {Department of Epidemiology and Biostatistics, Schulich School of Medicine and Dentistry, University of Western Ontario, London, ON, Canada gzou@robarts.ca; Zou, Guang Yong,London,Canada,N6A 5C1,Department of Epidemiology and Biostatistics, Schulich School},
annote = {Copyright - © American Psychological Association 2007

Date completed - 2007-08-22

Date created - 2006-07-06

Date revised - 20080107

Number of references - 53

SuppNotes - (2400) Other [Available: Internet]; 10.1037/1082-989x.12.4.399.supp

Last updated - 2015-02-03

SubjectsTermNotLitGenreText - Confidence Limits (Statistics)
1771 7878 371; Multiple Regression
5202 5210 7878 371 7886; Statistical Correlation
7879 7878 371; 3906 2922

ALF, E. F., JR; GRAF, R. G. Asymptotic confidence limits for the difference between two squared multiple correlations : A simplified approach. Psychological methods, 4. 1 (1999): 70-75. American Psychological Association

Algina, J. A comparison of methods for constructing confidence intervals for the squared multiple correlation coefficient. MULTIVARIATE BEHAVIORAL RESEARCH, 34. 4 (1999): 493-504. LAWRENCE ERLBAUM ASSOC INC

Algina, J; Moulder, B C. Sample sizes for confidence intervals on the increase in the squared multiple correlation coefficient. EDUCATIONAL AND PSYCHOLOGICAL MEASUREMENT, 61. 4 (2001): 633-649. SAGE PUBLICATIONS INC

ALGINA, J.; KESELMAN, H. J. Comparing squared multiple correlation coefficients : Examination of a confidence interval and a test of significance. Psychological methods, 4. 1 (1999): 76-83. American Psychological Association

Bradley, James V. Robustness? British Journal of Mathematical and Statistical Psychology, 31. 2 (1978): 144-152. British Psychological Society; Wiley-Blackwell Publishing Ltd

Carpenter, James; Bithell, John. Bootstrap confidence intervals: When, which, what? A practical guide for medical statisticians. Statistics in Medicine, 19. 9 (2000): 1141-1164. John Wiley and Sons Ltd

Cheung, M W L; Chan, W. Testing dependent correlation coefficients via structural equation modeling. ORGANIZATIONAL RESEARCH METHODS, 7. 2 (2004): 206-223. SAGE PUBLICATIONS INC

Cohen, Jacob; Cohen, Patricia; West, Stephen G.; Aiken, Leona S. Applied multiple regression/correlation analysis for the behavioral sciences (3rd ed.). Applied multiple regression/correlation analysis for the behavioral sciences (3rd ed.). (2003): xxviii, 703. Lawrence Erlbaum Associates Publishers

Cohen, Jacob. The earth is round (p 
Cumming, Geoff; Finch, Sue. Inference by Eye: Confidence Intervals and How to Read Pictures of Data. American Psychologist, 60. 2 (2005): 170-180. American Psychological Association

DiCiccio, T J; Efron, B. Bootstrap confidence intervals. STATISTICAL SCIENCE, 11. 3 (1996): 189-212. INST MATHEMATICAL STATISTICS

Donner, Allan; Zou, Guangyong. Interval estimation for a difference between intraclass kappa statistics. Biometrics, 58. 1 (2002): 209-215. Biometric Society

Efron, B., {\&}amp; Tibshirani, R. J. (1993). An introduction to the bootstrap. Boca Raton, FL: Chapman {\&}amp; Hall/CRC Press.

Efron, B. BOOTSTRAP CONFIDENCE INTERVALS GOOD OR BAD? Psychological Bulletin, 104. 2 (1988): 293-296

Efron, B. (1981). Nonparametric standard errors and confidence intervals, Canadian Journal of Statistics 9 (2): 139-172.

EFRON, B. 1977 RIETZ LECTURE - BOOTSTRAP METHODS - ANOTHER LOOK AT THE JACKKNIFE. ANNALS OF STATISTICS, 7. 1 (1979): 1-26. INST MATHEMATICAL STATISTICS

EFRON, B. BETTER BOOTSTRAP CONFIDENCE-INTERVALS. JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION, 82. 397 (1987): 171-185. AMER STATISTICAL ASSOC

Efron, B. Second thoughts on the bootstrap. STATISTICAL SCIENCE, 18. 2 (2003): 135-140. INST MATHEMATICAL STATISTICS

EFRON, B. Boostrap confidence intervals for a class of parametric problems. Biometrika, 72. 1 (1985): 45-58. Oxford University Press

Fisher, R. A. The general sampling distribution of the multiple correlation coefficient. Royal Society of London. Proceedings. Series B. Containing Papers of a Biological Character, A121. (1928): 654-673. The Royal Society

Gajjar, A. V. (1967). Limiting distributions of certain transformations of multiple correlation coefficients. Metron, 26, 189-193.

HELLAND, I. S. On the interpretation and use of R2 in regression analysis. Biometrics, 43. 1 (1987): 61-69. Blackwell

Kirk, Roger E. Effect magnitude: A different focus. JOURNAL OF STATISTICAL PLANNING AND INFERENCE, 137. 5 (2007): 1634-1646. ELSEVIER SCIENCE BV

Kramer, K H; Kramer, K H. TABLES FOR CONSTRUCTING CONFIDENCE LIMITS ON THE MULTIPLE CORRELATION COEFFICIENT. Journal of the American Statistical Association, 58. 304 (1963): 1082-1085

Lee, Y S. Some results on the sampling distribution of the multiple correlation coefficient. Journal of the Royal Statistical Society, Series B, Methodological, 33. (1971)

LEE, Y S. TABLES OF UPPER PERCENTAGE POINTS OF MULTIPLE CORRELATION COEFFICIENT. BIOMETRIKA, 59. 1 (1972): 175-189. BIOMETRIKA TRUST

Maxwell, Scott E. Sample size and multiple regression analysis. Psychological methods, 5. 4 (2000): 434-458. American Psychological Association

MORRIS, Martha Clare; TANGNEY, Christine C.; BIENIAS, Julia L.; EVANS, Denis A.; et al. Validity and reproducibility of a food frequency questionnaire by cognition in an older biracial sample. American journal of epidemiology, 158. 12 (2003): 1213-1217. Oxford University Press

Olkin, I., {\&}amp; Siotani, M. (1976). Asymptotic distribution of functions of a correlation matrix. In S. Ideka (Ed.), Essays in probability and statistics ( pp. 235-251). Tokyo: Shinko Tsusho.

OLKIN, I; FINN, J D. CORRELATIONS REDUX. PSYCHOLOGICAL BULLETIN, 118. 1 (1995): 155-164. AMER PSYCHOLOGICAL ASSOC

OLKIN, I; FINN, J. TESTING CORRELATED CORRELATIONS. PSYCHOLOGICAL BULLETIN, 108. 2 (1990): 330-333. AMER PSYCHOLOGICAL ASSOC

OZER, D. J. Correlation and the coefficient of determination. Psychological bulletin, 97. 2 (1985): 307-315. American Psychological Association

Pearson, K. Mathematical Contributions to the Theory of Evolution. On the Law of Ancestral Heredity. Proceedings of the Royal Society., LXII. (1898): 386-413

Raghunathan, T. E.; Rosenthal, Robert; Rubin, Donald B. Comparing correlated but nonoverlapping correlations. Psychological Methods, 1. 2 (1996): 178-183. American Psychological Association

Rao, Calyampudi Radhakrishna. Linear statistical inference and its applications. Linear statistical inference and its applications. (1965): xviii, 522. John Wiley {\&}amp; Sons Inc

ROBEY, R. R.; BARCIKOWSKI, R. S. Type I error and the number of iterations in Monte Carlo studies of robustness. British journal of mathematical {\&}amp; statistical psychology, 45. 2 (1992): 283-288. British Psychological Society

RODGERS, J. L.; NICEWANDER, W. A. Thirteen ways to look at the correlation coefficient. The American statistician, 42. 1 (1988): 59-66. American Statistical Association

ROTHMAN, K J. SIGNIFICANCE QUESTING. ANNALS OF INTERNAL MEDICINE, 105. 3 (1986): 445-447. AMER COLL PHYSICIANS

ROVINE, M. J.; VON EYE, A. A 14th way to look at a correlation coefficient : Correlation as the proportion of matches. The American statistician, 51. 1 (1997): 42-46. American Statistical Association

Rozeboom, William W. The fallacy of the null-hypothesis significance test. Psychological Bulletin, 57. 5 (1960): 416-428. American Psychological Association; Psychological Review Company; The Macmillan Company; The Review Publishing Company

SCHENKER, Nathaniel; GENTLEMAN, Jane F. On judging the significance of differences by examining the overlap between confidence intervals. The American statistician, 55. 3 (2001): 182-186. American Statistical Association

SCHENKER, N. Qualms about bootstrap confidence intervals. Journal of the American Statistical Association, 80. 390 (1985): 360-361. American Statistical Association

Schmidt, F. L., {\&}amp; Hunter, J. E. (1997). Eight common but false objections to the discontinuation of significance testing in the analysis of research data. In L. L. Harlow, S. A. Mulaik, {\&}amp; J. H. Steiger (Eds.), What if there were no significance tests? (pp. 37-64). Mahwah NJ: Erlbaum.

Schmidt, Frank L. Statistical significance testing and cumulative knowledge in psychology: Implications for training of researchers. Psychological Methods, 1. 2 (1996): 115-129. American Psychological Association

Schmidt, Elaine. The march of the century `The Stars and Stripes Forever' was Sousa's masterpiece; If you go What: Keith Brion's New Sousa Band When: 3 p.m. Sunday Where: Pabst Theater, 144 E. Wells St. Tickets: {\$}20, {\$}15 and {\$}10; half-price for children 14 and under. Call 286-3663. ------------ Freelance writer Elaine Schmidt is a professional flutist who has played the piccolo solo in {\&}quot;Stars and Stripes Forever{\&}quot; more times than she can remember. Milwaukee Journal Sentinel (1997): 1

Shao, Jun; Tu, Dongsheng. The jackknife and bootstrap. (1995): xvii, 516. Series in Statistics. New York; Heidelberg and London: Springer

Silver, N. Clayton; Hittner, James B.; May, Kim. A FORTRAN 77 program for comparing dependent correlations. Applied Psychological Measurement, 30. 2 (2006): 152-153. SAGE Publications Inc

Steiger, J. H. (1980). Tests for comparing elements of a correlation matrix. Psychological Bulletin, 87, 245-251.1980-08757-00110.1037/0033-2909.87.2.245

STEIGER, J H; FOULADI, R T. R2 - A COMPUTER-PROGRAM FOR INTERVAL ESTIMATION, POWER CALCULATIONS, SAMPLE-SIZE ESTIMATION, AND HYPOTHESIS-TESTING IN MULTIPLE-REGRESSION. BEHAVIOR RESEARCH METHODS INSTRUMENTS {\&}amp; COMPUTERS, 24. 4 (1992): 581-582. PSYCHONOMIC SOC INC

STRIGER, J. H.; WARD, L. M. Factor analysis and the coefficient of determination. Psychological bulletin, 101. 3 (1987): 471-474. American Psychological Association

Wilkinson, L; Task Force Stat Inference. Statistical methods in psychology journals - Guidelines and explanations. AMERICAN PSYCHOLOGIST, 54. 8 (1999): 594-604. AMER PSYCHOLOGICAL ASSOC

XIAO-LI MENG; ROSENTHAL, R.; RUBIN, D. B. Comparing correlated correlation coefficients. Psychological bulletin, 111. 1 (1992): 172-175. American Psychological Association

YOUNG, G A. BOOTSTRAP - MORE THAN A STAB IN THE DARK. STATISTICAL SCIENCE, 9. 3 (1994): 382-395. INST MATHEMATICAL STATISTICS},
author = {Zou, Guang Yong},
doi = {http://dx.doi.org/10.1037/1082-989X.12.4.399},
file = {:C$\backslash$:/Users/eribu/Downloads/met{\_}12{\_}4{\_}399.pdf.pdf:pdf},
issn = {1082-989X},
journal = {Psychological Methods},
keywords = {2200:Psychometrics {\&} Statistics {\&} Methodology,Confidence Limits (Statistics),Hypothesis Testing,Multiple Regression,Psychology,Statistical Correlation,article,article1,bootstrap,coefficient of determination,confidence interval,correlations,hypothesis testing,multiple regression},
language = {English},
mendeley-tags = {article1},
number = {4},
pages = {399--413},
publisher = {American Psychological Association},
title = {{Toward using confidence intervals to compare correlations.}},
url = {http://search.proquest.com/docview/614482873?accountid=11162 http://www.ub.gu.se/dynamiskt/cgi-bin/link{\_}resolver/link{\_}resolver.cgi?url{\_}ver=Z39.88-2004{\&}rft{\_}val{\_}fmt=info:ofi/fmt:kev:mtx:journal{\&}genre=article{\&}sid=ProQ:ProQ{\%}3Apsycarticles{\&}atitle=Toward+using+},
volume = {12},
year = {2007}
}
@techreport{Walck2007,
abstract = {Internal Report SUF-PFY/96-01 Stockholm (Handbook)},
author = {Walck, Christian},
booktitle = {Hand-book on STATISTICAL DISTRIBUTIONS for experimentalists},
file = {:C$\backslash$:/Users/eribu/Downloads/DistributionsHandbook.pdf:pdf},
isbn = {<null>},
issn = {<null>},
keywords = {article1},
mendeley-tags = {article1},
title = {{Hand-book on STATISTICAL DISTRIBUTIONS for experimentalists}},
url = {http://www.stat.rice.edu/{~}dobelman/textfiles/DistributionsHandbook.pdf},
year = {2007}
}
@article{Isaksson2008,
abstract = {The interest in statistical classification for critical applications such as diagnoses of patient samples based on supervised learning is rapidly growing. To gain acceptance in applications where the subsequent decisions have serious consequences, e.g. choice of cancer therapy, any such decision support system must come with a reliable performance estimate. Tailored for small sample problems, cross-validation (CV) and bootstrapping (BTS) have been the most commonly used methods to determine such estimates in virtually all branches of science for the last 20 years. Here, we address the often overlooked fact that the uncertainty in a point estimate obtained with CV and BTS is unknown and quite large for small sample classification problems encountered in biomedical applications and elsewhere. To avoid this fundamental problem of employing CV and BTS, until improved alternatives have been established, we suggest that the final classification performance always should be reported in the form of a Bayesian confidence interval obtained from a simple holdout test or using some other method that yields conservative measures of the uncertainty. ?? 2008 Elsevier B.V. All rights reserved.},
author = {Isaksson, A. and Wallman, M. and G??ransson, H. and Gustafsson, M. G.},
doi = {10.1016/j.patrec.2008.06.018},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Isaksson et al. - 2008 - Cross-validation and bootstrapping are unreliable in small sample classification.pdf:pdf},
isbn = {01678655},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Confidence interval,Performance estimation,Supervised classification,article1},
mendeley-tags = {article1},
title = {{Cross-validation and bootstrapping are unreliable in small sample classification}},
year = {2008}
}
@article{Hossjer2008,
abstract = {For mixed regression models, we define a variance decomposition including three terms, explained individual variance, unexplained individual variance and noise variance. In contrast to traditional variance decomposition, it is thus the unexplained, not the explained, variance that is split. It gives rise to a coefficient of individual determination (CID) defined as the estimated fraction of explained individual variance. We argue that in many applications CID is a valuable complement to R2, since it excludes noise variance (which can never be explained) and thus has one as a natural upper bound. A general theory for coefficients determination is presented, including various choices of regression models, weight functions and parameter estimates. In particular we focus on models where CID is computable, such as univariate mixed Poisson and logistic regression models, as well as multivariate mixed linear regression models. Large sample properties and confidence intervals are derived and finally, the theory is exemplified using Poisson regression on a Swedish motor traffic insurance data set. © 2007 Elsevier B.V. All rights reserved.},
author = {H{\"{o}}ssjer, Ola},
doi = {10.1016/j.jspi.2007.11.010},
file = {:C$\backslash$:/Users/eribu/Downloads/1-s2.0-S0378375807004107-main.pdf:pdf},
isbn = {0378-3758},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Coefficient of determination,Explained variance,Individual variance,Mixed regression models,Noise variance,Variance decomposition,article1},
mendeley-tags = {article1},
number = {10},
pages = {3022--3038},
title = {{On the coefficient of determination for mixed regression models}},
volume = {138},
year = {2008}
}
@article{Shieh2008a,
author = {Shieh, Gwowen},
file = {:C$\backslash$:/Users/eribu/Downloads/Organizational Research Methods-2008-Shieh-387-407.pdf:pdf},
journal = {Organizational Research Methods},
keywords = {article1,as fixed and known,bias,explanatory variables are treated,maximum likelihood estimator,mean square error,multiple linear regres-,one of the most,shrinkage estimator,sion,statistical methods,the values of the,traditionally,ultiple regression analysis is,widely used of all},
mendeley-tags = {article1},
number = {2},
pages = {387--407},
title = {{Improved Shrinkage Estimation of Squared Multiple Correlation Coefficient and Squared Cross-Validity Coefficient}},
volume = {11},
year = {2008}
}
@article{Baharev2008,
abstract = {Unfortunately many of the numerous algorithms for computing the comulative distribution function (cdf) and noncentrality parameter of the noncentral F and beta distributions can produce completely incorrect results as demonstrated in the paper by examples. Existing algorithms are scrutinized and those parts that involve numerical difficulties are identified. As a result, a pseudo code is presented in which all the known numerical problems are resolved. This pseudo code can be easily implemented in programming language C or FORTRAN without understanding the complicated mathematical background.},
author = {Baharev, Ali and Kem{\'{e}}ny, S{\'{a}}ndor},
doi = {10.1007/s11222-008-9061-3},
file = {:C$\backslash$:/Users/eribu/Downloads/ncbeta.pdf:pdf},
issn = {1573-1375},
journal = {Statistics and Computing},
keywords = {article1},
mendeley-tags = {article1},
number = {3},
pages = {333--340},
title = {{On the computation of the noncentral F and noncentral beta distribution}},
url = {http://dx.doi.org/10.1007/s11222-008-9061-3},
volume = {18},
year = {2008}
}
@article{Nemes2009,
abstract = {BACKGROUND: In epidemiological studies researchers use logistic regression as an analytical tool to study the association of a binary outcome to a set of possible exposures.$\backslash$n$\backslash$nMETHODS: Using a simulation study we illustrate how the analytically derived bias of odds ratios modelling in logistic regression varies as a function of the sample size.$\backslash$n$\backslash$nRESULTS: Logistic regression overestimates odds ratios in studies with small to moderate samples size. The small sample size induced bias is a systematic one, bias away from null. Regression coefficient estimates shifts away from zero, odds ratios from one.$\backslash$n$\backslash$nCONCLUSION: If several small studies are pooled without consideration of the bias introduced by the inherent mathematical properties of the logistic regression model, researchers may be mislead to erroneous interpretation of the results.},
author = {Nemes, Szilard and Jonasson, Junmei Miao and Genell, Anna and Steineck, Gunnar},
doi = {10.1186/1471-2288-9-56},
file = {:C$\backslash$:/Users/eribu/Downloads/art{\%}3A10.1186{\%}2F1471-2288-9-56.pdf:pdf},
isbn = {1471-2288 (Electronic)$\backslash$r1471-2288 (Linking)},
issn = {1471-2288},
journal = {BMC medical research methodology},
keywords = {Bias (Epidemiology),Computer Simulation,Female,Humans,Logistic Models,Models,Odds Ratio,Pregnancy,Sample Size,Statistical,article1,bredvidlasning},
mendeley-tags = {article1,bredvidlasning},
pages = {56},
pmid = {19635144},
title = {{Bias in odds ratios by logistic regression modelling and sample size.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2724427{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {9},
year = {2009}
}
@article{Hafdahl2009,
abstract = {In 2 Monte Carlo studies of fixed- and random-effects meta-analysis for correlations, A. P. Field (2001) ostensibly evaluated Hedges-Olkin-Vevea Fisher-z and Schmidt-Hunter Pearson-r estimators and tests in 120 conditions. Some authors have cited those results as evidence not to meta-analyze Fisher-z correlations, especially with heterogeneous correlation parameters. The present attempt to replicate Field's simulations included comparisons with analytic values as well as results for efficiency and confidence-interval coverage. Field's results under homogeneity were mostly replicable, but those under heterogeneity were not: The latter exhibited up to over .17 more bias than ours and, for tests of the mean correlation and homogeneity, respectively, nonnull rejection rates up to .60 lower and .65 higher. Changes to Field's observations and conclusions are recommended, and practical guidance is offered regarding simulation evidence and choices among methods. Most cautions about poor performance of Fisher-z methods are largely unfounded, especially with a more appropriate z-to-r transformation. The Appendix gives a computer program for obtaining Pearson-r moments from a normal Fisher-z distribution, which is used to demonstrate distortion due to direct z-to-r transformation of a mean Fisher-z correlation.},
author = {Hafdahl, Adam R and Williams, Michelle a},
doi = {10.1037/a0014697},
file = {:C$\backslash$:/Users/eribu/Downloads/Hafdahl{\_}2009.pdf:pdf},
isbn = {1082-989X$\backslash$n1939-1463},
issn = {1082-989X},
journal = {Psychological methods},
keywords = {10,1037,a0014697,article1,decades,doi,during the past 3,dx,fisher,http,meta-analysis,meta-analysis has become a,monte carlo simulation,org,random effects,s z transformation,supp,supplemental materials,validity generalization},
mendeley-tags = {article1},
number = {1},
pages = {24--42},
pmid = {19271846},
title = {{Meta-analysis of correlations revisited: attempted replication and extension of Field's (2001) simulation studies.}},
volume = {14},
year = {2009}
}
@article{Shieh2009,
abstract = {In regression analysis, the notion of population validity is of theoretical interest for describing the usefulness of the underlying regression model, whereas the presumably more important concept of population cross-validity represents the predictive effectiveness for the regression equation in future research. It appears that the inference procedures of the squared multiple correlation coefficient have been extensively developed. In contrast, a full range of statistical methods for the analysis of the squared cross-validity coefficient is considerably far from complete. This article considers a distinct expression for the definition of the squared cross-validity coefficient as the direct connection and monotone transformation to the squared multiple correlation coefficient. Therefore, all the currently available exact methods for interval estimation, power calculation, and sample size determination of the squared multiple correlation coefficient are naturally modified and extended to the analysis of the squared cross-validity coefficient. The adequacies of the existing approximate procedures and the suggested exact method are evaluated through a Monte Carlo study. Furthermore, practical applications in areas of psychology and management are presented to illustrate the essential features of the proposed methodologies. The first empirical example uses 6 control variables related to driver characteristics and traffic congestion and their relation to stress in bus drivers, and the second example relates skills, cognitive performance, and personality to team performance measures. The results in this article can facilitate the recommended practice of cross-validation in psychological and other areas of social science research. (Contains 2 figures and 8 tables.)},
author = {Shieh, Gwowen},
doi = {10.1080/00273170802620097},
file = {:C$\backslash$:/Users/eribu/Downloads/Exact Analysis of Squared Cross Validity Coefficient in Predictive Regression Models.pdf:pdf},
isbn = {0027-3171},
issn = {0027-3171},
journal = {Multivariate Behavioral Research},
keywords = {article1},
mendeley-tags = {article1},
number = {1},
pages = {82--105},
pmid = {263268700004},
title = {{Exact Analysis of Squared Cross-Validity Coefficient in Predictive Regression Models}},
url = {http://libweb.ben.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=eric{\&}AN=EJ827871{\&}site=ehost-live{\&}scope=cite},
volume = {44},
year = {2009}
}
@article{Gorsuch2010,
abstract = {Non-zero correlation coefficients have non-normal distributions, affecting both means and standard deviations. Previous research suggests that z transformation may effectively correct mean bias for N's less than 30. In this study, simulations with small (20 and 30) and large (50 and 100) N's found that mean bias adjustments for larger N's are seldom needed. However, z transformations improved confidence intervals even for N = 100. The improvement was not in the estimated standard errors so much as in the asymmetrical CI's estimates based upon the z transformation. The resulting observed probabilities were generally accurate to within 1 point in the first non-zero digit. These issues are an order of magnitude less important for accuracy than design issues influencing the accuracy of the results, such as reliability, restriction of range, and N. Keywords: Confidence intervals; Correlation coefficient; Fisher’s z transformation; Monte Carlo study; Mean bias in correlation coefficients},
author = {Gorsuch, Rl and Lehmann, Cs},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gorsuch, Lehmann - 2010 - Correlation Coefficients Mean Bias and Confidence Interval Distortions.pdf:pdf},
issn = {2159-7855},
journal = {Journal of Methods and Measurement in the Social Sciences},
keywords = {article1,because the distribution of,coefficients,confidence intervals,correlation coefficient,estimate the population correlation,fisher,is known to slightly,mean bias in correlation,monte carlo,r,r is,s z transformation,study,the observed correlation coefficient,under,$\rho$},
mendeley-tags = {article1},
number = {2},
pages = {52--65},
title = {{Correlation Coefficients: Mean Bias and Confidence Interval Distortions}},
url = {https://journals.uair.arizona.edu/index.php/jmmss/article/download/114/118},
volume = {1},
year = {2010}
}
@article{Renaud2010,
abstract = {To assess the quality of the fit in a multiple linear regression, the coefficient of determination or R2 is a very simple tool, yet the most used by practitioners. Indeed, it is reported in most statistical analyzes, and although it is not recommended as a final model selection tool, it provides an indication of the suitability of the chosen explanatory variables in predicting the response. In the classical setting, it is well known that the least-squares fit and coefficient of determination can be arbitrary and/or misleading in the presence of a single outlier. In many applied settings, the assumption of normality of the errors and the absence of outliers are difficult to establish. In these cases, robust procedures for estimation and inference in linear regression are available and provide a suitable alternative. In this paper we present a companion robust coefficient of determination that has several desirable properties not shared by others. It is robust to deviations from the specified regression model (like the presence of outliers), it is efficient if the errors are normally distributed, it does not make any assumption on the distribution of the explanatory variables (and therefore no assumption on the unconditional distribution of the responses). We also show that it is a consistent estimator of the population coefficient of determination. A simulation study and two real datasets support the appropriateness of this estimator, compared with classical (least-squares) and several previously proposed robust R2, even for small sample sizes. © 2010 Elsevier B.V. All rights reserved.},
author = {Renaud, Olivier and Victoria-Feser, Maria Pia},
doi = {10.1016/j.jspi.2010.01.008},
file = {:C$\backslash$:/Users/eribu/Downloads/1-s2.0-S0378375810000194-main.pdf:pdf},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Consistency,Correlation,Efficiency,Outliers,R-squared,article1},
mendeley-tags = {article1},
number = {7},
pages = {1852--1862},
title = {{A robust coefficient of determination for regression}},
volume = {140},
year = {2010}
}
@article{Shieh2010,
abstract = {This article investigates some unfamiliar properties of the Pearson product-moment correlation coefficient for the estimation of simple correlation coefficient. Although Pearson's r is biased, except for limited situations, and the minimum variance unbiased estimator has been proposed in the literature, researchers routinely employ the sample correlation coefficient in their practical applications, because of its simplicity and popularity. In order to support such practice, this study examines the mean squared errors of r and several prominent formulas. The results reveal specific situations in which the sample correlation coefficient performs better than the unbiased and nearly unbiased estimators, facilitating recommendation of r as an effect size index for the strength of linear association between two variables. In addition, related issues of estimating the squared simple correlation coefficient are also considered.},
author = {Shieh, Gwowen},
doi = {10.3758/BRM.42.4.906},
file = {:C$\backslash$:/Users/eribu/Downloads/000287537100002.pdf:pdf},
isbn = {1554-3528 (Electronic)$\backslash$r1554-351X (Linking)},
issn = {1554-351X},
journal = {Behavior research methods},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {4},
pages = {906--917},
pmid = {21139158},
title = {{Estimation of the simple correlation coefficient.}},
volume = {42},
year = {2010}
}
@article{distrMod,
author = {Kohl, Matthias and Ruckdeschel, Peter},
doi = {10.1002/wics.10},
file = {:C$\backslash$:/Users/eribu/Downloads/distrMod.pdf:pdf},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {article1,maximum likelihood estimators,minimum criterion estimators,minimum distance estimators,probability models,s4 classes,s4 methods},
mendeley-tags = {article1},
number = {10},
pages = {1--27},
title = {{R Package distrMod: S4 Classes and Methods for Probability Models}},
volume = {35},
year = {2010}
}
@article{Skidmore2011,
annote = {stj{\"{a}}rnmarkerad d{\aa} uppl{\"{a}}gget f{\"{o}}r studien {\"{a}}r v{\"{a}}ldigt lik v{\aa}r. Dock har det sedan visat sig att det f{\"{o}}reslagna resultatet inte var s{\aa} bra som man hoppades.},
author = {Skidmore, Susan Troncoso and Thompson, Bruce},
doi = {10.1080/00220973.2010.484437},
file = {:C$\backslash$:/Users/eribu/Downloads/Choosing the Best Correction Formula for the Pearson r 2Effect Size.pdf:pdf},
issn = {0022-0973},
journal = {The Journal of Experimental Education},
keywords = {article1},
mendeley-tags = {article1},
number = {3},
pages = {257--278},
title = {{Choosing the Best Correction Formula for the Pearson r 2 Effect Size}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00220973.2010.484437},
volume = {79},
year = {2011}
}
@article{Mukaka2012,
abstract = {Correlation is a statistical method used to assess a possible linear association between two continuous variables. It is simple both to calculate and to interpret. However, misuse of correlation is so common among researchers that some statisticians have wished that the method had never been devised at all. The aim of this article is to provide a guide to appropriate use of correlation in medical research and to highlight some misuse. Examples of the applications of the correlation coefficient have been provided using data from statistical simulations as well as real data. Rule of thumb for interpreting size of a correlation coefficient has been provided.},
author = {Mukaka, M. M.},
file = {:C$\backslash$:/Users/eribu/Downloads/MMJ2403-0069.pdf:pdf},
issn = {19957262},
journal = {Malawi Medical Journal},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {3},
pages = {69--71},
pmid = {23638278},
title = {{Statistics corner: A guide to appropriate use of correlation coefficient in medical research}},
volume = {24},
year = {2012}
}
@article{fitdistrplus,
abstract = {The package fitdistrplus provides functions for fitting univariate distributions to different types of data (continuous censored or non-censored data and discrete data) and allowing different estimation methods (maximum likelihood, moment matching, quantile matching and maximum goodness-of-fit estimation). Outputs of fitdist and fitdistcens functions are S3 objects, for which kind generic methods are provided, including summary, plot and quantile. This package also provides various functions to compare the fit of several distributions to a same data set and can handle bootstrap of parameter estimates. Detailed examples are given in food risk assessment, ecotoxicology and insurance contexts.},
author = {Delignette-muller, Marie Laure and Dutang, Christophe},
doi = {10.18637/jss.v064.i04},
file = {:C$\backslash$:/Users/eribu/Downloads/paper2JSS.pdf:pdf},
isbn = {9781420065213},
issn = {1548-7660},
journal = {Journal of Statistical Software},
keywords = {article1,bootstrap,censored data,distributions,maximum goodness-of-fit,maximum likelihood,moment matching,probability distribution fitting,quantile matching,r},
mendeley-tags = {article1},
number = {4},
pages = {1--34},
title = {{fitdistrplus : An R Package for Fitting Distributions}},
volume = {64},
year = {2015}
}
