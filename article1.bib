@article{Pearson1896,
author = {Pearson, Karl},
file = {:C$\backslash$:/Users/eribu/Downloads/Proc. R. Soc. Lond.-1896-Pearson-489-98.pdf:pdf},
journal = {Proceedings of the royal society of london},
keywords = {article1},
mendeley-tags = {article1},
number = {359-397},
pages = {489--498},
title = {{Mathematical Contributions to the Theory of Evolution.--On a Form of Spurious Correlation Which May Arise When Indices Are Used in the Measurement of Organs}},
volume = {60},
year = {1896}
}
@article{Student1908,
abstract = {His question was answered by Messrs Yule and Hooker and Professor Edgeworth, all of whom considered that Mr Hooker was probably safe in taking'HO as his limit of significance for a sample of 21. They did not, however, answer Dr Shaw's question in any more ...},
author = {Student},
file = {:C$\backslash$:/Users/eribu/Downloads/student1908.pdf:pdf},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {2-3},
pages = {302--310},
title = {{Probable Error of a Correlation Coefficient}},
url = {http://biomet.oxfordjournals.org/cgi/doi/10.1093/biomet/6.2-3.302 papers2://publication/doi/10.1093/biomet/6.2-3.302},
volume = {6},
year = {1908}
}
@article{Soper1913,
author = {Soper, H. E.},
doi = {10.1093/biomet/9.1-2.91},
file = {:C$\backslash$:/Users/eribu/Downloads/2331802.pdf:pdf},
issn = {00063444},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {1-2},
pages = {91--115},
title = {{On the peobable error of the correlation coefficient to a second approximation}},
volume = {9},
year = {1913}
}
@article{Fisher1915,
abstract = {508 Distribution of the Correlation Coeffeients of Samples In the second of these two papers the more difficult problem of the frequency distribution of the correlation coefficient is attempted. For samples of 2 the frequency},
author = {Fisher, R.a. and Fisher, R.a.},
doi = {10.2307/2331838},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fisher, Fisher - 1915 - Frequency distribution of the values of the correlation coefficient in samples from an indefinitely large popula.pdf:pdf},
isbn = {0006-3444},
issn = {00063444},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {507--521},
title = {{Frequency distribution of the values of the correlation coefficient in samples from an indefinitely large population}},
url = {http://biomet.oxfordjournals.org/cgi/reprint/10/4/507.pdf},
volume = {10},
year = {1915}
}
@article{Coop1916,
author = {{Soper, HE and Young, AW and Cave, BM and Lee, Alice and Pearson}, Karl},
file = {:C$\backslash$:/Users/eribu/Downloads/2331830.pdf:pdf},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {328--413},
title = {{On the Distribution of the Correlation Coefficient in Small Samples. Appendix II to the Papers of "Student" and R. A. Fisher}},
volume = {11},
year = {1916}
}
@misc{Fisher1921,
abstract = {This is the second of three papers dealing with the sampling errors of correlation coefficients covering the cases (i) "The frequency distribution of the values of the correlation coeffricient in samples from an indefinitely large population", Biometrika, 1915.},
author = {Fisher, R A},
booktitle = {Metron},
file = {:C$\backslash$:/Users/eribu/Downloads/14.pdf:pdf},
keywords = {article1},
mendeley-tags = {article1},
number = {1-32},
pages = {205--235},
title = {{On the probable error of a coefficient of correlation deduced from a small samlpe}},
volume = {1},
year = {1921}
}
@misc{Fisher1924,
abstract = {Reproduced with permission of Metron 35 THE DISTRIBUTION OF THE PARTIAL CORRELATION COEFFICIENT .1. The theoretical . distribution In ascertaining the exact distribution iu random samples to which the correlation coefficient between two normally distributed vari{\^{a}}tes is ...},
author = {Fisher, R a},
booktitle = {Metron},
file = {:C$\backslash$:/Users/eribu/Downloads/35.pdf:pdf},
keywords = {article1},
mendeley-tags = {article1},
number = {3-4},
pages = {329--332},
title = {{The distribution of the partial correlation coefficient}},
volume = {3},
year = {1924}
}
@article{Ezekei1929,
author = {Ezekei, Mordecai},
file = {:C$\backslash$:/Users/eribu/Downloads/2277015.pdf:pdf},
isbn = {0521773628},
journal = {Journal of the American Statistical Association},
keywords = {article1},
mendeley-tags = {article1},
number = {165},
pages = {99--104},
title = {{The Application of the Theory of Error to Multiple and Curvilinear Correlation}},
volume = {24},
year = {1929}
}
@article{Larson1931,
abstract = {A study is made, on 800 cases, of the shrinkage attendant upon using a regression equation derived from one group to predict the criterion scores of a second group. It is found that "the theoretically expected shrinkage of R as derived by the multiple correlation formula is a fact." The shrinkage increases as the number of variables increases and as the size of R decreases. The Smith formula for shrinkage-deduction parallels the empirical findings, but consistently yields higher values. The results upon increase in number of test variables suggest that test batteries may have definite limitations in size. (PsycINFO Database Record (c) 2006 APA, all rights reserved). © 1931 American Psychological Association.},
author = {Larson, S C},
doi = {10.1037/h0072400},
file = {:C$\backslash$:/Users/eribu/Downloads/edu{\_}22{\_}1{\_}45.pdf.pdf:pdf},
issn = {00220663 (ISSN)},
journal = {Journal of Educational Psychology},
keywords = {BIOMETRY AND STATISTICS,CORRELATION, MULTIPLE, SHRINKAGE,MULTIPLE,SHRINKAGE,article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {1},
pages = {45--55},
title = {{The shrinkage of the coefficient of multiple correlation}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0007318509{\&}partnerID=40{\&}md5=dc19e2f8fac696f27cb88e10bc8d38fe},
volume = {22},
year = {1931}
}
@article{Wherry1931,
abstract = {44¿ hORMULA POR (6) ?*.< *>' » егог NM and since 2 , by (2) above, we have s0 equa we have {\^{}} (7) -г f N(lt?z) f i-p2 1 N equal to (1 - {\^{}} 2 ), which is, exactly, the BB Smith (1). This has been widely used during the last few},
author = {Wherry, R},
file = {:C$\backslash$:/Users/eribu/Downloads/2957681.pdf:pdf},
journal = {The annals of mathematical statistics},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {4},
pages = {440--457},
title = {{A new formula for predicting the shrinkage of the coefficient of multiple correlation}},
url = {http://www.jstor.org/stable/2957681$\backslash$npapers2://publication/uuid/F3D4916B-BB98-4094-A459-DF4387AC9610},
volume = {2},
year = {1931}
}
@article{Nair1941,
author = {Nair, A N Krishnan},
file = {:C$\backslash$:/Users/eribu/Downloads/ref{\_}till{\_}coop1916/25047705.pdf:pdf},
journal = {The Indian Journal of Statistics},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {383--400},
title = {{Distribution of Students 't' and the Correlation Coefficient in Samples from Non-Normal Populations}},
volume = {5},
year = {1941}
}
@article{Gayen1951,
author = {Gayen, A. K.},
file = {:C$\backslash$:/Users/eribu/Downloads/2332329.pdf:pdf},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {1/2},
pages = {219--247},
title = {{The Frequency Distribution of the Product-Moment Correlation Coefficient in Random Samples of Any Size Drawn from Non-Normal Universes}},
volume = {38},
year = {1951}
}
@article{Cowden1952,
abstract = {Abstract A partial correlation coefficient which is also a multiple correlation coefficient is discussed. Its relationship with other well-known coefficients is explained. Computational methods for computing the estimating equation and the correlation coefficient are suggested. * The writer wishes to thank Professors Harold Hotelling, George E. Nicholson, and John H. Smith for critically reading the manuscript and offering valuable comments. Professor Hotelling indicated the method of computation which he had suggested in an unpublished paper (see note 5). Professor Smith called the writer's attention to some of the earlier references to the subject in the literature. Since the first draft of this paper was written (June, 1951), it has been learned that Professor C. Horace Hamilton, of the North Carolina State College of Agriculture and Engineering, has written an article entitled ?Population Pressure and Other Factors Affecting Net Rural-Urban Migration,? in which the coefficient of multiple-partial correlation is used. This article appears in Social Forces, 30 (December, 1951), pp. 209?15. The formula used is that attributed by the present writer to John H. Smith (see note 7.)$\backslash$nAbstract A partial correlation coefficient which is also a multiple correlation coefficient is discussed. Its relationship with other well-known coefficients is explained. Computational methods for computing the estimating equation and the correlation coefficient are suggested. * The writer wishes to thank Professors Harold Hotelling, George E. Nicholson, and John H. Smith for critically reading the manuscript and offering valuable comments. Professor Hotelling indicated the method of computation which he had suggested in an unpublished paper (see note 5). Professor Smith called the writer's attention to some of the earlier references to the subject in the literature. Since the first draft of this paper was written (June, 1951), it has been learned that Professor C. Horace Hamilton, of the North Carolina State College of Agriculture and Engineering, has written an article entitled ?Population Pressure and Other Factors Affecting Net Rural-Urban Migration,? in which the coefficient of multiple-partial correlation is used. This article appears in Social Forces, 30 (December, 1951), pp. 209?15. The formula used is that attributed by the present writer to John H. Smith (see note 7.)},
author = {Cowden, Dudley J.},
doi = {10.1080/01621459.1952.10501183},
file = {:C$\backslash$:/Users/eribu/Downloads/2281314.pdf:pdf},
isbn = {01621459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {259},
pages = {442--456},
title = {{The Multiple-Partial Correlation Coefficient}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1952.10501183},
volume = {47},
year = {1952}
}
@article{Hotelling1953,
author = {Hotelling, Harold},
file = {:C$\backslash$:/Users/eribu/Downloads/2983768.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series B (Methodological),},
keywords = {article1},
mendeley-tags = {article1},
number = {2},
pages = {296--193--232},
title = {{New Light on the Correlation Coefficient and its Transforms Author(s): Harold Hotelling}},
volume = {15},
year = {1953}
}
@article{Olkin1958,
abstract = {This paper deals with the unbiased estimation of the correlation of two variates having a bivariate normal distribution (Sec. 2), and of the intraclass correlation, i.e., the common correlation coefficient of a {\$}p{\$}-variate normal distribution with equal variances and equal covariances (Sec. 3). In both cases, the estimator has the following properties. It is a function of a complete sufficient statistic and is therefore the unique (except for sets of probability zero) minimum variance unbiased estimator. Its range is the region of possible values of the estimated quantity. It is a strictly increasing function of the usual estimator differing from it only by terms of order {\$}1/n{\$} and consequently having the same asymptotic distribution. Since the unbiased estimators are cumbersome in form in that they are expressed as series or integrals, tables are included giving the unbiased estimators as functions of the usual estimators. In Sec. 4 we give an unbiased estimator of the squared multiple correlation. It ha...},
author = {Olkin, Ingram and Pratt, J.W.},
doi = {10.2307/2237306},
file = {:C$\backslash$:/Users/eribu/Downloads/2237306.pdf:pdf},
issn = {00034851},
journal = {The annals of mathematical statistics},
keywords = {article1},
mendeley-tags = {article1},
number = {1},
pages = {201--211},
title = {{Unbiased estimation of certain correlation coefficients}},
url = {http://www.jstor.org/pss/2237306$\backslash$nhttp://www.jstor.org/stable/10.2307/2237306},
volume = {29},
year = {1958}
}
@article{Seber1963,
author = {Seber, G A F},
file = {:C$\backslash$:/Users/eribu/Downloads/Seber1963.pdf:pdf},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {3},
pages = {542--544},
title = {{The Non-Central Chi-Squared and Beta Distributions}},
volume = {50},
year = {1963}
}
@article{Ruben1966,
author = {Ruben, Harold},
file = {:C$\backslash$:/Users/eribu/Downloads/2984445.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series B (Methodological),},
keywords = {article1},
mendeley-tags = {article1},
number = {3},
pages = {513--525},
title = {{Some New Results on the Coefficient of the Sample Correlation Distribution}},
volume = {28},
year = {1966}
}
@article{Bartko1966,
abstract = {Discusses a procedure for estimating the reliability of sets of ratings in terms of the intraclass correlation coefficient, based upon analysis of variance and estimation of variance components. For the 1-way classification the intraclass correlation coefficient defined as the ratio of variances can be interpreted as a correlation coefficient. Caution, however, is urged in the application of the definition to a 2-way model, i.e., one in which between-rater variance is removed. It is maintained that the frequent use of the standard definition of the 1-way intraclass correlation coefficient applied to the 1-way classification is not a proper procedure if in fact the coefficient is to be interpreted as a correlation coefficient. Definitions for reliability obtained from the 2-way models are given which can legitimately be considered correlation coefficients. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
author = {Bartko, J J},
doi = {10.2466/pr0.1966.19.1.3},
isbn = {0031-5125},
issn = {0033-2941},
journal = {Psychological reports},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {1},
pages = {3--11},
pmid = {5942109},
title = {{The intraclass correlation coefficient as a measure of reliability.}},
volume = {19},
year = {1966}
}
@article{Hogben1968,
author = {Hogben, David},
doi = {10.6028/jres.072B.007},
file = {:C$\backslash$:/Users/eribu/Downloads/jresv72Bn1p33{\_}A1b.pdf:pdf},
issn = {0098-8979},
journal = {Journal of Research of the National Bureau of Standards, Section B: Mathematical Sciences},
keywords = {anal ysis of variance,article1,calibrali on,co rrelation coeffi cie,degrees of free dom,di s-,e,fix ed vari abl,nonce ntral beta variabl,noncentrality,nt,q variate,tribution},
mendeley-tags = {article1},
number = {1},
pages = {33},
title = {{The distribution of the sample correlation coefficient with one variable fixed}},
volume = {72B},
year = {1968}
}
@article{Society2013,
author = {Kymn, Kern O .},
file = {:C$\backslash$:/Users/eribu/Downloads/1909612.pdf:pdf},
journal = {Econometrica},
keywords = {article1},
mendeley-tags = {article1},
number = {1},
pages = {187--189},
title = {{The Distribution of the Sample Correlation Coefficient Under the Null Hypothesis}},
volume = {36},
year = {1968}
}
@article{Warren1971,
abstract = {A quantitative study is made of the bias in the usual estimate of the linear correlation coefficient and of the relative efficiency of the estimated regression, when a certain type of selective sampling is employed. A good compromise seems difficult to obtain and it is the author's thesis that the simultaneous presentation of regression equations and correlation coefficients is, in a sense, contradictory.},
author = {Warren, W. G.},
doi = {10.2307/2346463},
file = {:C$\backslash$:/Users/eribu/Downloads/2346463.pdf:pdf},
issn = {00359254},
journal = {Applied Statistics},
keywords = {article1},
mendeley-tags = {article1},
number = {2},
pages = {148},
title = {{Correlation or Regression: Bias or Precision}},
url = {http://www.jstor.org/stable/2346463$\backslash$nhttp://www.jstor.org/stable/10.2307/2346463?origin=crossref},
volume = {20},
year = {1971}
}
@article{Kowalski1972,
abstract = {Samples from non-normal bivariate distributions are simulated and the densities of the sample product-moment correlation coefficient, r, estimated and compared with the corresponding normal theory densities. The results are contrasted with the literature on the subject and an attempt is made to reconcile some of the earlier conflicting conclusions regarding the robustness of the distribution of r.},
author = {Kowalski, Charles J.},
doi = {10.2307/2346598},
file = {:C$\backslash$:/Users/eribu/Downloads/2346598.pdf:pdf},
issn = {00359254},
journal = {Journal of the Royal Statistical Society},
keywords = {article1,density estimation,distribution of correlation coefficient,non-normality,robustness,transformations},
mendeley-tags = {article1},
number = {1},
pages = {1--12},
title = {{On the Effects of Non-Normality on the Distribution of the Sample Product-Moment Correlation Coefficient}},
url = {http://www.jstor.org/stable/10.2307/2346598?origin=crossref},
volume = {21},
year = {1972}
}
@article{Barrett1974,
abstract = {Many scientists find the coefficient of determination (squared multiple correlation coefficient) a useful index in regression analyses. As with most indices, however, too much can be read into the coefficient of determination. Some scientists use it as a measure of “usefulness” or “goodness of fit” of a regression equation. Actuzlly the coefficient of determination only partially measures the usefulness of a regression equation; it also only partially measures goodness of fit in the sense of how close data points fit the regression surface. Examples are given illustrating the limits of the coefficient of determination and suggesting that graphs and confidence intervals me needed in a more complete evaluation of a regression equation.},
author = {Barrett, J P},
doi = {10.1080/00031305.1974.10479056},
isbn = {00031305},
issn = {0003-1305},
journal = {Am. Stat.},
keywords = {article1},
mendeley-tags = {article1},
pages = {19--20},
title = {{The coefficient of determination-some limitations}},
volume = {28},
year = {1974}
}
@article{Konishi1978,
author = {Konishi, Sandnori},
file = {:C$\backslash$:/Users/eribu/Downloads/2335923.pdf:pdf},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {3},
pages = {654--656},
title = {{An Approximation to the Distribution of the Sample Correlation Coefficient}},
volume = {65},
year = {1978}
}
@article{Claudy1978,
author = {Claudy, J. G.},
doi = {10.1177/014662167800200414},
file = {:C$\backslash$:/Users/eribu/Downloads/Applied Psychological Measurement-1978-Claudy-595-607.pdf:pdf},
issn = {0146-6216},
journal = {Applied Psychological Measurement},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {595--607},
title = {{Multiple Regression and Validity Estimation in One Sample}},
volume = {2},
year = {1978}
}
@article{Alam1979,
author = {Alam, Kursheed},
file = {:C$\backslash$:/Users/eribu/Downloads/ADA048126.pdf:pdf},
journal = {Naval Research Logistics Quarterl},
keywords = {article1},
mendeley-tags = {article1},
title = {{Distribution of sample correlation coefficients}},
year = {1979}
}
@article{Cattin1980,
abstract = {There are two ways to estimate the predictive power of a regression model: a cross-validation procedure and a formula. A number of formulas have been derived. A review of the literature leads to four (unbiased or least biased) formulas, each one appropriate depending on whether the predictor variables are fixed or random and on the measure needed, that is, a measure of the absolute error (the mean squared error of prediction) or of the relative error (the cross-validated multiple correlation). The advantages of these formulas over cross-validation are that they are less cumbersome to use and that they produce more precise estimates. The conditions under which it is appropriate to use these formulas are discussed as well as their use for comparing the predictive power of regression, subjective and equal weights. [ABSTRACT FROM AUTHOR]},
author = {Cattin, Philippe},
doi = {10.1037//0021-9010.65.4.407},
issn = {0021-9010},
journal = {Journal of Applied Psychology},
keywords = {ANALYSIS of variance,CORRELATION (Statistics),MATHEMATICAL statistics,REGRESSION analysis,article1},
mendeley-tags = {article1},
number = {4},
pages = {407--414},
title = {{Estimation of the Predictive Power of a Regression Model}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=bth{\&}AN=5133443{\&}site=ehost-live{\&}scope=site},
volume = {65},
year = {1980}
}
@article{Huberty1980,
author = {Huberty, Carl J and Mourad, Salah A},
file = {:C$\backslash$:/Users/eribu/Downloads/Educational and Psychological Measurement-1980-Huberty-101-12.pdf:pdf},
journal = {Educational and Psychological Measurement},
keywords = {article1},
mendeley-tags = {article1},
pages = {101--112},
title = {requires joint},
volume = {40},
year = {1980}
}
@article{Efron1983,
abstract = {We construct a prediction rule on the basis of some data, and then wish to estimate the error rate of this rule in classifying future observations. Cross-validation provides a nearly unbiased estimate, using only the original data. Cross-validation turns out to be related ... $\backslash$n},
author = {Efron, Bradley},
doi = {10.1080/01621459.1983.10477973},
isbn = {01621459},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {anova,article1,bootstrap,decomposition,logistic regression,prediction problem},
mendeley-tags = {article1},
number = {382},
pages = {316},
title = {{Estimating the Error Rate of a Prediction Rule: Improvement on Cross-Validation}},
url = {http://www.jstor.org/stable/2288636?origin=crossref$\backslash$npapers3://publication/doi/10.2307/2288636},
volume = {78},
year = {1983}
}
@article{Kvalseth1985,
abstract = {Abstract The coefficient of determination (R 2) is perhaps the single most extensively used measure of goodness of fit for regression models. It is also widely misused. The primary source of the problem is that except for linear models with an intercept term, the several alternative R 2 statistics are not generally equivalent. This article discusses various considerations and potential pitfalls in using the R 2's. Specific points are exemplified by means of empirical data. A new resistant statistic is also introduced.},
author = {Kv{\aa}lseth, Tarald O.},
doi = {10.1080/00031305.1985.10479448},
file = {:C$\backslash$:/Users/eribu/Downloads/2683704.pdf:pdf},
isbn = {0003-1305},
issn = {0003-1305},
journal = {American Statistician},
keywords = {article1,coefficient},
mendeley-tags = {article1},
number = {4},
pages = {279--285},
title = {{Cautionary Note about R2}},
url = {http://dx.doi.org/10.1080/00031305.1985.10479448},
volume = {39},
year = {1985}
}
@article{Ozer1985,
abstract = {Contends that both the interpretation of an effect size and the actual estimation of a coefficient of determination are partially theory-dependent. Two theoretical models for the variables cases are considered. In a variety of circumstances where the square of the correlation is used, the required assumptions are not tenable. In the alternate model, the absolute value of the correlation provides a coefficient of determination. The correlation coefficient is recommended for use as an effect-size indicator, because evaluating effect size in terms of variance accounted for may lead to interpretations that grossly underestimate the magnitude of a relation. (25 ref) (PsycINFO Database Record (c) 2010 APA )},
author = {Ozer, Daniel J.},
doi = {10.1037/0033-2909.97.2.307},
isbn = {0033-2909},
issn = {0033-2909},
journal = {Psychological Bulletin},
keywords = {article1},
mendeley-tags = {article1},
number = {2},
pages = {307--315},
title = {{Correlation and the coefficient of determination.}},
volume = {97},
year = {1985}
}
@article{Rodgers1988,
abstract = {In 1885, Sir Francis Galton first defined the term "regression" and completed the theory of bivariate correlation. A decade later, Karl Pearson developed the index that we still use to measure correlation, Pearson's r. Our article is written in recognition of the 100th anniversary of Galton's first discussion of regression and correlation. We begin with a brief history. Then we present 13 different formulas, each of which represents a different computational and conceptual definition of r. Each formula suggests a different way of thinking about this index, from algebraic, geometric, and trigonometric settings. We show that Pearson's r (or simple functions of r) may variously be thought of as a special type of mean, a special type of variance, the ratio of two means, the ratio of two variances, the slope of a line, the cosine of an angle, and the tangent to an ellipse, and may be looked at from several other interesting perspectives.},
archivePrefix = {arXiv},
arxivId = {Rodgers, J. L., {\&} Nicewander, W. A. (2008). Thirteen Ways to Look at the Correlation Coefficient, 42(1), 59–66.},
author = {Rodgers, Joseph Lee and Nicewander, W. Alan},
doi = {10.2307/2685263},
eprint = {Rodgers, J. L., {\&} Nicewander, W. A. (2008). Thirteen Ways to Look at the Correlation Coefficient, 42(1), 59–66.},
isbn = {00031305},
issn = {00031305},
journal = {The American Statistician},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {1},
pages = {59 -- 66},
pmid = {2685263},
title = {{Thirteen Ways to Look at the Correlation Coefficient}},
url = {http://www.jstor.org/stable/2685263},
volume = {42},
year = {1988}
}
@article{Hawkins1989,
abstract = {Hogg, RV, and Craig, AT (1978), Introduction to Mathematical Sta- tistics (4th ed.), New York: Macmillan. Pitman, EG (1939), "A Note on Normal CorTelation," Biomnetrika, 31, 9-12. Snedecor, GW, and Cochran, WG (1980), Statistical Methods (7th ed.), Ames: Iowa State},
author = {Hawkins, D},
doi = {10.2307/2685369},
file = {:C$\backslash$:/Users/eribu/Downloads/2685369.pdf:pdf},
issn = {00031305},
journal = {American Statistician},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {235--237},
title = {{Using U statistics to derive the asymptotic distribution of Fisher's Z statistic}},
url = {http://www.jstor.org/stable/2685369$\backslash$npapers3://publication/uuid/25473EA2-360A-4031-870D-0A90BCE030FF},
volume = {43},
year = {1989}
}
@article{Taylor1990,
abstract = {A basic consideration in the evaluation of professional medical literature is being able to understand the statistical analysis presented. One of the more frequently reported statistical methods involves correlation analysis where a correlation coefficient is reported representing the degree of linear association between two variables. This article discusses the basic aspects of correlation analysis with examples given from professional journals and focuses on the interpretations and limitations of the correlation coefficient. No attention was given to the actual calculation of this statistical value.},
author = {Taylor, R.},
doi = {10.1177/875647939000600106},
isbn = {8756479390006},
issn = {8756-4793},
journal = {Journal of Diagnostic Medical Sonography},
keywords = {article1,articles cannot be undertaken,coefficient of determination,correlation coefficient,medical or scientific journal,r coefficient,regression equation,the review of any,without being},
mendeley-tags = {article1},
pages = {35--39},
title = {{Interpretation of the Correlation Coefficient: A Basic Review}},
volume = {6},
year = {1990}
}
@article{Nagelkerke1991,
abstract = {A generalization of the coefficient of determination R2 to general regression models is discussed. A modification of an earlier definition to allow for discrete models is proposed.},
author = {Nagelkerke, N. J D},
doi = {10.1093/biomet/78.3.691},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nagelkerke - 1991 - A note on a general definition of the coefficient of determination.pdf:pdf},
isbn = {0006-3444},
issn = {00063444},
journal = {Biometrika},
keywords = {Discrete probability,Log likelihood,Multiple correlation coefficient,Regression model,Residual variation,article1},
mendeley-tags = {article1},
number = {3},
pages = {691--692},
pmid = {339},
title = {{A note on a general definition of the coefficient of determination}},
volume = {78},
year = {1991}
}
@article{Greco1992,
author = {Greco, Luigi},
file = {:C$\backslash$:/Users/eribu/Downloads/ref{\_}till{\_}coop1916/art{\%}3A10.1007{\%}2FBF02589036.pdf:pdf},
journal = {J. ltaL Statist. Soc.},
keywords = {article1,correlation coefficient,normal bi-variate popula-,probability distributions},
mendeley-tags = {article1},
pages = {289--294},
title = {{THE PROBABILITY INTEGRAL OF THE SAMPLE CORRELATION COEFFICIENT Ik- {\~{}}}},
volume = {2},
year = {1992}
}
@article{Efron1997,
abstract = {A study investigates the error rate of a rule for predicting future responses constructed from a training set of data. Results are nonparametric and apply to any possible prediction rule.},
annote = {Handlar om Bootstrap .632+ (vilket kanske {\"{a}}nnu inte {\"{a}}r helt relevant f{\"{o}}r oss).

Utv{\"{a}}rderar p{\aa} 24 olika modeller presenteade i tabell. Varierar sample size och dimensionality som vi. Dock stor skillnad att det baseras p{\aa} classification och inte regression. 

Anv{\"{a}}nder mindre samlpe sizes {\"{a}}n vi och fler variabler (st{\"{o}}rre p).

Har inte l{\"{a}}st s{\aa} noggrant d{\aa} den inte k{\"{a}}nns helt relevant och {\"{a}}r ganska teoretisk med mkt notation etc.},
author = {Efron, B. and Tibshirani, R.},
doi = {10.1080/01621459.1997.10474007},
file = {:C$\backslash$:/Users/eribu/Downloads/01621459{\%}2E1997{\%}2E10474007.pdf:pdf},
isbn = {0162-1459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {article1,classification,cross-validation bootstrap,prediction rule},
mendeley-tags = {article1},
number = {438},
pages = {548},
pmid = {370},
title = {{Improvements on cross-validation: The .632 plus bootstrap method}},
volume = {92},
year = {1997}
}
@article{ShigekazuNakagawa1997,
author = {{Shigekazu Nakagawa}, Naoto Niki},
file = {:C$\backslash$:/Users/eribu/Downloads/110001235586.pdf:pdf},
keywords = {article1,mixed conductors,p-t-x,perovskites,thermodynamic stability},
mendeley-tags = {article1},
number = {97},
title = {{Distribution of the sample correlation coefficient for nonnormal populations}},
volume = {2738},
year = {1997}
}
@article{KepplingerHansMathiasHabermeier1995,
author = {Raju, Nambury S and Bilgic, Reyhan and Edwards, Jack E and Fleer, Paul F},
file = {:C$\backslash$:/Users/eribu/Downloads/Applied Psychological Measurement-1997-Raju-291-305.pdf:pdf},
journal = {Applied Psychological Measurement},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {291--305},
title = {{Methodology Review: Estimation of population validity and cross-validity, and the use of equal weights in prediction}},
volume = {21},
year = {1997}
}
@article{Jr1998,
author = {Jr, Frank E Harrell},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jr - 1998 - Comparison of Strategies for Validating Binary Logistic Regression Models.pdf:pdf},
journal = {Statistics},
keywords = {article1},
mendeley-tags = {article1},
title = {{Comparison of Strategies for Validating Binary Logistic Regression Models}},
year = {1998}
}
@article{Algina1999,
abstract = {Four methods for constructing 100(1 - alpha){\%} confidence intervals$\backslash$nfor the population squared multiple correlation coefficient (rho(2))$\backslash$nwere compared. In one method the confidence interval was constructed$\backslash$nby using the distribution of R-2. Provided rho(2) > 0 the coverage$\backslash$nprobability for this method is exactly 1 - alpha when the data are$\backslash$nmultivariate normal. The other three methods are based on results$\backslash$nin Olkin and Finn (1995) and are approximate. Results show that each$\backslash$nof the approximate methods works very poorly for some combinations$\backslash$nof rho(2). The method based on the distribution of R-2 is recommended.},
author = {Algina, James},
doi = {10.1207/S15327906MBR3404{\_}5},
issn = {0027-3171},
journal = {Multivariate Behavioral Research},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {4},
pages = {493--504},
title = {{A Comparison of Methods for Constructing Confidence Intervals for the Squared Multiple Correlation Coefficient}},
url = {http://www.tandfonline.com/doi/abs/10.1207/S15327906MBR3404{\_}5},
volume = {34},
year = {1999}
}
@article{Raju1999,
abstract = {An empirical monte carlo study was performed using predictor and criterion data from 84,808 U.S. Air Force enlistees. 501 samples were drawn for each of seven sample size conditions: 25, 40, 60, 80, 100, 150, and 200. Using an eight-predictor model, 500 estimates for each of 9 validity and 11 cross-validity estimation procedures were generated for each sample size condition. These estimates were then compared to the actual squared population validity and cross-validity in terms of mean bias and mean squared bias. For the regression models determined using ordinary least squares, the Ezekiel procedure produced the most accurate estimates of squared population validity (followed by the Smith and the Wherry procedures), and Burket’s formula resulted in the best estimates of squared population cross-validity. Other analyses compared the coefficients determined by traditional empirical cross-validation and equal weights; equal weights resulted in no loss of predictive accuracy and less shrinkage. Numerous issues for future basic research on validation and cross-validation are identified.},
author = {Raju, N S and Bilgic, R and Edwards, J E and Fleer, P F},
doi = {10.1177/01466219922031220},
file = {:C$\backslash$:/Users/eribu/Downloads/Applied Psychological Measurement-1999-Raju-99-115.pdf:pdf},
isbn = {0146-6216},
issn = {0146-6216},
journal = {Applied Psychological Measurement},
keywords = {article1},
mendeley-tags = {article1},
number = {2},
pages = {99--115},
title = {{Accuracy of Population Validity and Cross-Validity Estimation: An Empirical Comparison of Formula-Based, Traditional Empirical, and Equal Weights Procedures}},
url = {http://apm.sagepub.com/content/23/2/99},
volume = {23},
year = {1999}
}
@article{Steyerberg2001,
abstract = {The performance of a predictive model is overestimated when simply determined on the sample of subjects that was used to construct the model. Several internal validation methods are available that aim to provide a more accurate estimate of model performance in new subjects. We evaluated several variants of split-sample, cross-validation and bootstrapping methods with a logistic regression model that included eight predictors for 30-day mortality after an acute myocardial infarction. Random samples with a size between n = 572 and n = 9165 were drawn from a large data set (GUSTO-I; n = 40,830; 2851 deaths) to reflect modeling in data sets with between 5 and 80 events per variable. Independent performance was determined on the remaining subjects. Performance measures included discriminative ability, calibration and overall accuracy. We found that split-sample analyses gave overly pessimistic estimates of performance, with large variability. Cross-validation on 10{\%} of the sample had low bias and low variability, but was not suitable for all performance measures. Internal validity could best be estimated with bootstrapping, which provided stable estimates with low bias. We conclude that split-sample validation is inefficient, and recommend bootstrapping for estimation of internal validity of a predictive logistic regression model.},
annote = {Tipsad av Szilard.

fokuserad p{\aa} logistisk regression.

Utg{\aa}r fr{\aa}n praktiskt exempel med hj{\"{a}}rtattack. 
V{\aa}r ansats {\"{a}}r mer teoretisk/generell.
J{\"{a}}mf{\"{o}}r med olika EPV-v{\"{a}}rden och stratifiering.
Resamplar 500 ggr.
stepwise model selection med 8 predektorer.

Utv{\"{a}}rderar flera olika m{\"{a}}tv{\"{a}}rden, inkl R2 (dock Negelkerke).

Olika metoder men inte jack-knife.

F{\aa}r delvis samma slutsats som vi ang {\"{o}}verskattning med cv.},
author = {Steyerberg, Ewout W and Harrell, Frank E and Borsboom, Gerard J.J.M and Eijkemans, M.J.C and Vergouwe, Yvonne and Habbema, J.Dik F},
doi = {10.1016/S0895-4356(01)00341-9},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Steyerberg et al. - 2001 - Internal validation of predictive models.pdf:pdf},
issn = {08954356},
journal = {Journal of Clinical Epidemiology},
keywords = {Bootstrapping,Internal validation,Logistic regression analysis,Predictive models,article1,harrell,statistics},
mendeley-tags = {article1,harrell,statistics},
month = {aug},
number = {8},
pages = {774--781},
title = {{Internal validation of predictive models}},
url = {http://www.sciencedirect.com/science/article/pii/S0895435601003419},
volume = {54},
year = {2001}
}
@article{Breiman2001,
abstract = {There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commit-ment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current prob-lems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.},
annote = {Denna artikel {\"{a}}r kritisk mot modellering och f{\"{o}}redrar i likhet med Kuhn att utg{\aa} fr{\aa}n accuracy meassure, inte model validering, d{\aa} detta ofta inte l{\aa}ter sig g{\"{o}}ras s{\aa} l{\"{a}}tt.

Inneh{\aa}ller ocks{\aa} kommentarer fr{\aa}n ett flertal auktoriteter p{\aa} omr{\aa}det samt d{\"{a}}refter ett avslutande svar fr{\aa}n f{\"{o}}rfattaren.},
author = {Breiman, Leo},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Breiman - 2001 - Statistical Modeling The Two Cultures.pdf:pdf},
journal = {Statistical Science},
keywords = {article1,statistics},
mendeley-tags = {article1,statistics},
number = {3},
pages = {199--231},
title = {{Statistical Modeling: The Two Cultures}},
volume = {16},
year = {2001}
}
@article{Yin2001,
abstract = {Abstract The effectiveness of various analytical formulas for estimating R 2 shrinkage in multiple regression analysis was investigated. Two categories of formulas were identified: estimators of the squared population multiple correlation coefficient ($\rho$2) and those of the squared population cross-validity coefficient ($\rho$c 2). The authors conducted a Monte Carlo experiment to investigate the effectiveness of the analytical formulas for estimating R 2 shrinkage, with 4 fully crossed factors (squared population multiple correlation coefficient, number of predictors, sample size, and degree of multicollinearity) and 500 replications in each cell. The results indicated that the most widely used Wherry formula (in both SAS and SPSS) is probably not the most effective analytical formula for estimating $\rho$2. Instead, the Pratt formula and the Browne formula outperformed other analytical formulas in estimating $\rho$2 and $\rho$c 2, respectively.},
author = {Yin, Ping and Fan, Xitao},
doi = {10.1080/00220970109600656},
file = {:C$\backslash$:/Users/eribu/Downloads/Estimating R 2 Shrinkage in Multiple Regression A Comparison of Different Analytical Methods.pdf:pdf},
isbn = {0022097010960},
issn = {0022-0973},
journal = {The Journal of Experimental Education},
keywords = {Cross-validation,Monte Carlo method,R 1 shrinkage,article1,multiple regression,statistical bias},
mendeley-tags = {article1},
number = {2},
pages = {203--224},
title = {{Estimating R 2 Shrinkage in Multiple Regression: A Comparison of Different Analytical Methods}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00220970109600656},
volume = {69},
year = {2001}
}
@article{Algina2001,
abstract = {The increase in the squared multiple correlation coefficient (DeltaR(2))$\backslash$nassociated with a variable in a regression equation is a commonly$\backslash$nused measure of importance in regression analysis. The probability$\backslash$nthat an asymptotic confidence interval will include Delta rho (2)$\backslash$nwas investigated. With sample sizes typically used in regression$\backslash$nanalyses, when Delta rho (2) = 0.00 and the confidence level is .95$\backslash$nor greater, the probability will be at least .999. For Delta rho$\backslash$n(2) greater than or equal to .01 and a confidence level of .95 or$\backslash$ngreater, the probability will be smaller than the nominal confidence$\backslash$nlevel. For Delta rho (2) greater than or equal to .05 and a confidence$\backslash$nlevel of .95, tables are provided for the sample size necessary for$\backslash$nthe probability to be at least .925 and to be at least .94.},
author = {Algina, J. and Moulder, B. C.},
doi = {10.1177/00131640121971400},
issn = {0013-1644},
journal = {Educational and Psychological Measurement},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {4},
pages = {633--649},
title = {{Sample Sizes for Confidence Intervals on the Increase in the Squared Multiple Correlation Coefficient}},
volume = {61},
year = {2001}
}
@article{Barnhart2002,
abstract = {Accurate and precise measurement is an important component of any proper study design. As elaborated by Lin (1989, Biometrics 45, 255-268), the concordance correlation coefficient (CCC) is more appropriate than other indices for measuring agreement when the variable of interest is continuous. However, this agreement index is defined in the context of comparing two fixed observers. In order to use multiple observers in a study involving large numbers of subjects, there is a need to assess agreement among these multiple observers. In this article, we present an overall CCC (OCCC) in terms of the interobserver variability for assessing agreement among multiple fixed observers. The OCCC turns out to be equivalent to the generalized CCC (King and Chinchilli, 2001, Statistics in Medicine 20, 2131-2147; Lin, 1989; Lin, 2000, Biometrics 56, 324-325) when the squared distance function is used. We evaluated the OCCC through generalized estimating equations (Barnhart and Williamson, 2001, Biometrics 57, 931-940) and U-statistics (King and Chinchilli, 2001) for inference. This article offers the following important points. First, it addresses the precision and accuracy indices as components of the OCCC. Second, it clarifies that the OCCC is the weighted average of all pairwise CCCs. Third, it is intuitively defined in terms of interobserver variability. Fourth, the inference approaches of GEE and the U-statistics are compared via simulations for small samples. Fifth, we illustrate the use of the OCCC by two medical examples with the GEE, U-statistics, and bootstrap approaches.},
author = {Barnhart, H X and Haber, M and Song, J},
doi = {10.1111/j.0006-341X.2002.01020.x},
isbn = {0006-341X (Print)},
issn = {0006-341X},
journal = {Biometrics},
keywords = {Agreement,Overall concordance correlation coefficient,Reproducibility,article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {4},
pages = {1020--1027},
pmid = {12495158},
title = {{Overall concordance correlation coefficient for evaluating agreement among multiple observers}},
volume = {58},
year = {2002}
}
@article{Zimmerman2003,
author = {Zimmerman, Donald W and Zumbo, Bruno D and Williams, Richard H},
file = {:C$\backslash$:/Users/eribu/Downloads/9.ZUMBO.pdf:pdf},
issn = {02112159},
journal = {Transformation},
keywords = {article1},
mendeley-tags = {article1},
number = {1},
pages = {133--158},
title = {{Bias in estimation and hypothesis testing of correlation}},
url = {http://redalyc.uaemex.mx/redalyc/html/169/16924109/16924109.html$\backslash$nhttp://www.uv.es/psicologica/articulos1.03/9.ZUMBO.pdf},
volume = {24},
year = {2003}
}
@article{Croux2003,
abstract = {Many robust regression estimators are defined by minimizing a measure of spread of the residuals. An accompanying R{\^{}}2-measure, or multiple correlation coefficient, is then easily obtained. In this paper, local robustness properties of these robust R{\^{}}2-coefficients are investigated. It is also shown how confidence intervals for the population multiple correlation coefficient can be constructed in the case of multivariate normality.},
author = {Croux, Christophe and Dehon, Catherine},
doi = {10.1007/s00362-003-0158-7},
issn = {0932-5026},
journal = {Statistical Papers},
keywords = {R{\^{}}2 measure,article1,influence function,multiple correlation,multiple correlation coefficient,regression analysis,robustness},
mendeley-tags = {article1,multiple correlation},
number = {3},
pages = {315--334},
title = {{Estimators of the multiple correlation coefficient: Local robustness and confidence intervals}},
url = {http://www.springerlink.com/index/jl8n427176112777.pdf$\backslash$nhttp://www.springerlink.com/index/10.1007/s00362-003-0158-7},
volume = {44},
year = {2003}
}
@article{Zimmerman2003a,
abstract = {This study examined bias in the sample correlation coefficient, r, and its correction by unbiased estimators. Computer simulations revealed that the expected value of correlation coefficients in samples from a normal population is slightly less than the population correlation, {\&}{\#}961;, and that the bias is almost eliminated by an estimator suggested by R.A. Fisher and is more completely eliminated by a related estimator recommended by Olkin and Pratt. Transformation of initial scores to ranks and calculation of the Spearman rank correlation, rS, produces somewhat greater bias. Type I error probabilities of significance tests of zero correlation based on the Student t statistic and exact tests based on critical values of rS obtained from permutations remain fairly close to the significance level for normal and several non-normal distributions. However, significance tests of non-zero values of correlation based on the r to Z transformation are grossly distorted for distributions that violate bivariate normality. Also, significance tests of non-zero values of rS based on the r to Z transformation are distorted even for normal distributions.},
author = {Zimmerman, D and Zumbo, B and Williams, R},
issn = {02112159},
journal = {Psicologica},
keywords = {article1},
mendeley-tags = {article1},
number = {24},
pages = {133--158},
title = {{Bias in Estimation and Hypothesis Testing of Correlation}},
url = {http://www.redalyc.org/articulo.oa?id=16924109SL},
volume = {24},
year = {2003}
}
@article{Fu2005,
abstract = {MOTIVATION: Estimation of misclassification error has received increasing attention in clinical diagnosis and bioinformatics studies, especially in small sample studies with microarray data. Current error estimation methods are not satisfactory because they either have large variability (such as leave-one-out cross-validation) or large bias (such as resubstitution and leave-one-out bootstrap). While small sample size remains one of the key features of costly clinical investigations or of microarray studies that have limited resources in funding, time and tissue materials, accurate and easy-to-implement error estimation methods for small samples are desirable and will be beneficial.$\backslash$n$\backslash$nRESULTS: A bootstrap cross-validation method is studied. It achieves accurate error estimation through a simple procedure with bootstrap resampling and only costs computer CPU time. Simulation studies and applications to microarray data demonstrate that it performs consistently better than its competitors. This method possesses several attractive properties: (1) it is implemented through a simple procedure; (2) it performs well for small samples with sample size, as small as 16; (3) it is not restricted to any particular classification rules and thus applies to many parametric or non-parametric methods.},
author = {Fu, Wenjiang J. and Carroll, Raymond J. and Wang, Suojin},
doi = {10.1093/bioinformatics/bti294},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fu, Carroll, Wang - 2005 - Estimating misclassification error with small samples via bootstrap cross-validation.pdf:pdf},
isbn = {1367-4803 (Print)$\backslash$r1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
keywords = {article1},
mendeley-tags = {article1},
pmid = {15691862},
title = {{Estimating misclassification error with small samples via bootstrap cross-validation}},
year = {2005}
}
@article{FarzipoorSean2005,
abstract = {In some of the papers on data envelopment analysis (DEA), there have been explained that if correlation coefficient between each pair of input (output) vectors is strong and positive, one of the input (output) vector could be omitted. The objective of this paper is to determine correlation coefficient threshold that beyond which omission of one or more input vectors have no statistically significant effect on the efficiency mean. The threshold identification in terms of some of the DEA models including CCR, CCRCSW, BCC and BCCCSW are performed. To analyze the data, analysis of variance (ANOVA) is used. ?? 2004 Published by Elsevier Inc.},
author = {{Farzipoor Sean}, R. and Memariani, A. and Lotfi, F. Hosseinzadeh},
doi = {10.1016/j.amc.2003.12.117},
isbn = {0096-3003},
issn = {00963003},
journal = {Applied Mathematics and Computation},
keywords = {Analysis of variance,Correlation coefficient,Data envelopment analysis,article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {2},
pages = {503--521},
title = {{The effect of correlation coefficient among multiple input vectors on the efficiency mean in data envelopment analysis}},
volume = {162},
year = {2005}
}
@book{Faraway2005,
abstract = {The book focuses on the practice of regression and analysis of variance. It clearly demonstrates the different methods available and in which situations each one applies. It covers all of the standard topics, from the basics of estimation to missing data, factorial designs, and block designs, but it also includes discussion of topics, such as model uncertainty, rarely addressed in books of this type. The presentation incorporates an abundance of examples that clarify both the use of each technique and the conclusions one can draw from the results.},
author = {Faraway, Julian J.},
booktitle = {Library},
isbn = {1584884258},
keywords = {article1},
mendeley-tags = {article1},
pages = {1--229},
title = {{Linear Models with R}},
url = {http://www.stat.lsa.umich.edu/{~}faraway/LMR/},
year = {2005}
}
@article{Association2005,
author = {Association, Statistical},
file = {:C$\backslash$:/Users/eribu/Downloads/adj r2.pdf:pdf},
isbn = {0521773628},
keywords = {article1},
mendeley-tags = {article1},
number = {471},
pages = {99--104},
title = {{Journal of the American Statistical Association, Vol. 100, No. 471, September 2005.}},
volume = {100},
year = {2005}
}
@article{Bioinformatics2006,
abstract = {Background: Cross-validation (CV) is an effective method for estimating the prediction error of a classifier. Some recent articles have proposed methods for optimizing classifiers by choosing classifier parameter values that minimize the CV error estimate. We have evaluated the validity of using the CV error estimate of the optimized classifier as an estimate of the true error expected on independent data. Results: We used CV to optimize the classification parameters for two kinds of classifiers; Shrunken Centroids and Support Vector Machines (SVM). Random training datasets were created, with no difference in the distribution of the features between the two classes. Using these "null" datasets, we selected classifier parameter values that minimized the CV error estimate. 10-fold CV was used for Shrunken Centroids while Leave-One-Out-CV (LOOCV) was used for the SVM. Independent test data was created to estimate the true error. With "null" and "non null" (with differential expression between the classes) data, we also tested a nested CV procedure, where an inner CV loop is used to perform the tuning of the parameters while an outer CV is used to compute an estimate of the error. The CV error estimate for the classifier with the optimal parameters was found to be a substantially biased estimate of the true error that the classifier would incur on independent data. Even though there is no real difference between the two classes for the "null" datasets, the CV error estimate for the Shrunken Centroid with the optimal parameters was less than 30{\%} on 18.5{\%} of simulated training data-sets. For SVM with optimal parameters the estimated error rate was less than 30{\%} on 38{\%} of "null" data-sets. Performance of the optimized classifiers on the independent test set was no better than chance. The nested CV procedure reduces the bias considerably and gives an estimate of the error that is very close to that obtained on the independent testing set for both Shrunken Centroids and SVM classifiers for "null" and "non-null" data distributions. Conclusion: We show that using CV to compute an error estimate for a classifier that has itself been tuned using CV gives a significantly biased estimate of the true error. Proper use of CV for estimating true error of a classifier developed using a well defined algorithm requires that all steps of the algorithm, including classifier parameter tuning, be repeated in each CV loop. A nested CV procedure provides an almost unbiased estimate of the true error.},
author = {Bioinformatics, Bmc and Varma, Sudhir and Simon, Richard},
doi = {10.1186/1471-2105-7-91},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bioinformatics, Varma, Simon - 2006 - Bias in error estimation when using cross-validation for model selection.pdf:pdf},
journal = {BMC Bioinformatics},
keywords = {article1},
mendeley-tags = {article1},
number = {7},
title = {{Bias in error estimation when using cross-validation for model selection}},
url = {http://www.biomedcentral.com/1471-2105/7/91},
volume = {7},
year = {2006}
}
@article{Asuero2006,
abstract = {Correlation and regression are different, but not mutually exclusive, techniques. Roughly, regression is used for prediction (which does not extrapolate beyond the data used in the analysis) whereas correlation is used to determine the degree of association. There situations in which the x variable is not fixed or readily chosen by the experimenter, but instead is a random covariate to the y variable. This paper shows the relationships between the coefficient of determination, the multiple correlation coefficient, the covariance, the correlation coefficient and the coefficient of alienation, for the case of two related variables x and y. It discusses the uses of the correlation coefficient r, either as a way to infer correlation, or to test linearity. A number of graphical examples are provided as well as examples of actual chemical applications. The paper recommends the use of z Fisher transformation instead of r values because r is not normally distributed but z is (at least in approximation). For either correlation or for regression models, the same expressions are valid, although they differ significantly in meaning. Correlation and regression are different, but not mutually exclusive, techniques. Roughly, regression is used for prediction (which does not extrapolate beyond the data used in the analysis) whereas correlation is used to determine the degree of association. There situations in which the x variable is not fixed or readily chosen by the experimenter, but instead is a random covariate to the y variable. This paper shows the relationships between the coefficient of determination, the multiple correlation coefficient, the covariance, the correlation coefficient and the coefficient of alienation, for the case of two related variables x and y. It discusses the uses of the correlation coefficient r, either as a way to infer correlation, or to test linearity. A number of graphical examples are provided as well as examples of actual chemical applications. The paper recommends the use of z Fisher transformation instead of r values because r is not normally distributed but z is (at least in approximation). For either correlation or for regression models, the same expressions are valid, although they differ significantly in meaning.},
author = {Asuero, a. G. and Sayago, a. and Gonz{\'{a}}lez, a. G.},
doi = {10.1080/10408340500526766},
isbn = {1040-8347},
issn = {1040-8347},
journal = {Critical Reviews in Analytical Chemistry},
keywords = {article1,cause and effect,correlation coefficient,covariance,inference,lineariy,multiple correlation,multiple correlation coefficient,significance tests},
mendeley-tags = {article1,multiple correlation},
number = {July},
pages = {41--59},
pmid = {19702027},
title = {{The Correlation Coefficient: An Overview}},
volume = {36},
year = {2006}
}
@misc{Gonz??lez2006,
abstract = {The use of the correlation coefficient for testing the linearity of calibration curves is performed according to the ANOVA checking of the lack-of-fit. The procedure is illustrated from a case study.},
author = {Gonz??lez, A. Gustavo and Herrador, M. ??ngeles and Asuero, Agust??n G. and Sayago, Ana},
booktitle = {Accreditation and Quality Assurance},
doi = {10.1007/s00769-006-0153-5},
isbn = {0949-1775},
issn = {09491775},
keywords = {Coefficient of determination,Correlation coefficient,Lack-of-fit,Linearity,article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {5},
pages = {256--258},
title = {{The correlation coefficient attacks again}},
volume = {11},
year = {2006}
}
@article{Wang2007,
abstract = {In this study the authors investigated the use of 5 (i.e., Claudy, Ezekiel, Olkin-Pratt, Pratt, and Smith) R[squared] correction formulas with the Pearson r[squared]. The authors estimated adjustment bias and precision under 6 x 3 x 6 conditions (i.e., population $\rho$ values of 0.0, 0.1, 0.3, 0.5, 0.7, and 0.9; population shapes normal, skewness = kurtosis = 1, and skewness = -1.5 with kurtosis = 3.5; ns = 10, 20, 40, 60, 100, and 200 respectively). Results indicate that the sample Pearson r[squared] is marginally biased at small sample sizes and small population effect sizes, and that the Ezekiel and the Smith R[squared] corrections work well in controlling this bias. (Contains 5 tables.)},
author = {Wang, Zhongmiao and Thompson, Bruce},
doi = {10.3200/JEXE.75.2.109-125},
file = {:C$\backslash$:/Users/eribu/Downloads/Is the Pearson r 2 Biased and if So What Is the Best Correction Formula.pdf:pdf},
issn = {0022-0973},
journal = {The Journal of Experimental Education},
keywords = {article1},
mendeley-tags = {article1},
number = {2},
pages = {109--125},
title = {{Is the Pearson r 2 Biased, and if So, What Is the Best Correction Formula?}},
volume = {75},
year = {2007}
}
@article{Isaksson2008,
abstract = {The interest in statistical classification for critical applications such as diagnoses of patient samples based on supervised learning is rapidly growing. To gain acceptance in applications where the subsequent decisions have serious consequences, e.g. choice of cancer therapy, any such decision support system must come with a reliable performance estimate. Tailored for small sample problems, cross-validation (CV) and bootstrapping (BTS) have been the most commonly used methods to determine such estimates in virtually all branches of science for the last 20 years. Here, we address the often overlooked fact that the uncertainty in a point estimate obtained with CV and BTS is unknown and quite large for small sample classification problems encountered in biomedical applications and elsewhere. To avoid this fundamental problem of employing CV and BTS, until improved alternatives have been established, we suggest that the final classification performance always should be reported in the form of a Bayesian confidence interval obtained from a simple holdout test or using some other method that yields conservative measures of the uncertainty. ?? 2008 Elsevier B.V. All rights reserved.},
author = {Isaksson, A. and Wallman, M. and G??ransson, H. and Gustafsson, M. G.},
doi = {10.1016/j.patrec.2008.06.018},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Isaksson et al. - 2008 - Cross-validation and bootstrapping are unreliable in small sample classification.pdf:pdf},
isbn = {01678655},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Confidence interval,Performance estimation,Supervised classification,article1},
mendeley-tags = {article1},
title = {{Cross-validation and bootstrapping are unreliable in small sample classification}},
year = {2008}
}
@article{Hossjer2008,
abstract = {For mixed regression models, we define a variance decomposition including three terms, explained individual variance, unexplained individual variance and noise variance. In contrast to traditional variance decomposition, it is thus the unexplained, not the explained, variance that is split. It gives rise to a coefficient of individual determination (CID) defined as the estimated fraction of explained individual variance. We argue that in many applications CID is a valuable complement to R2, since it excludes noise variance (which can never be explained) and thus has one as a natural upper bound. A general theory for coefficients determination is presented, including various choices of regression models, weight functions and parameter estimates. In particular we focus on models where CID is computable, such as univariate mixed Poisson and logistic regression models, as well as multivariate mixed linear regression models. Large sample properties and confidence intervals are derived and finally, the theory is exemplified using Poisson regression on a Swedish motor traffic insurance data set. © 2007 Elsevier B.V. All rights reserved.},
author = {H{\"{o}}ssjer, Ola},
doi = {10.1016/j.jspi.2007.11.010},
isbn = {0378-3758},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Coefficient of determination,Explained variance,Individual variance,Mixed regression models,Noise variance,Variance decomposition,article1},
mendeley-tags = {article1},
number = {10},
pages = {3022--3038},
title = {{On the coefficient of determination for mixed regression models}},
volume = {138},
year = {2008}
}
@article{Shieh2008,
abstract = {The sample squared multiple correlation coefficient is widely used for describing the usefulness of a multiple linear regression model in many areas of science. In this article, the author considers the problem of estimating the squared multiple correlation coefficient and the squared cross-validity coefficient under the assumption that the response and predictor variables have a joint multinormal distribution. Detailed numerical investigations are conducted to assess the exact bias and mean square error of the proposed modifications of established estimators. Notably, the positive-part Pratt estimator and the synthesis of Browne and positive-part Pratt estimators are recommended in the estimation of squared multiple correlation coefficient and squared cross-validity coefficient, respectively, for their overall advantages of incurring the least amount of statistical discrepancy and computational requirement.},
author = {Shieh, Gwowen},
doi = {10.1177/1094428106292901},
isbn = {1094-4281},
issn = {1094-4281},
journal = {Organizational Research Methods},
keywords = {article1,as fixed and known,bias,explanatory variables are treated,maximum likelihood estimator,mean square error,multiple correlation,multiple linear regres-,one of the most,shrinkage estimator,sion,statistical methods,the values of the,traditionally,ultiple regression analysis is,widely used of all},
mendeley-tags = {article1,multiple correlation},
number = {2},
pages = {387--407},
title = {{Improved Shrinkage Estimation of Squared Multiple Correlation Coefficient and Squared Cross-Validity Coefficient}},
volume = {11},
year = {2008}
}
@article{Shieh2008a,
author = {Shieh, Gwowen},
file = {:C$\backslash$:/Users/eribu/Downloads/Organizational Research Methods-2008-Shieh-387-407.pdf:pdf},
journal = {Organizational Research Methods},
keywords = {article1,as fixed and known,bias,explanatory variables are treated,maximum likelihood estimator,mean square error,multiple linear regres-,one of the most,shrinkage estimator,sion,statistical methods,the values of the,traditionally,ultiple regression analysis is,widely used of all},
mendeley-tags = {article1},
number = {2},
pages = {387--407},
title = {{Improved Shrinkage Estimation of Squared Multiple Correlation Coefficient and Squared Cross-Validity Coefficient}},
volume = {11},
year = {2008}
}
@article{Kim2009,
abstract = {We consider the accuracy estimation of a classifier constructed on a given training sample. The naive resubstitution estimate is known to have a downward bias problem. The traditional approach to tackling this bias problem is cross-validation. The bootstrap is another way to bring down the high variability of cross-validation. But a direct comparison of the two estimators, cross-validation and bootstrap, is not fair because the latter estimator requires much heavier computation. We performed an empirical study to compare the??.632+??bootstrap estimator with the repeated 10-fold cross-validation and the repeated one-third holdout estimator. All the estimators were set to require about the same amount of computation. In the simulation study, the repeated 10-fold cross-validation estimator was found to have better performance than the??.632+??bootstrap estimator when the classifier is highly adaptive to the training sample. We have also found that the??.632+??bootstrap estimator suffers from a bias problem for large samples as well as for small samples. ?? 2009 Elsevier B.V. All rights reserved.},
annote = {behandlar classification, inte regression.},
author = {Kim, Ji Hyun},
doi = {10.1016/j.csda.2009.04.009},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim - 2009 - Estimating classification error rate Repeated cross-validation, repeated hold-out and bootstrap.pdf:pdf},
isbn = {0167-9473},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {article1},
mendeley-tags = {article1},
number = {11},
pages = {3735--3745},
title = {{Estimating classification error rate: Repeated cross-validation, repeated hold-out and bootstrap}},
volume = {53},
year = {2009}
}
@article{Hafdahl2009,
abstract = {In 2 Monte Carlo studies of fixed- and random-effects meta-analysis for correlations, A. P. Field (2001) ostensibly evaluated Hedges-Olkin-Vevea Fisher-z and Schmidt-Hunter Pearson-r estimators and tests in 120 conditions. Some authors have cited those results as evidence not to meta-analyze Fisher-z correlations, especially with heterogeneous correlation parameters. The present attempt to replicate Field's simulations included comparisons with analytic values as well as results for efficiency and confidence-interval coverage. Field's results under homogeneity were mostly replicable, but those under heterogeneity were not: The latter exhibited up to over .17 more bias than ours and, for tests of the mean correlation and homogeneity, respectively, nonnull rejection rates up to .60 lower and .65 higher. Changes to Field's observations and conclusions are recommended, and practical guidance is offered regarding simulation evidence and choices among methods. Most cautions about poor performance of Fisher-z methods are largely unfounded, especially with a more appropriate z-to-r transformation. The Appendix gives a computer program for obtaining Pearson-r moments from a normal Fisher-z distribution, which is used to demonstrate distortion due to direct z-to-r transformation of a mean Fisher-z correlation.},
author = {Hafdahl, Adam R and Williams, Michelle a},
doi = {10.1037/a0014697},
isbn = {1082-989X$\backslash$n1939-1463},
issn = {1082-989X},
journal = {Psychological methods},
keywords = {10,1037,a0014697,article1,decades,doi,during the past 3,dx,fisher,http,meta-analysis,meta-analysis has become a,monte carlo simulation,org,random effects,s z transformation,supp,supplemental materials,validity generalization},
mendeley-tags = {article1},
number = {1},
pages = {24--42},
pmid = {19271846},
title = {{Meta-analysis of correlations revisited: attempted replication and extension of Field's (2001) simulation studies.}},
volume = {14},
year = {2009}
}
@article{Gorsuch2010,
abstract = {Non-zero correlation coefficients have non-normal distributions, affecting both means and standard deviations. Previous research suggests that z transformation may effectively correct mean bias for N's less than 30. In this study, simulations with small (20 and 30) and large (50 and 100) N's found that mean bias adjustments for larger N's are seldom needed. However, z transformations improved confidence intervals even for N = 100. The improvement was not in the estimated standard errors so much as in the asymmetrical CI's estimates based upon the z transformation. The resulting observed probabilities were generally accurate to within 1 point in the first non-zero digit. These issues are an order of magnitude less important for accuracy than design issues influencing the accuracy of the results, such as reliability, restriction of range, and N. Keywords: Confidence intervals; Correlation coefficient; Fisher’s z transformation; Monte Carlo study; Mean bias in correlation coefficients},
author = {Gorsuch, Rl and Lehmann, Cs},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gorsuch, Lehmann - 2010 - Correlation Coefficients Mean Bias and Confidence Interval Distortions.pdf:pdf},
issn = {2159-7855},
journal = {Journal of Methods and Measurement in the Social Sciences},
keywords = {article1,because the distribution of,coefficients,confidence intervals,correlation coefficient,estimate the population correlation,fisher,is known to slightly,mean bias in correlation,monte carlo,r,r is,s z transformation,study,the observed correlation coefficient,under,$\rho$},
mendeley-tags = {article1},
number = {2},
pages = {52--65},
title = {{Correlation Coefficients: Mean Bias and Confidence Interval Distortions}},
url = {https://journals.uair.arizona.edu/index.php/jmmss/article/download/114/118},
volume = {1},
year = {2010}
}
@article{Renaud2010,
abstract = {To assess the quality of the fit in a multiple linear regression, the coefficient of determination or R2 is a very simple tool, yet the most used by practitioners. Indeed, it is reported in most statistical analyzes, and although it is not recommended as a final model selection tool, it provides an indication of the suitability of the chosen explanatory variables in predicting the response. In the classical setting, it is well known that the least-squares fit and coefficient of determination can be arbitrary and/or misleading in the presence of a single outlier. In many applied settings, the assumption of normality of the errors and the absence of outliers are difficult to establish. In these cases, robust procedures for estimation and inference in linear regression are available and provide a suitable alternative. In this paper we present a companion robust coefficient of determination that has several desirable properties not shared by others. It is robust to deviations from the specified regression model (like the presence of outliers), it is efficient if the errors are normally distributed, it does not make any assumption on the distribution of the explanatory variables (and therefore no assumption on the unconditional distribution of the responses). We also show that it is a consistent estimator of the population coefficient of determination. A simulation study and two real datasets support the appropriateness of this estimator, compared with classical (least-squares) and several previously proposed robust R2, even for small sample sizes. © 2010 Elsevier B.V. All rights reserved.},
author = {Renaud, Olivier and Victoria-Feser, Maria Pia},
doi = {10.1016/j.jspi.2010.01.008},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Consistency,Correlation,Efficiency,Outliers,R-squared,article1},
mendeley-tags = {article1},
number = {7},
pages = {1852--1862},
title = {{A robust coefficient of determination for regression}},
volume = {140},
year = {2010}
}
@article{Shieh2010,
abstract = {This article investigates some unfamiliar properties of the Pearson product-moment correlation coefficient for the estimation of simple correlation coefficient. Although Pearson's r is biased, except for limited situations, and the minimum variance unbiased estimator has been proposed in the literature, researchers routinely employ the sample correlation coefficient in their practical applications, because of its simplicity and popularity. In order to support such practice, this study examines the mean squared errors of r and several prominent formulas. The results reveal specific situations in which the sample correlation coefficient performs better than the unbiased and nearly unbiased estimators, facilitating recommendation of r as an effect size index for the strength of linear association between two variables. In addition, related issues of estimating the squared simple correlation coefficient are also considered.},
author = {Shieh, Gwowen},
doi = {10.3758/BRM.42.4.906},
isbn = {1554-3528 (Electronic)$\backslash$r1554-351X (Linking)},
issn = {1554-351X},
journal = {Behavior research methods},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {4},
pages = {906--917},
pmid = {21139158},
title = {{Estimation of the simple correlation coefficient.}},
volume = {42},
year = {2010}
}
@article{Skidmore2011,
author = {Skidmore, Susan Troncoso and Thompson, Bruce},
doi = {10.1080/00220973.2010.484437},
file = {:C$\backslash$:/Users/eribu/Downloads/Choosing the Best Correction Formula for the Pearson r 2Effect Size.pdf:pdf},
issn = {0022-0973},
journal = {The Journal of Experimental Education},
keywords = {article1},
mendeley-tags = {article1},
number = {3},
pages = {257--278},
title = {{Choosing the Best Correction Formula for the Pearson r 2 Effect Size}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00220973.2010.484437},
volume = {79},
year = {2011}
}
@article{Mukaka2012,
abstract = {Correlation is a statistical method used to assess a possible linear association between two continuous variables. It is simple both to calculate and to interpret. However, misuse of correlation is so common among researchers that some statisticians have wished that the method had never been devised at all. The aim of this article is to provide a guide to appropriate use of correlation in medical research and to highlight some misuse. Examples of the applications of the correlation coefficient have been provided using data from statistical simulations as well as real data. Rule of thumb for interpreting size of a correlation coefficient has been provided.},
author = {Mukaka, M. M.},
file = {:C$\backslash$:/Users/eribu/Downloads/MMJ2403-0069.pdf:pdf},
issn = {19957262},
journal = {Malawi Medical Journal},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {3},
pages = {69--71},
pmid = {23638278},
title = {{Statistics corner: A guide to appropriate use of correlation coefficient in medical research}},
volume = {24},
year = {2012}
}
