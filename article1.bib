@article{Pearson1895,
abstract = {In statistics, the Pearson product-moment correlation coefficient (/ˈpɪərsɨn/) (sometimes referred to as the PPMCC or PCC or Pearson's r) is a measure of the linear correlation (dependence) between two variables X and Y. It was developed by Karl Pearson from a related idea introduced by Francis Galton in the 1880s},
annote = {Detta {\"{a}}r visserligen den artikel som gett upphov till Pearsons korrelationscoefficient men h{\"{a}}rifr{\aa}n h{\"{a}}nvisas till Galtons formel s{\aa} egentligen var det inte helt nytt.

V{\"{a}}ldigt kort note som egentligen {\"{a}}r del av l{\"{a}}ngre paper som inte han f{\"{a}}rdigst{\"{a}}llas pga h{\"{a}}lsoproblem.},
author = {Pearson, Karl},
doi = {10.1098/rspl.1895.0041},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pearson - 1895 - Note on Regression and Inheritance in the Case of Two Parents.pdf:pdf},
isbn = {0370-1662},
issn = {0370-1662},
journal = {Proceedings of the Royal Society of London (1854-1905)},
keywords = {article1},
mendeley-tags = {article1},
pages = {240--242},
title = {{Note on Regression and Inheritance in the Case of Two Parents}},
volume = {58},
year = {1895}
}
@article{Pearson1896a,
author = {Pearson, Karl},
doi = {10.1098/rspl.1896.0076},
file = {:C$\backslash$:/Users/eribu/Downloads/Proc. R. Soc. Lond.-1896-Pearson-489-98.pdf:pdf},
isbn = {03701662},
issn = {0370-1662},
journal = {Proceedings of the Royal Society of London},
pages = {489--498},
title = {{Mathematical Contributions to the Theory of Evolution. - On a Form of Spurious Correlation Which May Arise When Indices Are Used in the Measurement of Organs}},
volume = {60},
year = {1896}
}
@article{Pearson1896,
annote = {http://www.amstat.org/publications/jse/v9n3/stanton.html

Tycks mena att detta {\"{a}}r k{\"{a}}llan vari {\&}quot;r{\&}quot; anv{\"{a}}nders f{\"{o}}rsta g{\aa}ngen!?},
author = {Pearson, Karl},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pearson - 1896 - Mathematical Contributions to the Theory of Evolution. III. Regression, Heredity, and Panmixia.pdf:pdf},
journal = {Philosophical transactions of the royal society A},
keywords = {article1},
mendeley-tags = {article1},
title = {{Mathematical Contributions to the Theory of Evolution. III. Regression, Heredity, and Panmixia}},
volume = {187},
year = {1896}
}
@article{Student1908,
abstract = {His question was answered by Messrs Yule and Hooker and Professor Edgeworth, all of whom considered that Mr Hooker was probably safe in taking'HO as his limit of significance for a sample of 21. They did not, however, answer Dr Shaw's question in any more ...},
author = {Student},
file = {:C$\backslash$:/Users/eribu/Downloads/student1908.pdf:pdf},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {2-3},
pages = {302--310},
title = {{Probable Error of a Correlation Coefficient}},
url = {http://biomet.oxfordjournals.org/cgi/doi/10.1093/biomet/6.2-3.302 papers2://publication/doi/10.1093/biomet/6.2-3.302},
volume = {6},
year = {1908}
}
@article{Soper1913,
author = {Soper, H. E.},
doi = {10.1093/biomet/9.1-2.91},
file = {:C$\backslash$:/Users/eribu/Downloads/2331802.pdf:pdf},
issn = {00063444},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {1-2},
pages = {91--115},
title = {{On the peobable error of the correlation coefficient to a second approximation}},
volume = {9},
year = {1913}
}
@article{Fisher1915,
abstract = {508 Distribution of the Correlation Coeffeients of Samples In the second of these two papers the more difficult problem of the frequency distribution of the correlation coefficient is attempted. For samples of 2 the frequency},
author = {Fisher, R.a. and Fisher, R.a.},
doi = {10.2307/2331838},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fisher, Fisher - 1915 - Frequency distribution of the values of the correlation coefficient in samples from an indefinitely large popula.pdf:pdf},
isbn = {0006-3444},
issn = {00063444},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {507--521},
title = {{Frequency distribution of the values of the correlation coefficient in samples from an indefinitely large population}},
url = {http://biomet.oxfordjournals.org/cgi/reprint/10/4/507.pdf},
volume = {10},
year = {1915}
}
@article{Coop1916,
author = {{Soper, HE and Young, AW and Cave, BM and Lee, Alice and Pearson}, Karl},
file = {:C$\backslash$:/Users/eribu/Downloads/2331830.pdf:pdf},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {328--413},
title = {{On the Distribution of the Correlation Coefficient in Small Samples. Appendix II to the Papers of "Student" and R. A. Fisher}},
volume = {11},
year = {1916}
}
@misc{Fisher1921,
abstract = {This is the second of three papers dealing with the sampling errors of correlation coefficients covering the cases (i) "The frequency distribution of the values of the correlation coeffricient in samples from an indefinitely large population", Biometrika, 1915.},
author = {Fisher, R A},
booktitle = {Metron},
file = {:C$\backslash$:/Users/eribu/Downloads/14.pdf:pdf},
keywords = {article1},
mendeley-tags = {article1},
number = {1-32},
pages = {205--235},
title = {{On the probable error of a coefficient of correlation deduced from a small samlpe}},
volume = {1},
year = {1921}
}
@article{Fisher1924a,
abstract = {Reproduced with permission of Metron 35 THE DISTRIBUTION OF THE PARTIAL CORRELATION COEFFICIENT .1. The theoretical . distribution In ascertaining the exact distribution iu random samples to which the correlation coefficient between two normally distributed vari{\^{a}}tes is ...},
author = {Fisher, R a},
journal = {Metron},
number = {3-4},
pages = {329--332},
title = {{The distribution of the partial correlation coefficient}},
volume = {3},
year = {1924}
}
@misc{Fisher1924,
abstract = {Reproduced with permission of Metron 35 THE DISTRIBUTION OF THE PARTIAL CORRELATION COEFFICIENT .1. The theoretical . distribution In ascertaining the exact distribution iu random samples to which the correlation coefficient between two normally distributed vari{\^{a}}tes is ...},
author = {Fisher, R a},
booktitle = {Metron},
file = {:C$\backslash$:/Users/eribu/Downloads/35.pdf:pdf},
keywords = {article1},
mendeley-tags = {article1},
number = {3-4},
pages = {329--332},
title = {{The distribution of the partial correlation coefficient}},
volume = {3},
year = {1924}
}
@article{Ezekei1929,
author = {Ezekei, Mordecai},
file = {:C$\backslash$:/Users/eribu/Downloads/2277015.pdf:pdf},
isbn = {0521773628},
journal = {Journal of the American Statistical Association},
keywords = {article1},
mendeley-tags = {article1},
number = {165},
pages = {99--104},
title = {{The Application of the Theory of Error to Multiple and Curvilinear Correlation}},
volume = {24},
year = {1929}
}
@article{Larson1931,
abstract = {A study is made, on 800 cases, of the shrinkage attendant upon using a regression equation derived from one group to predict the criterion scores of a second group. It is found that "the theoretically expected shrinkage of R as derived by the multiple correlation formula is a fact." The shrinkage increases as the number of variables increases and as the size of R decreases. The Smith formula for shrinkage-deduction parallels the empirical findings, but consistently yields higher values. The results upon increase in number of test variables suggest that test batteries may have definite limitations in size. (PsycINFO Database Record (c) 2006 APA, all rights reserved). © 1931 American Psychological Association.},
author = {Larson, S C},
doi = {10.1037/h0072400},
file = {:C$\backslash$:/Users/eribu/Downloads/edu{\_}22{\_}1{\_}45.pdf.pdf:pdf},
issn = {00220663 (ISSN)},
journal = {Journal of Educational Psychology},
keywords = {BIOMETRY AND STATISTICS,CORRELATION, MULTIPLE, SHRINKAGE,MULTIPLE,SHRINKAGE,article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {1},
pages = {45--55},
title = {{The shrinkage of the coefficient of multiple correlation}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0007318509{\&}partnerID=40{\&}md5=dc19e2f8fac696f27cb88e10bc8d38fe},
volume = {22},
year = {1931}
}
@article{Wherry1931,
abstract = {44¿ hORMULA POR (6) ?*.< *>' » егог NM and since 2 , by (2) above, we have s0 equa we have {\^{}} (7) -г f N(lt?z) f i-p2 1 N equal to (1 - {\^{}} 2 ), which is, exactly, the BB Smith (1). This has been widely used during the last few},
author = {Wherry, R},
file = {:C$\backslash$:/Users/eribu/Downloads/2957681.pdf:pdf},
journal = {The annals of mathematical statistics},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {4},
pages = {440--457},
title = {{A new formula for predicting the shrinkage of the coefficient of multiple correlation}},
url = {http://www.jstor.org/stable/2957681$\backslash$npapers2://publication/uuid/F3D4916B-BB98-4094-A459-DF4387AC9610},
volume = {2},
year = {1931}
}
@article{Wherry1931a,
abstract = {44¿ hORMULA POR  (6) ?*.< *>' » егог NM and since 2 , by (2) above, we have s0 equa we have {\^{}} (7) -г f N(lt?z) f i-p2 1 N equal to (1 - {\^{}} 2 ), which is, exactly, the BB Smith  (1). This  has been widely used during the last few },
author = {Wherry, R},
file = {:C$\backslash$:/Users/eribu/Downloads/2957681.pdf:pdf},
journal = {The annals of mathematical statistics},
number = {4},
pages = {440--457},
title = {{A new formula for predicting the shrinkage of the coefficient of multiple correlation}},
url = {http://www.jstor.org/stable/2957681$\backslash$npapers2://publication/uuid/F3D4916B-BB98-4094-A459-DF4387AC9610},
volume = {2},
year = {1931}
}
@article{Larson1931a,
abstract = {A study is made, on 800 cases, of the shrinkage attendant upon using a regression equation derived from one group to predict the criterion scores of a second group. It is found that "the theoretically expected shrinkage of R as derived by the multiple correlation formula is a fact." The shrinkage increases as the number of variables increases and as the size of R decreases. The Smith formula for shrinkage-deduction parallels the empirical findings, but consistently yields higher values. The results upon increase in number of test variables suggest that test batteries may have definite limitations in size. (PsycINFO Database Record (c) 2006 APA, all rights reserved). © 1931 American Psychological Association.},
author = {Larson, S C},
doi = {10.1037/h0072400},
file = {:C$\backslash$:/Users/eribu/Downloads/edu{\_}22{\_}1{\_}45.pdf.pdf:pdf},
issn = {00220663 (ISSN)},
journal = {Journal of Educational Psychology},
keywords = {BIOMETRY AND STATISTICS,CORRELATION, MULTIPLE, SHRINKAGE},
number = {1},
pages = {45--55},
title = {{The shrinkage of the coefficient of multiple correlation}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0007318509{\&}partnerID=40{\&}md5=dc19e2f8fac696f27cb88e10bc8d38fe},
volume = {22},
year = {1931}
}
@article{Rider1932,
abstract = {IT was the original purpose of this study to attempt to discover the effect upon the distribution in random samples, particularly in small samples, of the product-moment coefficient of correlation, r, when the samples are drawn from a non-normal instead of a normal population. In Part I the results of sampling from certain populations which differ greatly from the normal are given, also the results of sampling from a normal population having a high degree of correlation. As the sampling was done experimentally, it was necessary to deal with discrete populations. This opened up the question of the effect of grouping upon the distribution of r, a question which is investigated in Part II.},
author = {Rider, Paul R.},
file = {:C$\backslash$:/Users/eribu/Downloads/ref{\_}till{\_}coop1916/2331973.pdf:pdf},
journal = {Biometrika},
number = {3},
pages = {382--403},
title = {{On the Distribution of the correlation coefficient in small samples}},
volume = {24},
year = {1932}
}
@article{Rider1932a,
abstract = {IT was the original purpose of this study to attempt to discover the effect upon the distribution in random samples, particularly in small samples, of the product-moment coefficient of correlation, r, when the samples are drawn from a non-normal instead of a normal population. In Part I the results of sampling from certain populations which differ greatly from the normal are given, also the results of sampling from a normal population having a high degree of correlation. As the sampling was done experimentally, it was necessary to deal with discrete populations. This opened up the question of the effect of grouping upon the distribution of r, a question which is investigated in Part II.},
author = {Rider, Paul R.},
file = {:C$\backslash$:/Users/eribu/Downloads/ref{\_}till{\_}coop1916/2331973.pdf:pdf},
journal = {Biometrika},
number = {3},
pages = {382--403},
title = {{On the Distribution of the correlation coefficient in small samples}},
volume = {24},
year = {1932}
}
@article{Nair1941,
author = {Nair, A N Krishnan},
file = {:C$\backslash$:/Users/eribu/Downloads/ref{\_}till{\_}coop1916/25047705.pdf:pdf},
journal = {The Indian Journal of Statistics},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {383--400},
title = {{Distribution of Students 't' and the Correlation Coefficient in Samples from Non-Normal Populations}},
volume = {5},
year = {1941}
}
@article{Gayen1951,
author = {Gayen, A. K.},
file = {:C$\backslash$:/Users/eribu/Downloads/2332329.pdf:pdf},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {1/2},
pages = {219--247},
title = {{The Frequency Distribution of the Product-Moment Correlation Coefficient in Random Samples of Any Size Drawn from Non-Normal Universes}},
volume = {38},
year = {1951}
}
@article{Cowden1952,
abstract = {Abstract A partial correlation coefficient which is also a multiple correlation coefficient is discussed. Its relationship with other well-known coefficients is explained. Computational methods for computing the estimating equation and the correlation coefficient are suggested. * The writer wishes to thank Professors Harold Hotelling, George E. Nicholson, and John H. Smith for critically reading the manuscript and offering valuable comments. Professor Hotelling indicated the method of computation which he had suggested in an unpublished paper (see note 5). Professor Smith called the writer's attention to some of the earlier references to the subject in the literature. Since the first draft of this paper was written (June, 1951), it has been learned that Professor C. Horace Hamilton, of the North Carolina State College of Agriculture and Engineering, has written an article entitled ?Population Pressure and Other Factors Affecting Net Rural-Urban Migration,? in which the coefficient of multiple-partial correlation is used. This article appears in Social Forces, 30 (December, 1951), pp. 209?15. The formula used is that attributed by the present writer to John H. Smith (see note 7.)$\backslash$nAbstract A partial correlation coefficient which is also a multiple correlation coefficient is discussed. Its relationship with other well-known coefficients is explained. Computational methods for computing the estimating equation and the correlation coefficient are suggested. * The writer wishes to thank Professors Harold Hotelling, George E. Nicholson, and John H. Smith for critically reading the manuscript and offering valuable comments. Professor Hotelling indicated the method of computation which he had suggested in an unpublished paper (see note 5). Professor Smith called the writer's attention to some of the earlier references to the subject in the literature. Since the first draft of this paper was written (June, 1951), it has been learned that Professor C. Horace Hamilton, of the North Carolina State College of Agriculture and Engineering, has written an article entitled ?Population Pressure and Other Factors Affecting Net Rural-Urban Migration,? in which the coefficient of multiple-partial correlation is used. This article appears in Social Forces, 30 (December, 1951), pp. 209?15. The formula used is that attributed by the present writer to John H. Smith (see note 7.)},
author = {Cowden, Dudley J.},
doi = {10.1080/01621459.1952.10501183},
file = {:C$\backslash$:/Users/eribu/Downloads/2281314.pdf:pdf},
isbn = {01621459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {259},
pages = {442--456},
title = {{The Multiple-Partial Correlation Coefficient}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1952.10501183},
volume = {47},
year = {1952}
}
@article{Hotelling1953,
author = {Hotelling, Harold},
file = {:C$\backslash$:/Users/eribu/Downloads/2983768.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series B (Methodological),},
keywords = {article1},
mendeley-tags = {article1},
number = {2},
pages = {296--193--232},
title = {{New Light on the Correlation Coefficient and its Transforms Author(s): Harold Hotelling}},
volume = {15},
year = {1953}
}
@article{Olkin1958,
abstract = {This paper deals with the unbiased estimation of the correlation of two variates having a bivariate normal distribution (Sec. 2), and of the intraclass correlation, i.e., the common correlation coefficient of a {\$}p{\$}-variate normal distribution with equal variances and equal covariances (Sec. 3). In both cases, the estimator has the following properties. It is a function of a complete sufficient statistic and is therefore the unique (except for sets of probability zero) minimum variance unbiased estimator. Its range is the region of possible values of the estimated quantity. It is a strictly increasing function of the usual estimator differing from it only by terms of order {\$}1/n{\$} and consequently having the same asymptotic distribution. Since the unbiased estimators are cumbersome in form in that they are expressed as series or integrals, tables are included giving the unbiased estimators as functions of the usual estimators. In Sec. 4 we give an unbiased estimator of the squared multiple correlation. It ha...},
author = {Olkin, Ingram and Pratt, J.W.},
doi = {10.2307/2237306},
file = {:C$\backslash$:/Users/eribu/Downloads/2237306.pdf:pdf},
issn = {00034851},
journal = {The annals of mathematical statistics},
keywords = {article1},
mendeley-tags = {article1},
number = {1},
pages = {201--211},
title = {{Unbiased estimation of certain correlation coefficients}},
url = {http://www.jstor.org/pss/2237306$\backslash$nhttp://www.jstor.org/stable/10.2307/2237306},
volume = {29},
year = {1958}
}
@article{Olkin1958a,
abstract = {This paper deals with the unbiased estimation of the correlation of two variates having a bivariate normal distribution (Sec. 2), and of the intraclass correlation, i.e., the common correlation coefficient of a {\$}p{\$}-variate normal distribution with equal variances and equal covariances (Sec. 3). In both cases, the estimator has the following properties. It is a function of a complete sufficient statistic and is therefore the unique (except for sets of probability zero) minimum variance unbiased estimator. Its range is the region of possible values of the estimated quantity. It is a strictly increasing function of the usual estimator differing from it only by terms of order {\$}1/n{\$} and consequently having the same asymptotic distribution. Since the unbiased estimators are cumbersome in form in that they are expressed as series or integrals, tables are included giving the unbiased estimators as functions of the usual estimators. In Sec. 4 we give an unbiased estimator of the squared multiple correlation. It ha...},
author = {Olkin, Ingram and Pratt, J.W.},
file = {:C$\backslash$:/Users/eribu/Downloads/2237306.pdf:pdf},
journal = {The annals of mathematical statistics},
number = {1},
pages = {201--211},
title = {{Unbiased estimation of certain correlation coefficients}},
url = {http://www.jstor.org/pss/2237306$\backslash$nhttp://www.jstor.org/stable/10.2307/2237306},
volume = {29},
year = {1958}
}
@article{Seber1963,
author = {Seber, G A F},
file = {:C$\backslash$:/Users/eribu/Downloads/Seber1963.pdf:pdf},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {3},
pages = {542--544},
title = {{The Non-Central Chi-Squared and Beta Distributions}},
volume = {50},
year = {1963}
}
@article{Park1964,
author = {Park, John H Jr},
file = {:C$\backslash$:/Users/eribu/Downloads/2238295.pdf:pdf},
journal = {The Annals of Mathematical Statistics},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {1583--1593},
title = {{Variations of the Non-central t and Beta Distributions}},
volume = {35},
year = {1964}
}
@article{Ruben1966,
author = {Ruben, Harold},
file = {:C$\backslash$:/Users/eribu/Downloads/2984445.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series B (Methodological),},
keywords = {article1},
mendeley-tags = {article1},
number = {3},
pages = {513--525},
title = {{Some New Results on the Coefficient of the Sample Correlation Distribution}},
volume = {28},
year = {1966}
}
@article{Bartko1966,
abstract = {Discusses a procedure for estimating the reliability of sets of ratings in terms of the intraclass correlation coefficient, based upon analysis of variance and estimation of variance components. For the 1-way classification the intraclass correlation coefficient defined as the ratio of variances can be interpreted as a correlation coefficient. Caution, however, is urged in the application of the definition to a 2-way model, i.e., one in which between-rater variance is removed. It is maintained that the frequent use of the standard definition of the 1-way intraclass correlation coefficient applied to the 1-way classification is not a proper procedure if in fact the coefficient is to be interpreted as a correlation coefficient. Definitions for reliability obtained from the 2-way models are given which can legitimately be considered correlation coefficients. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
author = {Bartko, J J},
doi = {10.2466/pr0.1966.19.1.3},
isbn = {0031-5125},
issn = {0033-2941},
journal = {Psychological reports},
keywords = {multiple correlation},
mendeley-tags = {multiple correlation},
number = {1},
pages = {3--11},
pmid = {5942109},
title = {{The intraclass correlation coefficient as a measure of reliability.}},
volume = {19},
year = {1966}
}
@article{Hogben1968,
author = {Hogben, David},
doi = {10.6028/jres.072B.007},
file = {:C$\backslash$:/Users/eribu/Downloads/jresv72Bn1p33{\_}A1b.pdf:pdf},
issn = {0098-8979},
journal = {Journal of Research of the National Bureau of Standards, Section B: Mathematical Sciences},
keywords = {anal ysis of variance,article1,calibrali on,co rrelation coeffi cie,degrees of free dom,di s-,e,fix ed vari abl,nonce ntral beta variabl,noncentrality,nt,q variate,tribution},
mendeley-tags = {article1},
number = {1},
pages = {33},
title = {{The distribution of the sample correlation coefficient with one variable fixed}},
volume = {72B},
year = {1968}
}
@article{Kymn1968,
author = {Kymn, Kern O .},
file = {:C$\backslash$:/Users/eribu/Downloads/1909612.pdf:pdf},
journal = {Econometrica},
keywords = {article1},
mendeley-tags = {article1},
number = {1},
pages = {187--189},
title = {{The Distribution of the Sample Correlation Coefficient Under the Null Hypothesis}},
volume = {36},
year = {1968}
}
@article{Ramanathan1969,
author = {Ramanathan},
doi = {10.2307/2286841},
file = {:C$\backslash$:/Users/eribu/Downloads/2281314.pdf:pdf},
journal = {journal of American Statistical Association},
number = {325},
pages = {90--101},
title = {{Journal of the American Statistical}},
volume = {64},
year = {1969}
}
@article{Warren1971,
abstract = {A quantitative study is made of the bias in the usual estimate of the linear correlation coefficient and of the relative efficiency of the estimated regression, when a certain type of selective sampling is employed. A good compromise seems difficult to obtain and it is the author's thesis that the simultaneous presentation of regression equations and correlation coefficients is, in a sense, contradictory.},
author = {Warren, W. G.},
doi = {10.2307/2346463},
file = {:C$\backslash$:/Users/eribu/Downloads/2346463.pdf:pdf},
issn = {00359254},
journal = {Applied Statistics},
keywords = {article1},
mendeley-tags = {article1},
number = {2},
pages = {148},
title = {{Correlation or Regression: Bias or Precision}},
url = {http://www.jstor.org/stable/2346463$\backslash$nhttp://www.jstor.org/stable/10.2307/2346463?origin=crossref},
volume = {20},
year = {1971}
}
@article{Warren1971a,
abstract = {A quantitative study is made of the bias in the usual estimate of the linear correlation coefficient and of the relative efficiency of the estimated regression, when a certain type of selective sampling is employed. A good compromise seems difficult to obtain and it is the author's thesis that the simultaneous presentation of regression equations and correlation coefficients is, in a sense, contradictory.},
author = {Warren, W. G.},
doi = {10.2307/2346463},
file = {:C$\backslash$:/Users/eribu/Downloads/2346463.pdf:pdf},
issn = {00359254},
journal = {Applied Statistics},
number = {2},
pages = {148},
title = {{Correlation or Regression: Bias or Precision}},
url = {http://www.jstor.org/stable/2346463$\backslash$nhttp://www.jstor.org/stable/10.2307/2346463?origin=crossref},
volume = {20},
year = {1971}
}
@article{Kowalski1972,
abstract = {Samples from non-normal bivariate distributions are simulated and the densities of the sample product-moment correlation coefficient, r, estimated and compared with the corresponding normal theory densities. The results are contrasted with the literature on the subject and an attempt is made to reconcile some of the earlier conflicting conclusions regarding the robustness of the distribution of r.},
author = {Kowalski, Charles J.},
doi = {10.2307/2346598},
file = {:C$\backslash$:/Users/eribu/Downloads/2346598.pdf:pdf},
issn = {00359254},
journal = {Journal of the Royal Statistical Society},
keywords = {article1,density estimation,distribution of correlation coefficient,non-normality,robustness,transformations},
mendeley-tags = {article1},
number = {1},
pages = {1--12},
title = {{On the Effects of Non-Normality on the Distribution of the Sample Product-Moment Correlation Coefficient}},
url = {http://www.jstor.org/stable/10.2307/2346598?origin=crossref},
volume = {21},
year = {1972}
}
@article{Crocker1972,
annote = {doi: 10.1080/00031305.1972.10477345},
author = {Crocker, Douglas C},
doi = {10.1080/00031305.1972.10477345},
file = {:C$\backslash$:/Users/eribu/Downloads/2683460.pdf:pdf},
issn = {0003-1305},
journal = {The American Statistician},
keywords = {article1},
mendeley-tags = {article1},
month = {apr},
number = {2},
pages = {31--33},
publisher = {Taylor {\&} Francis},
title = {{Some Interpretations of the Multiple Correlation Coefficient}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00031305.1972.10477345},
volume = {26},
year = {1972}
}
@article{Barrett1974,
abstract = {Many scientists find the coefficient of determination (squared multiple correlation coefficient) a useful index in regression analyses. As with most indices, however, too much can be read into the coefficient of determination. Some scientists use it as a measure of “usefulness” or “goodness of fit” of a regression equation. Actuzlly the coefficient of determination only partially measures the usefulness of a regression equation; it also only partially measures goodness of fit in the sense of how close data points fit the regression surface. Examples are given illustrating the limits of the coefficient of determination and suggesting that graphs and confidence intervals me needed in a more complete evaluation of a regression equation.},
author = {Barrett, James P},
doi = {10.1080/00031305.1974.10479056},
file = {:C$\backslash$:/Users/eribu/Downloads/2683523.pdf:pdf},
isbn = {00031305},
issn = {0003-1305},
journal = {The American Statistician},
keywords = {article1},
mendeley-tags = {article1},
month = {feb},
number = {1},
pages = {19--20},
title = {{The Coefficient of Determination—Some Limitations}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00031305.1974.10479056},
volume = {28},
year = {1974}
}
@article{Konishi1978,
author = {Konishi, Sandnori},
file = {:C$\backslash$:/Users/eribu/Downloads/2335923.pdf:pdf},
journal = {Biometrika},
keywords = {article1},
mendeley-tags = {article1},
number = {3},
pages = {654--656},
title = {{An Approximation to the Distribution of the Sample Correlation Coefficient}},
volume = {65},
year = {1978}
}
@article{Claudy1978,
author = {Claudy, J. G.},
doi = {10.1177/014662167800200414},
file = {:C$\backslash$:/Users/eribu/Downloads/Applied Psychological Measurement-1978-Claudy-595-607.pdf:pdf},
issn = {0146-6216},
journal = {Applied Psychological Measurement},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {595--607},
title = {{Multiple Regression and Validity Estimation in One Sample}},
volume = {2},
year = {1978}
}
@article{Alam1979,
author = {Alam, Kursheed},
file = {:C$\backslash$:/Users/eribu/Downloads/ADA048126.pdf:pdf},
journal = {Naval Research Logistics Quarterl},
keywords = {article1},
mendeley-tags = {article1},
pages = {237--330},
title = {{Distribution of sample correlation coefficients}},
volume = {26},
year = {1979}
}
@article{Cattin1980,
abstract = {There are two ways to estimate the predictive power of a regression model: a cross-validation procedure and a formula. A number of formulas have been derived. A review of the literature leads to four (unbiased or least biased) formulas, each one appropriate depending on whether the predictor variables are fixed or random and on the measure needed, that is, a measure of the absolute error (the mean squared error of prediction) or of the relative error (the cross-validated multiple correlation). The advantages of these formulas over cross-validation are that they are less cumbersome to use and that they produce more precise estimates. The conditions under which it is appropriate to use these formulas are discussed as well as their use for comparing the predictive power of regression, subjective and equal weights. [ABSTRACT FROM AUTHOR]},
author = {Cattin, Philippe},
doi = {10.1037//0021-9010.65.4.407},
issn = {0021-9010},
journal = {Journal of Applied Psychology},
keywords = {ANALYSIS of variance,CORRELATION (Statistics),MATHEMATICAL statistics,REGRESSION analysis,article1},
mendeley-tags = {article1},
number = {4},
pages = {407--414},
title = {{Estimation of the Predictive Power of a Regression Model}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=bth{\&}AN=5133443{\&}site=ehost-live{\&}scope=site},
volume = {65},
year = {1980}
}
@article{Huberty1980,
author = {Huberty, Carl J and Mourad, Salah A},
file = {:C$\backslash$:/Users/eribu/Downloads/Educational and Psychological Measurement-1980-Huberty-101-12.pdf:pdf},
journal = {Educational and Psychological Measurement},
keywords = {article1},
mendeley-tags = {article1},
pages = {101--112},
title = {{Estimation in multiple correlation/prediction}},
volume = {40},
year = {1980}
}
@article{Efron1983,
abstract = {We construct a prediction rule on the basis of some data, and then wish to estimate the error rate of this rule in classifying future observations. Cross-validation provides a nearly unbiased estimate, using only the original data. Cross-validation turns out to be related ... $\backslash$n},
author = {Efron, Bradley},
doi = {10.1080/01621459.1983.10477973},
isbn = {01621459},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {anova,article1,bootstrap,decomposition,logistic regression,prediction problem},
mendeley-tags = {article1},
number = {382},
pages = {316},
title = {{Estimating the Error Rate of a Prediction Rule: Improvement on Cross-Validation}},
url = {http://www.jstor.org/stable/2288636?origin=crossref$\backslash$npapers3://publication/doi/10.2307/2288636},
volume = {78},
year = {1983}
}
@article{Kvalseth1985,
abstract = {Abstract The coefficient of determination (R 2) is perhaps the single most extensively used measure of goodness of fit for regression models. It is also widely misused. The primary source of the problem is that except for linear models with an intercept term, the several alternative R 2 statistics are not generally equivalent. This article discusses various considerations and potential pitfalls in using the R 2's. Specific points are exemplified by means of empirical data. A new resistant statistic is also introduced.},
author = {Kv{\aa}lseth, Tarald O.},
doi = {10.1080/00031305.1985.10479448},
file = {:C$\backslash$:/Users/eribu/Downloads/2683704.pdf:pdf},
isbn = {0003-1305},
issn = {0003-1305},
journal = {American Statistician},
keywords = {article1,coefficient},
mendeley-tags = {article1},
number = {4},
pages = {279--285},
title = {{Cautionary Note about R2}},
url = {http://dx.doi.org/10.1080/00031305.1985.10479448},
volume = {39},
year = {1985}
}
@article{Ozer1985,
abstract = {Contends that both the interpretation of an effect size and the actual estimation of a coefficient of determination are partially theory-dependent. Two theoretical models for the variables cases are considered. In a variety of circumstances where the square of the correlation is used, the required assumptions are not tenable. In the alternate model, the absolute value of the correlation provides a coefficient of determination. The correlation coefficient is recommended for use as an effect-size indicator, because evaluating effect size in terms of variance accounted for may lead to interpretations that grossly underestimate the magnitude of a relation. (25 ref) (PsycINFO Database Record (c) 2010 APA )},
author = {Ozer, Daniel J.},
doi = {10.1037/0033-2909.97.2.307},
isbn = {0033-2909},
issn = {0033-2909},
journal = {Psychological Bulletin},
keywords = {article1},
mendeley-tags = {article1},
number = {2},
pages = {307--315},
title = {{Correlation and the coefficient of determination.}},
volume = {97},
year = {1985}
}
@article{Wood1986,
author = {Wood, Robert},
doi = {10.1080/0141192860120303},
file = {:C$\backslash$:/Users/eribu/Downloads/Think Before you Square Correlations or do anything with them.pdf:pdf},
isbn = {0141192860},
issn = {0141-1926},
journal = {British Educational Research Journal},
keywords = {article1},
mendeley-tags = {article1},
number = {3},
pages = {249--255},
title = {{Think Before you Square Correlations—or do anything with them}},
url = {http://doi.wiley.com/10.1080/0141192860120303},
volume = {12},
year = {1986}
}
@article{Cramer1987,
abstract = {We derive and use easily computable expressions for the mean and variance of R2 in the standard linear regression model with fixed regressors. In respect to its probability limit R2 is seriously biased upward in small samples; the0 ‘adjusted’ R̄2 does much better. But at sample sizes where these distinctions matter both measures are thoroughly unreliable because of their large dispersion. R2 should not be quoted for samples of less than fifty observations.},
author = {Cramer, J.S.},
doi = {10.1016/0304-4076(87)90027-3},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {article1},
mendeley-tags = {article1},
month = {jul},
number = {2-3},
pages = {253--266},
title = {{Mean and variance of R2 in small and moderate samples}},
url = {http://www.sciencedirect.com/science/article/pii/0304407687900273},
volume = {35},
year = {1987}
}
@article{Rodgers1988,
abstract = {In 1885, Sir Francis Galton first defined the term "regression" and completed the theory of bivariate correlation. A decade later, Karl Pearson developed the index that we still use to measure correlation, Pearson's r. Our article is written in recognition of the 100th anniversary of Galton's first discussion of regression and correlation. We begin with a brief history. Then we present 13 different formulas, each of which represents a different computational and conceptual definition of r. Each formula suggests a different way of thinking about this index, from algebraic, geometric, and trigonometric settings. We show that Pearson's r (or simple functions of r) may variously be thought of as a special type of mean, a special type of variance, the ratio of two means, the ratio of two variances, the slope of a line, the cosine of an angle, and the tangent to an ellipse, and may be looked at from several other interesting perspectives.},
archivePrefix = {arXiv},
arxivId = {Rodgers, J. L., {\&} Nicewander, W. A. (2008). Thirteen Ways to Look at the Correlation Coefficient, 42(1), 59–66.},
author = {Rodgers, Joseph Lee and Nicewander, W. Alan},
doi = {10.2307/2685263},
eprint = {Rodgers, J. L., {\&} Nicewander, W. A. (2008). Thirteen Ways to Look at the Correlation Coefficient, 42(1), 59–66.},
isbn = {00031305},
issn = {00031305},
journal = {The American Statistician},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {1},
pages = {59 -- 66},
pmid = {2685263},
title = {{Thirteen Ways to Look at the Correlation Coefficient}},
url = {http://www.jstor.org/stable/2685263},
volume = {42},
year = {1988}
}
@article{Hawkins1989,
abstract = {Hogg, RV, and Craig, AT (1978), Introduction to Mathematical Sta- tistics (4th ed.), New York: Macmillan. Pitman, EG (1939), "A Note on Normal CorTelation," Biomnetrika, 31, 9-12. Snedecor, GW, and Cochran, WG (1980), Statistical Methods (7th ed.), Ames: Iowa State},
author = {Hawkins, D},
doi = {10.2307/2685369},
file = {:C$\backslash$:/Users/eribu/Downloads/2685369.pdf:pdf},
issn = {00031305},
journal = {American Statistician},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {235--237},
title = {{Using U statistics to derive the asymptotic distribution of Fisher's Z statistic}},
url = {http://www.jstor.org/stable/2685369$\backslash$npapers3://publication/uuid/25473EA2-360A-4031-870D-0A90BCE030FF},
volume = {43},
year = {1989}
}
@article{Taylor1990,
abstract = {A basic consideration in the evaluation of professional medical literature is being able to understand the statistical analysis presented. One of the more frequently reported statistical methods involves correlation analysis where a correlation coefficient is reported representing the degree of linear association between two variables. This article discusses the basic aspects of correlation analysis with examples given from professional journals and focuses on the interpretations and limitations of the correlation coefficient. No attention was given to the actual calculation of this statistical value.},
author = {Taylor, R.},
doi = {10.1177/875647939000600106},
isbn = {8756479390006},
issn = {8756-4793},
journal = {Journal of Diagnostic Medical Sonography},
keywords = {article1,articles cannot be undertaken,coefficient of determination,correlation coefficient,medical or scientific journal,r coefficient,regression equation,the review of any,without being},
mendeley-tags = {article1},
pages = {35--39},
title = {{Interpretation of the Correlation Coefficient: A Basic Review}},
volume = {6},
year = {1990}
}
@article{Nagelkerke1991,
abstract = {A generalization of the coefficient of determination R2 to general regression models is discussed. A modification of an earlier definition to allow for discrete models is proposed.},
author = {Nagelkerke, N. J D},
doi = {10.1093/biomet/78.3.691},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nagelkerke - 1991 - A note on a general definition of the coefficient of determination.pdf:pdf},
isbn = {0006-3444},
issn = {00063444},
journal = {Biometrika},
keywords = {Discrete probability,Log likelihood,Multiple correlation coefficient,Regression model,Residual variation,article1},
mendeley-tags = {article1},
number = {3},
pages = {691--692},
pmid = {339},
title = {{A note on a general definition of the coefficient of determination}},
volume = {78},
year = {1991}
}
@article{Faraway1992,
abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org. A regression analysis usually consists of several stages, such as variable selec-tion, transformation and residual diagnosis. Inference is often made from the selected model without regard to the model selection methods that preceeded it. This can result in overoptimistic and biased inferences. We first characterize data-analytic actions as functions acting on regression models. We investigate the extent of the problem and test bootstrap, jackknife, and sample-splitting methods for ameliorating it. We also demon-strate an interactive LISP-STAT system for assessing the cost of the data analysis while it is taking place.},
author = {Faraway, Julian J},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Faraway - 1992 - Interface Foundation of America On the Cost of Data Analysis On the Cost of Data Analysis.pdf:pdf},
journal = {Source: Journal of Computational and Graphical Statistics},
keywords = {Bootstrap,Data splitting,Jackknife,Model selection,Regression analysis},
number = {3},
pages = {213--229},
title = {{Interface Foundation of America On the Cost of Data Analysis On the Cost of Data Analysis}},
url = {http://www.jstor.org http://www.jstor.org/stable/1390717 http://www.jstor.org/stable/1390717?seq=1{\&}cid=pdf-reference{\#}references{\_}tab{\_}contents http://www.jstor.org/page/},
volume = {1},
year = {1992}
}
@article{Greco1992a,
author = {Greco, Luigi and Cassino, Universitgt},
file = {:C$\backslash$:/Users/eribu/Downloads/ref{\_}till{\_}coop1916/art{\%}3A10.1007{\%}2FBF02589036.pdf:pdf},
keywords = {correlation coefficient,normal bi-variate popula-,probability distributions},
pages = {289--294},
title = {{THE PROBABILITY INTEGRAL OF THE SAMPLE CORRELATION COEFFICIENT Ik- {\~{}}}},
year = {1992}
}
@article{Greco1992,
author = {Greco, Luigi},
file = {:C$\backslash$:/Users/eribu/Downloads/ref{\_}till{\_}coop1916/art{\%}3A10.1007{\%}2FBF02589036.pdf:pdf},
journal = {J. ltaL Statist. Soc.},
keywords = {article1,correlation coefficient,normal bi-variate popula-,probability distributions},
mendeley-tags = {article1},
pages = {289--294},
title = {{THE PROBABILITY INTEGRAL OF THE SAMPLE CORRELATION COEFFICIENT Ik- {\~{}}}},
volume = {2},
year = {1992}
}
@article{Kohavi1995,
abstract = {We review accuracy estimation methods and compare the two most common methods: cross-validation and bootstrap. Recent experimen-tal results on artiicial data and theoretical re-sults in restricted settings have shown that for selecting a good classiier from a set of classi-(model selection), ten-fold cross-validation may be better than the more expensive leave-one-out cross-validation. We report on a large-scale experiment|over half a million runs of C4.5 and a Naive-Bayes algorithm|to estimate the eeects of diierent parameters on these al-gorithms on real-world datasets. For cross-validation, we vary the number of folds and whether the folds are stratiied or not; for boot-strap, we vary the number of bootstrap sam-ples. Our results indicate that for real-word datasets similar to ours, the best method to use for model selection is ten-fold stratiied cross validation, even if computation power allows using more folds.},
author = {Kohavi, Ron},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kohavi - 1995 - A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection.pdf:pdf},
title = {{A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection}},
url = {http://robotics.stanford.edu/{~}ronnyk},
year = {1995}
}
@article{Efron1997,
abstract = {A study investigates the error rate of a rule for predicting future responses constructed from a training set of data. Results are nonparametric and apply to any possible prediction rule.},
annote = {Handlar om Bootstrap .632+ (vilket kanske {\"{a}}nnu inte {\"{a}}r helt relevant f{\"{o}}r oss).

Utv{\"{a}}rderar p{\aa} 24 olika modeller presenteade i tabell. Varierar sample size och dimensionality som vi. Dock stor skillnad att det baseras p{\aa} classification och inte regression. 

Anv{\"{a}}nder mindre samlpe sizes {\"{a}}n vi och fler variabler (st{\"{o}}rre p).

Har inte l{\"{a}}st s{\aa} noggrant d{\aa} den inte k{\"{a}}nns helt relevant och {\"{a}}r ganska teoretisk med mkt notation etc.},
author = {Efron, B. and Tibshirani, R.},
doi = {10.1080/01621459.1997.10474007},
file = {:C$\backslash$:/Users/eribu/Downloads/01621459{\%}2E1997{\%}2E10474007.pdf:pdf},
isbn = {0162-1459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {article1,classification,cross-validation bootstrap,prediction rule},
mendeley-tags = {article1},
number = {438},
pages = {548},
pmid = {370},
title = {{Improvements on cross-validation: The .632 plus bootstrap method}},
volume = {92},
year = {1997}
}
@article{Efron1997a,
author = {Efron, Bradley and Tibshirani, Robert},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Efron, Tibshirani - 1997 - Improvements on Cross-Validation The .632 Bootstrap Method.pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {438},
pages = {548--560},
title = {{Improvements on Cross-Validation: The .632+ Bootstrap Method}},
url = {http://links.jstor.org/sici?sici=0162-1459{\%}28199706{\%}2992{\%}3A438{\%}3C548{\%}3AIOCT.B{\%}3E2.0.CO{\%}3B2-I},
volume = {92},
year = {1997}
}
@article{Charles1997,
abstract = {Shared decision-making is increasingly advocated as an ideal model of treatment decision-making in the medical encounter. To date, the concept has been rather poorly and loosely defined. This paper attempts to provide greater conceptual clarity about shared treatment decision-making, identify some key characteristics of this model, and discuss measurement issues. The particular decision-making context that we focus on is potentially life threatening illnesses, where there are important decisions to be made at key points in the disease process, and several treatment options exist with different possible outcomes and substantial uncertainty. We suggest as key characteristics of shared decision-making (1) that at least two participants-physician and patient be involved; (2) that both parties share information; (3) that both parties take steps to build a consensus about the preferred treatment; and (4) that an agreement is reached on the treatment to implement. Some challenges to measuring shared decision-making are discussed as well as potential benefits of a shared decision-making model for both physicians and patients.},
author = {Charles, Cathy and Gafni, Amiram and Whelan, Tim},
doi = {10.1016/S0277-9536(96)00221-3},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Charles, Gafni, Whelan - 1997 - Shared decision-making in the medical encounter What does it mean (Or it takes, at least two to tango).pdf:pdf},
isbn = {0277-9536 (Print)$\backslash$r0277-9536 (Linking)},
issn = {02779536},
journal = {Social Science and Medicine},
keywords = {Physician/Patient communication,Shared treatment decision-making},
pmid = {9032835},
title = {{Shared decision-making in the medical encounter: What does it mean? (Or it takes, at least two to tango)}},
year = {1997}
}
@article{ShigekazuNakagawa1997,
author = {{Shigekazu Nakagawa}, Naoto Niki},
file = {:C$\backslash$:/Users/eribu/Downloads/110001235586.pdf:pdf},
keywords = {article1,mixed conductors,p-t-x,perovskites,thermodynamic stability},
mendeley-tags = {article1},
number = {97},
title = {{Distribution of the sample correlation coefficient for nonnormal populations}},
volume = {2738},
year = {1997}
}
@article{Heskes1997,
abstract = {We propose a new method to compute prediction intervals. Especially for small data sets the width of a prediction interval does not only de-pend on the variance of the target distribution, but also on the accuracy of our estimator of the mean of the target, i.e., on the width of the con-dence interval. The conndence interval follows from the variation in an ensemble of neural networks, each of them trained and stopped on bootstrap replicates of the original data set. A second improvement is the use of the residuals on validation patterns instead of on training patterns for estimation of the variance of the target distribution. As illustrated on a synthetic example, our method is better than existing methods with regard to extrapolation and interpolation in data regimes with a limited amount of data, and yields prediction intervals which actual conndence levels are closer to the desired conndence levels.},
author = {Heskes, Tom},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Heskes - 1997 - Practical conndence and prediction intervals.pdf:pdf},
pages = {176--182},
publisher = {MIT Press},
title = {{Practical conndence and prediction intervals}},
year = {1997}
}
@article{KepplingerHansMathiasHabermeier1995,
author = {Raju, Nambury S and Bilgic, Reyhan and Edwards, Jack E and Fleer, Paul F},
file = {:C$\backslash$:/Users/eribu/Downloads/Applied Psychological Measurement-1997-Raju-291-305.pdf:pdf},
journal = {Applied Psychological Measurement},
keywords = {article1},
mendeley-tags = {article1},
number = {4},
pages = {291--305},
title = {{Methodology Review: Estimation of population validity and cross-validity, and the use of equal weights in prediction}},
volume = {21},
year = {1997}
}
@article{Jr1998,
author = {Jr, Frank E Harrell},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jr - 1998 - Comparison of Strategies for Validating Binary Logistic Regression Models.pdf:pdf},
journal = {Statistics},
keywords = {article1},
mendeley-tags = {article1},
title = {{Comparison of Strategies for Validating Binary Logistic Regression Models}},
year = {1998}
}
@article{Jevsevar1999,
author = {Jevsevar, David S and Bozic, Kevin J},
doi = {10.1007/s11999-015-4336-4},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jevsevar, Bozic - 1999 - Orthopaedic Healthcare Worldwide Using Clinical Practice Guidelines in Clinical Decision Making.pdf:pdf},
title = {{Orthopaedic Healthcare Worldwide: Using Clinical Practice Guidelines in Clinical Decision Making}},
year = {1999}
}
@article{Berliner1999,
abstract = {Background Despite the overall effectiveness of total hip arthroplasty (THA), a subset of patients remain dissatisfied with their results because of persistent pain or functional limitations. It is therefore important to develop predictive tools capable of identifying patients at risk for poor out-comes before surgery. Questions/purposes The purpose of this study was to use preoperative patient-reported outcome measure (PROM) scores to predict which patients undergoing THA are most likely to experience a clinically meaningful change in functional outcome 1 year after surgery. Methods A retrospective cohort study design was used to evaluate preoperative and 1-year postoperative SF-12 ver-sion 2 (SF12v2) and Hip Disability and Osteoarthritis Outcome Score (HOOS) scores from 537 selected patients who underwent primary unilateral THA. Minimum clini-cally important differences (MCIDs) were calculated using a distribution-based method. A receiver operating charac-teristic analysis was used to calculate threshold values, defined as the levels at which substantial changes occurred, and their predictive ability. MCID values for HOOS and SF12v2 physical component summary (PCS) scores were calculated to be 9.1 and 4.6, respectively. We analyzed the effect of SF12v2 mental component summary (MCS) scores, which measure mental and emotional health, on SF12v2 PCS and HOOS threshold values. Results Threshold values for preoperative HOOS and PCS scores were a maximum of 51.0 (area under the curve [AUC], 0.74; p $\backslash$ 0.001) and 32.5 (AUC, 0.62; p $\backslash$ 0.001), respectively. As preoperative mental and emotional health improved, which was reflected by a higher MCS score, HOOS and PCS threshold values also increased. When preoperative mental and emotional health were taken into},
author = {Berliner, Jonathan L and {Brodke Ba}, Dane J and {Chan Mph}, Vanessa and Soohoo, Nelson F and Bozic, Kevin J and Berliner, J L and Brodke, D J and Chan, V and Lee, Philip R and Soohoo, N F and Bozic, K J},
doi = {10.1007/s11999-015-4350-6},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Berliner et al. - 1999 - John Charnley Award Preoperative Patient-reported Outcome Measures Predict Clinically Meaningful Improvement in.pdf:pdf},
journal = {Clinical Orthopaedics and Related Research®},
pages = {321--329},
title = {{John Charnley Award Preoperative Patient-reported Outcome Measures Predict Clinically Meaningful Improvement in Function After THA Clinical Orthopaedics and Related Research ®}},
volume = {474},
year = {1999}
}
@article{Algina1999,
abstract = {Four methods for constructing 100(1 - alpha){\%} confidence intervals$\backslash$nfor the population squared multiple correlation coefficient (rho(2))$\backslash$nwere compared. In one method the confidence interval was constructed$\backslash$nby using the distribution of R-2. Provided rho(2) > 0 the coverage$\backslash$nprobability for this method is exactly 1 - alpha when the data are$\backslash$nmultivariate normal. The other three methods are based on results$\backslash$nin Olkin and Finn (1995) and are approximate. Results show that each$\backslash$nof the approximate methods works very poorly for some combinations$\backslash$nof rho(2). The method based on the distribution of R-2 is recommended.},
author = {Algina, James},
doi = {10.1207/S15327906MBR3404{\_}5},
issn = {0027-3171},
journal = {Multivariate Behavioral Research},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {4},
pages = {493--504},
title = {{A Comparison of Methods for Constructing Confidence Intervals for the Squared Multiple Correlation Coefficient}},
url = {http://www.tandfonline.com/doi/abs/10.1207/S15327906MBR3404{\_}5},
volume = {34},
year = {1999}
}
@article{Raju1999,
abstract = {An empirical monte carlo study was performed using predictor and criterion data from 84,808 U.S. Air Force enlistees. 501 samples were drawn for each of seven sample size conditions: 25, 40, 60, 80, 100, 150, and 200. Using an eight-predictor model, 500 estimates for each of 9 validity and 11 cross-validity estimation procedures were generated for each sample size condition. These estimates were then compared to the actual squared population validity and cross-validity in terms of mean bias and mean squared bias. For the regression models determined using ordinary least squares, the Ezekiel procedure produced the most accurate estimates of squared population validity (followed by the Smith and the Wherry procedures), and Burket’s formula resulted in the best estimates of squared population cross-validity. Other analyses compared the coefficients determined by traditional empirical cross-validation and equal weights; equal weights resulted in no loss of predictive accuracy and less shrinkage. Numerous issues for future basic research on validation and cross-validation are identified.},
author = {Raju, N S and Bilgic, R and Edwards, J E and Fleer, P F},
doi = {10.1177/01466219922031220},
file = {:C$\backslash$:/Users/eribu/Downloads/Applied Psychological Measurement-1999-Raju-99-115.pdf:pdf},
isbn = {0146-6216},
issn = {0146-6216},
journal = {Applied Psychological Measurement},
keywords = {article1},
mendeley-tags = {article1},
number = {2},
pages = {99--115},
title = {{Accuracy of Population Validity and Cross-Validity Estimation: An Empirical Comparison of Formula-Based, Traditional Empirical, and Equal Weights Procedures}},
url = {http://apm.sagepub.com/content/23/2/99},
volume = {23},
year = {1999}
}
@inproceedings{Altman2000,
abstract = {Prognostic models are used in medicine for investigating patient outcome in relation to patient and disease characteristics. Such models do not always work well in practice, so it is widely recommended that they need to be validated. The idea of validating a prognostic model is generally taken to mean establishing that it works satisfactorily for patients other than those from whose data it was derived. In this paper we examine what is meant by validation and review why it is necessary. We consider how to validate a model and suggest that it is desirable to consider two rather different aspects - statistical and clinical validity - and examine some general approaches to validation. We illustrate the issues using several case studies.},
author = {Altman, Douglas G. and Royston, Patrick},
booktitle = {Statistics in Medicine},
doi = {10.1002/(SICI)1097-0258(20000229)19:4<453::AID-SIM350>3.0.CO;2-5},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Altman, Royston - 2000 - What do we mean by validating a prognostic model.pdf:pdf},
isbn = {0277-6715 (Print) 0277-6715 (Linking)},
issn = {02776715},
pmid = {10694730},
title = {{What do we mean by validating a prognostic model?}},
year = {2000}
}
@article{Carpenter2000,
abstract = {Since the early 1980s, a bewildering array of methods for constructing bootstrap confidence intervals have been proposed. In this article, we address the following questions. First, when should bootstrap confidence intervals be used. Secondly, which method should be chosen, and thirdly, how should it be implemented. In order to do this, we review the common algorithms for resampling and methods for constructing bootstrap confidence intervals, together with some less well known ones, highlighting their strengths and weaknesses. We then present a simulation study, a flow chart for choosing an appropriate method and a survival analysis example.},
author = {Carpenter, James and Bithell, John},
doi = {10.1002/(SICI)1097-0258(20000515)19:9<1141::AID-SIM479>3.0.CO;2-F},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Carpenter, Bithell - 2000 - Bootstrap confidence intervals When, which, what A practical guide for medical statisticians.pdf:pdf},
isbn = {0277-6715},
issn = {02776715},
journal = {Statistics in Medicine},
pmid = {10797513},
title = {{Bootstrap confidence intervals: When, which, what? A practical guide for medical statisticians}},
year = {2000}
}
@article{Priebe2000,
abstract = {We describe and investigate a data-driven procedure for obtaining parsimonious mixture model estimates or, conversely, kernel estimates with data-driven local smoothing properties. The main idea is to obtain a semiparametric estimate by alternating between the parametric and nonparametric viewpoints. (C) 2000 Elsevier Science B.V. All rights reserved.},
author = {Priebe, Carey E. and Marchette, David J.},
doi = {10.1016/S0167-9473(00)00003-7},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Priebe, Marchette - 2000 - Alternating kernel and mixture density estimates.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {Kernel estimator,Mixture model,Semiparametric},
title = {{Alternating kernel and mixture density estimates}},
year = {2000}
}
@article{Steyerberg2001,
abstract = {The performance of a predictive model is overestimated when simply determined on the sample of subjects that was used to construct the model. Several internal validation methods are available that aim to provide a more accurate estimate of model performance in new subjects. We evaluated several variants of split-sample, cross-validation and bootstrapping methods with a logistic regression model that included eight predictors for 30-day mortality after an acute myocardial infarction. Random samples with a size between n = 572 and n = 9165 were drawn from a large data set (GUSTO-I; n = 40,830; 2851 deaths) to reflect modeling in data sets with between 5 and 80 events per variable. Independent performance was determined on the remaining subjects. Performance measures included discriminative ability, calibration and overall accuracy. We found that split-sample analyses gave overly pessimistic estimates of performance, with large variability. Cross-validation on 10{\%} of the sample had low bias and low variability, but was not suitable for all performance measures. Internal validity could best be estimated with bootstrapping, which provided stable estimates with low bias. We conclude that split-sample validation is inefficient, and recommend bootstrapping for estimation of internal validity of a predictive logistic regression model.},
annote = {Tipsad av Szilard.

fokuserad p{\aa} logistisk regression.

Utg{\aa}r fr{\aa}n praktiskt exempel med hj{\"{a}}rtattack. 
V{\aa}r ansats {\"{a}}r mer teoretisk/generell.
J{\"{a}}mf{\"{o}}r med olika EPV-v{\"{a}}rden och stratifiering.
Resamplar 500 ggr.
stepwise model selection med 8 predektorer.

Utv{\"{a}}rderar flera olika m{\"{a}}tv{\"{a}}rden, inkl R2 (dock Negelkerke).

Olika metoder men inte jack-knife.

F{\aa}r delvis samma slutsats som vi ang {\"{o}}verskattning med cv.},
author = {Steyerberg, Ewout W and Harrell, Frank E and Borsboom, Gerard J.J.M and Eijkemans, M.J.C and Vergouwe, Yvonne and Habbema, J.Dik F},
doi = {10.1016/S0895-4356(01)00341-9},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Steyerberg et al. - 2001 - Internal validation of predictive models.pdf:pdf},
issn = {08954356},
journal = {Journal of Clinical Epidemiology},
keywords = {Bootstrapping,Internal validation,Logistic regression analysis,Predictive models,article1,harrell,statistics},
mendeley-tags = {article1,harrell,statistics},
month = {aug},
number = {8},
pages = {774--781},
title = {{Internal validation of predictive models}},
url = {http://www.sciencedirect.com/science/article/pii/S0895435601003419},
volume = {54},
year = {2001}
}
@article{Rabin2001,
abstract = {Zimbabwe. The process o f shared development and local experimentation resulted in EQ-5D, a generic measure of health status that provides a simple descriptive profile and a single index value that can be used in the clinical and economic evaluation o f health care and in population health surveys. Currently, EQ-5D is being widely used in different countries by clinical researchers in a variety o f clinical areas. EQ-5D is also being used by eight out o f the first 10 o f the top 50 pharmaceutical companies listed in the annual report o f Pharma Business (November/ December 1999). Furthermore, EQ-5D is one o f the handful o f measures recommended for use in cost-effectiveness analyses by the Washington Panel on Cost Effectiveness in Health and Medicine. EQ-5D has now been translated into most major languages with the EuroQol Group closely monitoring the process.},
author = {Rabin, Rosalind and {De Charro}, Frank},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rabin, De Charro - 2001 - EQ-SD a measure of health status from the EuroQol Group.pdf:pdf},
journal = {Ann Med},
keywords = {EQ-5D,EuroQol Group,application,health status measurement,translation,valuation},
pages = {337--343},
title = {{EQ-SD: a measure of health status from the EuroQol Group}},
volume = {33},
year = {2001}
}
@article{Breiman2001,
abstract = {There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commit-ment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current prob-lems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.},
annote = {Denna artikel {\"{a}}r kritisk mot modellering och f{\"{o}}redrar i likhet med Kuhn att utg{\aa} fr{\aa}n accuracy meassure, inte model validering, d{\aa} detta ofta inte l{\aa}ter sig g{\"{o}}ras s{\aa} l{\"{a}}tt.

Inneh{\aa}ller ocks{\aa} kommentarer fr{\aa}n ett flertal auktoriteter p{\aa} omr{\aa}det samt d{\"{a}}refter ett avslutande svar fr{\aa}n f{\"{o}}rfattaren.},
author = {Breiman, Leo},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Breiman - 2001 - Statistical Modeling The Two Cultures.pdf:pdf},
journal = {Statistical Science},
keywords = {article1,statistics},
mendeley-tags = {article1,statistics},
number = {3},
pages = {199--231},
title = {{Statistical Modeling: The Two Cultures}},
volume = {16},
year = {2001}
}
@article{Yin2001,
abstract = {Abstract The effectiveness of various analytical formulas for estimating R 2 shrinkage in multiple regression analysis was investigated. Two categories of formulas were identified: estimators of the squared population multiple correlation coefficient ($\rho$2) and those of the squared population cross-validity coefficient ($\rho$c 2). The authors conducted a Monte Carlo experiment to investigate the effectiveness of the analytical formulas for estimating R 2 shrinkage, with 4 fully crossed factors (squared population multiple correlation coefficient, number of predictors, sample size, and degree of multicollinearity) and 500 replications in each cell. The results indicated that the most widely used Wherry formula (in both SAS and SPSS) is probably not the most effective analytical formula for estimating $\rho$2. Instead, the Pratt formula and the Browne formula outperformed other analytical formulas in estimating $\rho$2 and $\rho$c 2, respectively.},
author = {Yin, Ping and Fan, Xitao},
doi = {10.1080/00220970109600656},
file = {:C$\backslash$:/Users/eribu/Downloads/Estimating R 2 Shrinkage in Multiple Regression A Comparison of Different Analytical Methods.pdf:pdf},
isbn = {0022097010960},
issn = {0022-0973},
journal = {The Journal of Experimental Education},
keywords = {Cross-validation,Monte Carlo method,R 1 shrinkage,article1,multiple regression,statistical bias},
mendeley-tags = {article1},
number = {2},
pages = {203--224},
title = {{Estimating R 2 Shrinkage in Multiple Regression: A Comparison of Different Analytical Methods}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00220970109600656},
volume = {69},
year = {2001}
}
@article{Algina2001,
abstract = {The increase in the squared multiple correlation coefficient (DeltaR(2))$\backslash$nassociated with a variable in a regression equation is a commonly$\backslash$nused measure of importance in regression analysis. The probability$\backslash$nthat an asymptotic confidence interval will include Delta rho (2)$\backslash$nwas investigated. With sample sizes typically used in regression$\backslash$nanalyses, when Delta rho (2) = 0.00 and the confidence level is .95$\backslash$nor greater, the probability will be at least .999. For Delta rho$\backslash$n(2) greater than or equal to .01 and a confidence level of .95 or$\backslash$ngreater, the probability will be smaller than the nominal confidence$\backslash$nlevel. For Delta rho (2) greater than or equal to .05 and a confidence$\backslash$nlevel of .95, tables are provided for the sample size necessary for$\backslash$nthe probability to be at least .925 and to be at least .94.},
author = {Algina, J. and Moulder, B. C.},
doi = {10.1177/00131640121971400},
issn = {0013-1644},
journal = {Educational and Psychological Measurement},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {4},
pages = {633--649},
title = {{Sample Sizes for Confidence Intervals on the Increase in the Squared Multiple Correlation Coefficient}},
volume = {61},
year = {2001}
}
@incollection{Bobko2001,
abstract = {After reading this chapter, you should be able to : Explain what a correlation coefficient measures. Recognize a scatterplot and understand the direction or sign of the relationship. Understand the formula for the Pearson correlation, including where the important information is and the purpose of the denominator. Provide at least two situations where r not appropriate for describing a relationship. Given any particular value of r and the raw data, multiply one or both scales by 38.2 and still know the value of the correlation. Give examples of how outliers can increase or decrease a correlation. Critique the following statement: “The correlation of .82 demonstrates that good supervisors cause increased worker productivity.” Explain why range restriction generally reduces the magnitude of r . Discuss how different levels of analysis can affect r . Recognize factors that are important in interpreting the magnitude of r . Explain what r 2 Define ... },
author = {Bobko, Philip},
booktitle = {Correlation and Regression: Applications for Industrial Organizational Psychology and Management.},
doi = {10.4135/9781412983815},
isbn = {Print ISBN: 9780761923039$\backslash$rOnline ISBN: 9781412983815},
pages = {12--42},
title = {{A Review of the Correlation Coefficient and its Properties}},
year = {2001}
}
@article{Mittlbock2002,
abstract = {The proportion of explained variation in logistic regression can be expressed by the multiple R 2 originally developed for the general linear model (cf. MITTLBOCK and SCHEMPER (1996)). In this paper we present a detailed investigation of this measure in small samples and/or with many covariates and propose either of two adjustments, one being a direct analogue of R-adj(2) of the general linear model, and the other being based on shrinkage. Furthermore, we explore the use of bootstrap confidence intervals and give a table of the expected variability of estimates of explained variation for samples of varying sizes. We recommend to quantify gains of predictive precision due to prognostic factors by both relative and absolute measures. For binary outcomes the components of the relative measure, R-2, are suitable absolute measures of predictive precision. They are interpretable as average absolute residuals conditional on using prognostic factors and without such information. We motivate application of the presented measures by the statistical analysis of a study of physical characteristics of urine possibly related to the presence of calcium oxalate crystals.},
author = {Mittlb{\"{o}}ck, M. and Schemper, M.},
doi = {10.1002/1521-4036(200204)44:3<263::AID-BIMJ263>3.0.CO;2-7},
isbn = {0323-3847},
issn = {03233847},
journal = {Biometrical Journal},
keywords = {Prediction error,Predictive accuracy,Proportion of explained variation,R2 measures,Shrinkage},
number = {3},
pages = {263--272},
title = {{Explained variation for logistic regression - Small sample adjustments, confidence intervals and predictive precision}},
volume = {44},
year = {2002}
}
@article{,
abstract = {Bootstrapping is a general approach to statistical inference based on building a sampling distribution for a statistic by resampling from the data at hand. The term 'bootstrapping,' due to Efron (1979), is an allusion to the expression 'pulling oneself up by one's bootstraps' – in this case, using the sample data as a population from which repeated samples are drawn. At first blush, the approach seems circular, but has been shown to be sound. Two S libraries for bootstrapping are associated with extensive treatments of the subject: Efron and Tibshirani's (1993) bootstrap library, and Davison and Hinkley's (1997) boot library. Of the two, boot, programmed by A. J. Canty, is somewhat more capable, and will be used for the examples in this appendix. There are several forms of the bootstrap, and, additionally, several other resampling methods that are related to it, such as jackknifing, cross-validation, randomization tests, and permutation tests. I will stress the nonparametric bootstrap. Suppose that we draw a sample S = {\{}X 1 , X 2 , ..., X n {\}} from a population P = {\{}x 1 , x 2 , ..., x N {\}}; imagine further, at least for the time being, that N is very much larger than n, and that S is either a simple random sample or an independent random sample from P; 1 I will briefly consider other sampling schemes at the end of the appendix. It will also help initially to think of the elements of the population (and, hence, of the sample) as scalar values, but they could just as easily be vectors (i.e., multivariate). Now suppose that we are interested in some statistic T = t(S) as an estimate of the corresponding population parameter $\theta$ = t(P). Again, $\theta$ could be a vector of parameters and T the corresponding vector of estimates, but for simplicity assume that $\theta$ is a scalar. A traditional approach to statistical inference is to make assumptions about the structure of the population (e.g., an assumption of normality), and, along with the stipulation of random sampling, to use these assumptions to derive the sampling distribution of T , on which classical inference is based. In certain instances, the exact distribution of T may be intractable, and so we instead derive its asymptotic distribution. This familiar approach has two potentially important deficiencies: 1. If the assumptions about the population are wrong, then the corresponding sampling distribution of the statistic may be seriously inaccurate. On the other hand, if asymptotic results are relied upon, these may not hold to the required level of accuracy in a relatively small sample.},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2002 - Bootstrapping Regression Models.pdf:pdf},
title = {{Bootstrapping Regression Models}},
year = {2002}
}
@article{Barnhart2002,
abstract = {Accurate and precise measurement is an important component of any proper study design. As elaborated by Lin (1989, Biometrics 45, 255-268), the concordance correlation coefficient (CCC) is more appropriate than other indices for measuring agreement when the variable of interest is continuous. However, this agreement index is defined in the context of comparing two fixed observers. In order to use multiple observers in a study involving large numbers of subjects, there is a need to assess agreement among these multiple observers. In this article, we present an overall CCC (OCCC) in terms of the interobserver variability for assessing agreement among multiple fixed observers. The OCCC turns out to be equivalent to the generalized CCC (King and Chinchilli, 2001, Statistics in Medicine 20, 2131-2147; Lin, 1989; Lin, 2000, Biometrics 56, 324-325) when the squared distance function is used. We evaluated the OCCC through generalized estimating equations (Barnhart and Williamson, 2001, Biometrics 57, 931-940) and U-statistics (King and Chinchilli, 2001) for inference. This article offers the following important points. First, it addresses the precision and accuracy indices as components of the OCCC. Second, it clarifies that the OCCC is the weighted average of all pairwise CCCs. Third, it is intuitively defined in terms of interobserver variability. Fourth, the inference approaches of GEE and the U-statistics are compared via simulations for small samples. Fifth, we illustrate the use of the OCCC by two medical examples with the GEE, U-statistics, and bootstrap approaches.},
author = {Barnhart, H X and Haber, M and Song, J},
doi = {10.1111/j.0006-341X.2002.01020.x},
isbn = {0006-341X (Print)},
issn = {0006-341X},
journal = {Biometrics},
keywords = {Agreement,Overall concordance correlation coefficient,Reproducibility,article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {4},
pages = {1020--1027},
pmid = {12495158},
title = {{Overall concordance correlation coefficient for evaluating agreement among multiple observers}},
volume = {58},
year = {2002}
}
@article{Zimmerman2003,
author = {Zimmerman, Donald W and Zumbo, Bruno D and Williams, Richard H},
file = {:C$\backslash$:/Users/eribu/Downloads/9.ZUMBO.pdf:pdf},
issn = {02112159},
journal = {Transformation},
keywords = {article1},
mendeley-tags = {article1},
number = {1},
pages = {133--158},
title = {{Bias in estimation and hypothesis testing of correlation}},
url = {http://redalyc.uaemex.mx/redalyc/html/169/16924109/16924109.html$\backslash$nhttp://www.uv.es/psicologica/articulos1.03/9.ZUMBO.pdf},
volume = {24},
year = {2003}
}
@article{Ferro2003,
author = {Ferro, Christopher A T and Segers, Johan},
file = {:C$\backslash$:/Users/eribu/Downloads/2983768 (1).pdf:pdf},
journal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
number = {2},
pages = {545--556},
title = {{Journal of the {\{}R{\}}oyal {\{}S{\}}tatistical {\{}S{\}}ociety: {\{}S{\}}eries {\{}B{\}} ({\{}S{\}}tatistical {\{}M{\}}ethodology)}},
volume = {65},
year = {2003}
}
@article{Croux2003,
abstract = {Many robust regression estimators are defined by minimizing a measure of spread of the residuals. An accompanying R{\^{}}2-measure, or multiple correlation coefficient, is then easily obtained. In this paper, local robustness properties of these robust R{\^{}}2-coefficients are investigated. It is also shown how confidence intervals for the population multiple correlation coefficient can be constructed in the case of multivariate normality.},
author = {Croux, Christophe and Dehon, Catherine},
doi = {10.1007/s00362-003-0158-7},
issn = {0932-5026},
journal = {Statistical Papers},
keywords = {R{\^{}}2 measure,article1,influence function,multiple correlation,multiple correlation coefficient,regression analysis,robustness},
mendeley-tags = {article1,multiple correlation},
number = {3},
pages = {315--334},
title = {{Estimators of the multiple correlation coefficient: Local robustness and confidence intervals}},
url = {http://www.springerlink.com/index/jl8n427176112777.pdf$\backslash$nhttp://www.springerlink.com/index/10.1007/s00362-003-0158-7},
volume = {44},
year = {2003}
}
@article{Zimmerman2003a,
abstract = {This study examined bias in the sample correlation coefficient, r, and its correction by unbiased estimators. Computer simulations revealed that the expected value of correlation coefficients in samples from a normal population is slightly less than the population correlation, {\&}{\#}961;, and that the bias is almost eliminated by an estimator suggested by R.A. Fisher and is more completely eliminated by a related estimator recommended by Olkin and Pratt. Transformation of initial scores to ranks and calculation of the Spearman rank correlation, rS, produces somewhat greater bias. Type I error probabilities of significance tests of zero correlation based on the Student t statistic and exact tests based on critical values of rS obtained from permutations remain fairly close to the significance level for normal and several non-normal distributions. However, significance tests of non-zero values of correlation based on the r to Z transformation are grossly distorted for distributions that violate bivariate normality. Also, significance tests of non-zero values of rS based on the r to Z transformation are distorted even for normal distributions.},
author = {Zimmerman, D and Zumbo, B and Williams, R},
issn = {02112159},
journal = {Psicologica},
keywords = {article1},
mendeley-tags = {article1},
number = {24},
pages = {133--158},
title = {{Bias in Estimation and Hypothesis Testing of Correlation}},
url = {http://www.redalyc.org/articulo.oa?id=16924109SL},
volume = {24},
year = {2003}
}
@article{Braga-Neto2004,
abstract = {MOTIVATION: Microarray classification typically possesses two striking attributes: (1) classifier design and error estimation are based on remarkably small samples and (2) cross-validation error estimation is employed in the majority of the papers. Thus, it is necessary to have a quantifiable understanding of the behavior of cross-validation in the context of very small samples. RESULTS: An extensive simulation study has been performed comparing cross-validation, resubstitution and bootstrap estimation for three popular classification rules-linear discriminant analysis, 3-nearest-neighbor and decision trees (CART)-using both synthetic and real breast-cancer patient data. Comparison is via the distribution of differences between the estimated and true errors. Various statistics for the deviation distribution have been computed: mean (for estimator bias), variance (for estimator precision), root-mean square error (for composition of bias and variance) and quartile ranges, including outlier behavior. In general, while cross-validation error estimation is much less biased than resubstitution, it displays excessive variance, which makes individual estimates unreliable for small samples. Bootstrap methods provide improved performance relative to variance, but at a high computational cost and often with increased bias (albeit, much less than with resubstitution).},
author = {Braga-Neto, Ulisses M. and Dougherty, Edward R.},
doi = {10.1093/bioinformatics/btg419},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Braga-Neto, Dougherty - 2004 - Is cross-validation valid for small-sample microarray classification.pdf:pdf},
isbn = {1367-4803},
issn = {13674803},
journal = {Bioinformatics},
pmid = {14960464},
title = {{Is cross-validation valid for small-sample microarray classification?}},
year = {2004}
}
@article{Fu2005,
abstract = {MOTIVATION: Estimation of misclassification error has received increasing attention in clinical diagnosis and bioinformatics studies, especially in small sample studies with microarray data. Current error estimation methods are not satisfactory because they either have large variability (such as leave-one-out cross-validation) or large bias (such as resubstitution and leave-one-out bootstrap). While small sample size remains one of the key features of costly clinical investigations or of microarray studies that have limited resources in funding, time and tissue materials, accurate and easy-to-implement error estimation methods for small samples are desirable and will be beneficial.$\backslash$n$\backslash$nRESULTS: A bootstrap cross-validation method is studied. It achieves accurate error estimation through a simple procedure with bootstrap resampling and only costs computer CPU time. Simulation studies and applications to microarray data demonstrate that it performs consistently better than its competitors. This method possesses several attractive properties: (1) it is implemented through a simple procedure; (2) it performs well for small samples with sample size, as small as 16; (3) it is not restricted to any particular classification rules and thus applies to many parametric or non-parametric methods.},
author = {Fu, Wenjiang J. and Carroll, Raymond J. and Wang, Suojin},
doi = {10.1093/bioinformatics/bti294},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fu, Carroll, Wang - 2005 - Estimating misclassification error with small samples via bootstrap cross-validation.pdf:pdf},
isbn = {1367-4803 (Print)$\backslash$r1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
keywords = {article1},
mendeley-tags = {article1},
pmid = {15691862},
title = {{Estimating misclassification error with small samples via bootstrap cross-validation}},
year = {2005}
}
@article{FarzipoorSean2005,
abstract = {In some of the papers on data envelopment analysis (DEA), there have been explained that if correlation coefficient between each pair of input (output) vectors is strong and positive, one of the input (output) vector could be omitted. The objective of this paper is to determine correlation coefficient threshold that beyond which omission of one or more input vectors have no statistically significant effect on the efficiency mean. The threshold identification in terms of some of the DEA models including CCR, CCRCSW, BCC and BCCCSW are performed. To analyze the data, analysis of variance (ANOVA) is used. ?? 2004 Published by Elsevier Inc.},
author = {{Farzipoor Sean}, R. and Memariani, A. and Lotfi, F. Hosseinzadeh},
doi = {10.1016/j.amc.2003.12.117},
isbn = {0096-3003},
issn = {00963003},
journal = {Applied Mathematics and Computation},
keywords = {Analysis of variance,Correlation coefficient,Data envelopment analysis,article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {2},
pages = {503--521},
title = {{The effect of correlation coefficient among multiple input vectors on the efficiency mean in data envelopment analysis}},
volume = {162},
year = {2005}
}
@book{Faraway2005,
abstract = {The book focuses on the practice of regression and analysis of variance. It clearly demonstrates the different methods available and in which situations each one applies. It covers all of the standard topics, from the basics of estimation to missing data, factorial designs, and block designs, but it also includes discussion of topics, such as model uncertainty, rarely addressed in books of this type. The presentation incorporates an abundance of examples that clarify both the use of each technique and the conclusions one can draw from the results.},
author = {Faraway, Julian J.},
booktitle = {Library},
isbn = {1584884258},
keywords = {article1},
mendeley-tags = {article1},
pages = {1--229},
title = {{Linear Models with R}},
url = {http://www.stat.lsa.umich.edu/{~}faraway/LMR/},
year = {2005}
}
@article{Association2005,
author = {Association, Statistical},
file = {:C$\backslash$:/Users/eribu/Downloads/adj r2.pdf:pdf},
isbn = {0521773628},
keywords = {article1},
mendeley-tags = {article1},
number = {471},
pages = {99--104},
title = {{Journal of the American Statistical Association, Vol. 100, No. 471, September 2005.}},
volume = {100},
year = {2005}
}
@inproceedings{Makoul2006,
abstract = {Objective: Given the fluidity with which the term shared decision making (SDM) is used in teaching, assessment and research, we conducted a focused and systematic review of articles that specifically address SDM to determine the range of conceptual definitions. Methods: In April 2005, we ran a Pubmed (Medline) search to identify articles published through 31 December 2003 with the words shared decision making in the title or abstract. The search yielded 681 citations, 342 of which were about SDM in the context of physician-patient encounters and published in English. We read and reviewed the full text of all 342 articles, and got any non-redundant references to SDM, which yielded an additional 76 articles. Results: Of the 418 articles examined, 161 (38.5{\%}) had a conceptual definition of SDM. We identified 31 separate concepts used to explicate SDM, but only "patient values/preferences" (67.1{\%}) and "options" (50.9{\%}) appeared in more than half the 161 definitions. Relatively few articles explicitly recognized and integrated previous work. Conclusion: Our review reveals that there is no shared definition of SDM. We propose a definition that integrates the extant literature base and outlines essential elements that must be present for patients and providers to engage in the process of SDM. Practice implications: The integrative definition of SDM is intended to provide a useful foundation for describing and operationalizing SDM in further research. ?? 2005 Elsevier Ireland Ltd. All rights reserved.},
author = {Makoul, Gregory and Clayman, Marla L.},
booktitle = {Patient Education and Counseling},
doi = {10.1016/j.pec.2005.06.010},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Makoul, Clayman - 2006 - An integrative model of shared decision making in medical encounters.pdf:pdf},
isbn = {0738-3991},
issn = {07383991},
keywords = {Physician-patient relationship,Shared decision making},
pmid = {16051459},
title = {{An integrative model of shared decision making in medical encounters}},
year = {2006}
}
@article{Burton2006,
abstract = {Simulation studies use computer intensive procedures to assess the performance of a variety of statistical methods in relation to a known truth. Such evaluation cannot be achieved with studies of real data alone. Designing high-quality simulations that reflect the complex situations seen in practice, such as in prognostic factors studies, is not a simple process. Unfortunately, very few published simulation studies provide sufficient details to allow readers to understand fully all the processes required to design a simulation study. When planning a simulation study, it is recommended that a detailed protocol be produced, giving full details of how the study will be performed, analysed and reported. This paper details the important considerations necessary when designing any simulation study, including defining specific objectives of the study, determining the procedures for generating the data sets and the number of simulations to perform. A checklist highlighting the important considerations when designing a simulation study is provided. A small review of the literature identifies the current practices within published simulation studies. Copyright © 2006 John Wiley {\&} Sons, Ltd.},
author = {Burton, Andrea and Altman, Douglas G. and Royston, Patrick and Holder, Roger L.},
doi = {10.1002/sim.2673},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Burton et al. - 2006 - The design of simulation studies in medical statistics.pdf:pdf},
isbn = {2007090091480},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Bias,Coverage,Design,Mean square error,Protocol,Simulation study},
pmid = {16947139},
title = {{The design of simulation studies in medical statistics}},
year = {2006}
}
@article{Bioinformatics2006,
abstract = {Background: Cross-validation (CV) is an effective method for estimating the prediction error of a classifier. Some recent articles have proposed methods for optimizing classifiers by choosing classifier parameter values that minimize the CV error estimate. We have evaluated the validity of using the CV error estimate of the optimized classifier as an estimate of the true error expected on independent data. Results: We used CV to optimize the classification parameters for two kinds of classifiers; Shrunken Centroids and Support Vector Machines (SVM). Random training datasets were created, with no difference in the distribution of the features between the two classes. Using these "null" datasets, we selected classifier parameter values that minimized the CV error estimate. 10-fold CV was used for Shrunken Centroids while Leave-One-Out-CV (LOOCV) was used for the SVM. Independent test data was created to estimate the true error. With "null" and "non null" (with differential expression between the classes) data, we also tested a nested CV procedure, where an inner CV loop is used to perform the tuning of the parameters while an outer CV is used to compute an estimate of the error. The CV error estimate for the classifier with the optimal parameters was found to be a substantially biased estimate of the true error that the classifier would incur on independent data. Even though there is no real difference between the two classes for the "null" datasets, the CV error estimate for the Shrunken Centroid with the optimal parameters was less than 30{\%} on 18.5{\%} of simulated training data-sets. For SVM with optimal parameters the estimated error rate was less than 30{\%} on 38{\%} of "null" data-sets. Performance of the optimized classifiers on the independent test set was no better than chance. The nested CV procedure reduces the bias considerably and gives an estimate of the error that is very close to that obtained on the independent testing set for both Shrunken Centroids and SVM classifiers for "null" and "non-null" data distributions. Conclusion: We show that using CV to compute an error estimate for a classifier that has itself been tuned using CV gives a significantly biased estimate of the true error. Proper use of CV for estimating true error of a classifier developed using a well defined algorithm requires that all steps of the algorithm, including classifier parameter tuning, be repeated in each CV loop. A nested CV procedure provides an almost unbiased estimate of the true error.},
author = {Bioinformatics, Bmc and Varma, Sudhir and Simon, Richard},
doi = {10.1186/1471-2105-7-91},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bioinformatics, Varma, Simon - 2006 - Bias in error estimation when using cross-validation for model selection.pdf:pdf},
journal = {BMC Bioinformatics},
keywords = {article1},
mendeley-tags = {article1},
number = {7},
title = {{Bias in error estimation when using cross-validation for model selection}},
url = {http://www.biomedcentral.com/1471-2105/7/91},
volume = {7},
year = {2006}
}
@article{Asuero2006,
abstract = {Correlation and regression are different, but not mutually exclusive, techniques. Roughly, regression is used for prediction (which does not extrapolate beyond the data used in the analysis) whereas correlation is used to determine the degree of association. There situations in which the x variable is not fixed or readily chosen by the experimenter, but instead is a random covariate to the y variable. This paper shows the relationships between the coefficient of determination, the multiple correlation coefficient, the covariance, the correlation coefficient and the coefficient of alienation, for the case of two related variables x and y. It discusses the uses of the correlation coefficient r, either as a way to infer correlation, or to test linearity. A number of graphical examples are provided as well as examples of actual chemical applications. The paper recommends the use of z Fisher transformation instead of r values because r is not normally distributed but z is (at least in approximation). For either correlation or for regression models, the same expressions are valid, although they differ significantly in meaning. Correlation and regression are different, but not mutually exclusive, techniques. Roughly, regression is used for prediction (which does not extrapolate beyond the data used in the analysis) whereas correlation is used to determine the degree of association. There situations in which the x variable is not fixed or readily chosen by the experimenter, but instead is a random covariate to the y variable. This paper shows the relationships between the coefficient of determination, the multiple correlation coefficient, the covariance, the correlation coefficient and the coefficient of alienation, for the case of two related variables x and y. It discusses the uses of the correlation coefficient r, either as a way to infer correlation, or to test linearity. A number of graphical examples are provided as well as examples of actual chemical applications. The paper recommends the use of z Fisher transformation instead of r values because r is not normally distributed but z is (at least in approximation). For either correlation or for regression models, the same expressions are valid, although they differ significantly in meaning.},
author = {Asuero, a. G. and Sayago, A. and Gonz{\'{a}}lez, a. G.},
doi = {10.1080/10408340500526766},
file = {:C$\backslash$:/Users/eribu/Downloads/The Correlation Coefficient An Overview.pdf:pdf},
isbn = {1040-8347},
issn = {1040-8347},
journal = {Critical Reviews in Analytical Chemistry},
keywords = {article1,cause and effect,correlation coefficient,covariance,inference,lineariy,multiple correlation,multiple correlation coefficient,significance tests},
mendeley-tags = {article1,multiple correlation},
number = {July},
pages = {41--59},
pmid = {19702027},
title = {{The Correlation Coefficient: An Overview}},
volume = {36},
year = {2006}
}
@misc{Gonz??lez2006,
abstract = {The use of the correlation coefficient for testing the linearity of calibration curves is performed according to the ANOVA checking of the lack-of-fit. The procedure is illustrated from a case study.},
author = {Gonz??lez, A. Gustavo and Herrador, M. ??ngeles and Asuero, Agust??n G. and Sayago, Ana},
booktitle = {Accreditation and Quality Assurance},
doi = {10.1007/s00769-006-0153-5},
isbn = {0949-1775},
issn = {09491775},
keywords = {Coefficient of determination,Correlation coefficient,Lack-of-fit,Linearity,article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {5},
pages = {256--258},
title = {{The correlation coefficient attacks again}},
volume = {11},
year = {2006}
}
@article{Asuero2006a,
abstract = {Correlation and regression are different, but not mutually exclusive, techniques. Roughly, regression is used for prediction (which does not extrapolate beyond the data used in the analysis) whereas correlation is used to determine the degree of association. There situations in which the x variable is not fixed or readily chosen by the experimenter, but instead is a random covariate to the y variable. This paper shows the relationships between the coefficient of determination, the multiple correlation coefficient, the covariance, the correlation coefficient and the coefficient of alienation, for the case of two related variables x and y. It discusses the uses of the correlation coefficient r, either as a way to infer correlation, or to test linearity. A number of graphical examples are provided as well as examples of actual chemical applications. The paper recommends the use of z Fisher transformation instead of r values because r is not normally distributed but z is (at least in approximation). For either correlation or for regression models, the same expressions are valid, although they differ significantly in meaning. Correlation and regression are different, but not mutually exclusive, techniques. Roughly, regression is used for prediction (which does not extrapolate beyond the data used in the analysis) whereas correlation is used to determine the degree of association. There situations in which the x variable is not fixed or readily chosen by the experimenter, but instead is a random covariate to the y variable. This paper shows the relationships between the coefficient of determination, the multiple correlation coefficient, the covariance, the correlation coefficient and the coefficient of alienation, for the case of two related variables x and y. It discusses the uses of the correlation coefficient r, either as a way to infer correlation, or to test linearity. A number of graphical examples are provided as well as examples of actual chemical applications. The paper recommends the use of z Fisher transformation instead of r values because r is not normally distributed but z is (at least in approximation). For either correlation or for regression models, the same expressions are valid, although they differ significantly in meaning.},
author = {Asuero, a. G. and Sayago, a. and Gonz{\'{a}}lez, a. G.},
journal = {Critical Reviews in Analytical Chemistry},
keywords = {cause and effect,correlation coefficient,covariance,inference,lineariy,multiple correlation coefficient,significance tests},
number = {July},
pages = {41--59},
title = {{The Correlation Coefficient: An Overview}},
volume = {36},
year = {2006}
}
@article{Asuero2006b,
abstract = {Correlation and regression are different, but not mutually exclusive, techniques. Roughly, regression is used for prediction (which does not extrapolate beyond the data used in the analysis) whereas correlation is used to determine the degree of association. There situations in which the x variable is not fixed or readily chosen by the experimenter, but instead is a random covariate to the y variable. This paper shows the relationships between the coefficient of determination, the multiple correlation coefficient, the covariance, the correlation coefficient and the coefficient of alienation, for the case of two related variables x and y. It discusses the uses of the correlation coefficient r, either as a way to infer correlation, or to test linearity. A number of graphical examples are provided as well as examples of actual chemical applications. The paper recommends the use of z Fisher transformation instead of r values because r is not normally distributed but z is (at least in approximation). For either correlation or for regression models, the same expressions are valid, although they differ significantly in meaning. Correlation and regression are different, but not mutually exclusive, techniques. Roughly, regression is used for prediction (which does not extrapolate beyond the data used in the analysis) whereas correlation is used to determine the degree of association. There situations in which the x variable is not fixed or readily chosen by the experimenter, but instead is a random covariate to the y variable. This paper shows the relationships between the coefficient of determination, the multiple correlation coefficient, the covariance, the correlation coefficient and the coefficient of alienation, for the case of two related variables x and y. It discusses the uses of the correlation coefficient r, either as a way to infer correlation, or to test linearity. A number of graphical examples are provided as well as examples of actual chemical applications. The paper recommends the use of z Fisher transformation instead of r values because r is not normally distributed but z is (at least in approximation). For either correlation or for regression models, the same expressions are valid, although they differ significantly in meaning.},
author = {Asuero, a. G. and Sayago, a. and Gonz{\'{a}}lez, a. G.},
doi = {10.1080/10408340500526766},
file = {:C$\backslash$:/Users/eribu/Downloads/The Correlation Coefficient An Overview.pdf:pdf},
isbn = {1040-8347},
issn = {1040-8347},
journal = {Critical Reviews in Analytical Chemistry},
keywords = {cause and effect,correlation coefficient,covariance,inference,lineariy,multiple correlation coefficient,significance tests},
number = {July},
pages = {41--59},
pmid = {19702027},
title = {{The Correlation Coefficient: An Overview}},
volume = {36},
year = {2006}
}
@misc{Weinstein2007,
abstract = {The risks and benefits of any health care intervention are valued differently by stakeholders. One of the ethical imperatives of patient-centered care is the balanced, evidence-based presentation of risks and benefits by providers to patients. Using the example of musculoskeletal surgery with devices, we advocate the use of shared decision-making tools and processes known to improve knowledge, adjust unrealistic expectations, and elicit values about benefits desired and the degree of acceptable risks for individual patients. We describe feasibility and efficacy within our organization and address ways to foster the further adoption of this approach.},
author = {Weinstein, James N. and Clay, Kate and Morgan, Tamara S.},
booktitle = {Health Affairs},
doi = {10.1377/hlthaff.26.3.726},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Weinstein, Clay, Morgan - 2007 - Perspective Informed patient choice Patient-centered valuing of surgical risks and benefits.pdf:pdf},
isbn = {1544-5208 (Electronic)$\backslash$r0278-2715 (Linking)},
issn = {02782715},
pmid = {17485750},
title = {{Perspective: Informed patient choice: Patient-centered valuing of surgical risks and benefits}},
year = {2007}
}
@article{Wang2007,
abstract = {In this study the authors investigated the use of 5 (i.e., Claudy, Ezekiel, Olkin-Pratt, Pratt, and Smith) R[squared] correction formulas with the Pearson r[squared]. The authors estimated adjustment bias and precision under 6 x 3 x 6 conditions (i.e., population $\rho$ values of 0.0, 0.1, 0.3, 0.5, 0.7, and 0.9; population shapes normal, skewness = kurtosis = 1, and skewness = -1.5 with kurtosis = 3.5; ns = 10, 20, 40, 60, 100, and 200 respectively). Results indicate that the sample Pearson r[squared] is marginally biased at small sample sizes and small population effect sizes, and that the Ezekiel and the Smith R[squared] corrections work well in controlling this bias. (Contains 5 tables.)},
author = {Wang, Zhongmiao and Thompson, Bruce},
doi = {10.3200/JEXE.75.2.109-125},
file = {:C$\backslash$:/Users/eribu/Downloads/Is the Pearson r 2 Biased and if So What Is the Best Correction Formula.pdf:pdf},
issn = {0022-0973},
journal = {The Journal of Experimental Education},
keywords = {article1},
mendeley-tags = {article1},
number = {2},
pages = {109--125},
title = {{Is the Pearson r 2 Biased, and if So, What Is the Best Correction Formula?}},
volume = {75},
year = {2007}
}
@article{Kuhn2008,
abstract = {The caret package, short for classification and regression training, contains numerous tools for developing predictive models using the rich set of models available in R. The package focuses on simplifying model training and tuning across a wide variety of modeling techniques. It also includes methods for pre-processing training data, calculating variable importance, and model visualizations. An example from computational chemistry is used to illustrate the functionality on a real data set and to benchmark the benefits of parallel processing with several types of models.},
author = {Kuhn, Max},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuhn - 2008 - Building Predictive Models in R Using the caret Package.pdf:pdf},
journal = {JSS Journal of Statistical Software},
keywords = {NetWorkSpaces,R,model building,parallel processing,tuning parameters},
number = {5},
title = {{Building Predictive Models in R Using the caret Package}},
url = {http://www.jstatsoft.org/},
volume = {28},
year = {2008}
}
@article{Isaksson2008,
abstract = {The interest in statistical classification for critical applications such as diagnoses of patient samples based on supervised learning is rapidly growing. To gain acceptance in applications where the subsequent decisions have serious consequences, e.g. choice of cancer therapy, any such decision support system must come with a reliable performance estimate. Tailored for small sample problems, cross-validation (CV) and bootstrapping (BTS) have been the most commonly used methods to determine such estimates in virtually all branches of science for the last 20 years. Here, we address the often overlooked fact that the uncertainty in a point estimate obtained with CV and BTS is unknown and quite large for small sample classification problems encountered in biomedical applications and elsewhere. To avoid this fundamental problem of employing CV and BTS, until improved alternatives have been established, we suggest that the final classification performance always should be reported in the form of a Bayesian confidence interval obtained from a simple holdout test or using some other method that yields conservative measures of the uncertainty. ?? 2008 Elsevier B.V. All rights reserved.},
author = {Isaksson, A. and Wallman, M. and G??ransson, H. and Gustafsson, M. G.},
doi = {10.1016/j.patrec.2008.06.018},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Isaksson et al. - 2008 - Cross-validation and bootstrapping are unreliable in small sample classification.pdf:pdf},
isbn = {01678655},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Confidence interval,Performance estimation,Supervised classification,article1},
mendeley-tags = {article1},
title = {{Cross-validation and bootstrapping are unreliable in small sample classification}},
year = {2008}
}
@article{Hossjer2008,
abstract = {For mixed regression models, we define a variance decomposition including three terms, explained individual variance, unexplained individual variance and noise variance. In contrast to traditional variance decomposition, it is thus the unexplained, not the explained, variance that is split. It gives rise to a coefficient of individual determination (CID) defined as the estimated fraction of explained individual variance. We argue that in many applications CID is a valuable complement to R2, since it excludes noise variance (which can never be explained) and thus has one as a natural upper bound. A general theory for coefficients determination is presented, including various choices of regression models, weight functions and parameter estimates. In particular we focus on models where CID is computable, such as univariate mixed Poisson and logistic regression models, as well as multivariate mixed linear regression models. Large sample properties and confidence intervals are derived and finally, the theory is exemplified using Poisson regression on a Swedish motor traffic insurance data set. © 2007 Elsevier B.V. All rights reserved.},
author = {H{\"{o}}ssjer, Ola},
doi = {10.1016/j.jspi.2007.11.010},
isbn = {0378-3758},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Coefficient of determination,Explained variance,Individual variance,Mixed regression models,Noise variance,Variance decomposition,article1},
mendeley-tags = {article1},
number = {10},
pages = {3022--3038},
title = {{On the coefficient of determination for mixed regression models}},
volume = {138},
year = {2008}
}
@article{Shieh2008,
abstract = {The sample squared multiple correlation coefficient is widely used for describing the usefulness of a multiple linear regression model in many areas of science. In this article, the author considers the problem of estimating the squared multiple correlation coefficient and the squared cross-validity coefficient under the assumption that the response and predictor variables have a joint multinormal distribution. Detailed numerical investigations are conducted to assess the exact bias and mean square error of the proposed modifications of established estimators. Notably, the positive-part Pratt estimator and the synthesis of Browne and positive-part Pratt estimators are recommended in the estimation of squared multiple correlation coefficient and squared cross-validity coefficient, respectively, for their overall advantages of incurring the least amount of statistical discrepancy and computational requirement.},
author = {Shieh, Gwowen},
doi = {10.1177/1094428106292901},
isbn = {1094-4281},
issn = {1094-4281},
journal = {Organizational Research Methods},
keywords = {article1,as fixed and known,bias,explanatory variables are treated,maximum likelihood estimator,mean square error,multiple correlation,multiple linear regres-,one of the most,shrinkage estimator,sion,statistical methods,the values of the,traditionally,ultiple regression analysis is,widely used of all},
mendeley-tags = {article1,multiple correlation},
number = {2},
pages = {387--407},
title = {{Improved Shrinkage Estimation of Squared Multiple Correlation Coefficient and Squared Cross-Validity Coefficient}},
volume = {11},
year = {2008}
}
@article{Shieh2008a,
author = {Shieh, Gwowen},
file = {:C$\backslash$:/Users/eribu/Downloads/Organizational Research Methods-2008-Shieh-387-407.pdf:pdf},
journal = {Organizational Research Methods},
keywords = {article1,as fixed and known,bias,explanatory variables are treated,maximum likelihood estimator,mean square error,multiple linear regres-,one of the most,shrinkage estimator,sion,statistical methods,the values of the,traditionally,ultiple regression analysis is,widely used of all},
mendeley-tags = {article1},
number = {2},
pages = {387--407},
title = {{Improved Shrinkage Estimation of Squared Multiple Correlation Coefficient and Squared Cross-Validity Coefficient}},
volume = {11},
year = {2008}
}
@article{Ludvigsson2009,
abstract = {Swedish health care and national health registers are dependent on the presence of a unique identifier. This paper describes the Swedish personal identity number (PIN) and explores ethical issues of its use in medical research. A ten-digit-PIN is maintained by the National Tax Board for all individuals that have resided in Sweden since 1947. Until January 2008, an estimated 75,638 individuals have changed PIN. The most common reasons for change of PIN are incorrect recording of date of birth or sex among immigrants or newborns. Although uncommon, change of sex always leads to change of PIN since the PIN is sex-specific. The most common reasons for re-use of PIN (n = 15,887), is when immigrants are assigned a PIN that has previously been assigned to someone else. This is sometimes necessary since there is a shortage of certain PIN combinations referring to dates of birth in the 1950s and 1960s. Several ethical issues can be raised pro and con the use of PIN in medical research. The Swedish PIN is a useful tool for linkages between medical registers and allows for virtually 100{\%} coverage of the Swedish health care system. We suggest that matching of registers through PIN and matching of national health registers without the explicit approval of the individual patient is to the benefit for both the individual patient and for society.},
author = {Ludvigsson, Jonas F. and Otterblad-Olausson, Petra and Pettersson, Birgitta U. and Ekbom, Anders},
doi = {10.1007/s10654-009-9350-y},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ludvigsson et al. - 2009 - The Swedish personal identity number Possibilities and pitfalls in healthcare and medical research.pdf:pdf},
isbn = {1065400993},
issn = {03932990},
journal = {European Journal of Epidemiology},
keywords = {Civil registration number,Identification,Personal identity number,Pin,Population,Review,Sweden},
pmid = {19504049},
title = {{The Swedish personal identity number: Possibilities and pitfalls in healthcare and medical research}},
year = {2009}
}
@article{Nemes2009,
abstract = {BACKGROUND: In epidemiological studies researchers use logistic regression as an analytical tool to study the association of a binary outcome to a set of possible exposures.$\backslash$n$\backslash$nMETHODS: Using a simulation study we illustrate how the analytically derived bias of odds ratios modelling in logistic regression varies as a function of the sample size.$\backslash$n$\backslash$nRESULTS: Logistic regression overestimates odds ratios in studies with small to moderate samples size. The small sample size induced bias is a systematic one, bias away from null. Regression coefficient estimates shifts away from zero, odds ratios from one.$\backslash$n$\backslash$nCONCLUSION: If several small studies are pooled without consideration of the bias introduced by the inherent mathematical properties of the logistic regression model, researchers may be mislead to erroneous interpretation of the results.},
author = {Nemes, Szilard and Jonasson, Junmei Miao and Genell, Anna and Steineck, Gunnar},
doi = {10.1186/1471-2288-9-56},
file = {:C$\backslash$:/Users/eribu/Downloads/art{\%}3A10.1186{\%}2F1471-2288-9-56.pdf:pdf},
isbn = {1471-2288 (Electronic)$\backslash$r1471-2288 (Linking)},
issn = {1471-2288},
journal = {BMC medical research methodology},
keywords = {Bias (Epidemiology),Computer Simulation,Female,Humans,Logistic Models,Models,Odds Ratio,Pregnancy,Sample Size,Statistical,article1,bredvidlasning},
mendeley-tags = {article1,bredvidlasning},
pages = {56},
pmid = {19635144},
title = {{Bias in odds ratios by logistic regression modelling and sample size.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2724427{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {9},
year = {2009}
}
@article{Kim2009,
abstract = {We consider the accuracy estimation of a classifier constructed on a given training sample. The naive resubstitution estimate is known to have a downward bias problem. The traditional approach to tackling this bias problem is cross-validation. The bootstrap is another way to bring down the high variability of cross-validation. But a direct comparison of the two estimators, cross-validation and bootstrap, is not fair because the latter estimator requires much heavier computation. We performed an empirical study to compare the??.632+??bootstrap estimator with the repeated 10-fold cross-validation and the repeated one-third holdout estimator. All the estimators were set to require about the same amount of computation. In the simulation study, the repeated 10-fold cross-validation estimator was found to have better performance than the??.632+??bootstrap estimator when the classifier is highly adaptive to the training sample. We have also found that the??.632+??bootstrap estimator suffers from a bias problem for large samples as well as for small samples. ?? 2009 Elsevier B.V. All rights reserved.},
annote = {behandlar classification, inte regression.},
author = {Kim, Ji Hyun},
doi = {10.1016/j.csda.2009.04.009},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim - 2009 - Estimating classification error rate Repeated cross-validation, repeated hold-out and bootstrap.pdf:pdf},
isbn = {0167-9473},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {validation},
mendeley-tags = {validation},
number = {11},
pages = {3735--3745},
title = {{Estimating classification error rate: Repeated cross-validation, repeated hold-out and bootstrap}},
volume = {53},
year = {2009}
}
@article{Hafdahl2009,
abstract = {In 2 Monte Carlo studies of fixed- and random-effects meta-analysis for correlations, A. P. Field (2001) ostensibly evaluated Hedges-Olkin-Vevea Fisher-z and Schmidt-Hunter Pearson-r estimators and tests in 120 conditions. Some authors have cited those results as evidence not to meta-analyze Fisher-z correlations, especially with heterogeneous correlation parameters. The present attempt to replicate Field's simulations included comparisons with analytic values as well as results for efficiency and confidence-interval coverage. Field's results under homogeneity were mostly replicable, but those under heterogeneity were not: The latter exhibited up to over .17 more bias than ours and, for tests of the mean correlation and homogeneity, respectively, nonnull rejection rates up to .60 lower and .65 higher. Changes to Field's observations and conclusions are recommended, and practical guidance is offered regarding simulation evidence and choices among methods. Most cautions about poor performance of Fisher-z methods are largely unfounded, especially with a more appropriate z-to-r transformation. The Appendix gives a computer program for obtaining Pearson-r moments from a normal Fisher-z distribution, which is used to demonstrate distortion due to direct z-to-r transformation of a mean Fisher-z correlation.},
author = {Hafdahl, Adam R and Williams, Michelle a},
doi = {10.1037/a0014697},
isbn = {1082-989X$\backslash$n1939-1463},
issn = {1082-989X},
journal = {Psychological methods},
keywords = {10,1037,a0014697,article1,decades,doi,during the past 3,dx,fisher,http,meta-analysis,meta-analysis has become a,monte carlo simulation,org,random effects,s z transformation,supp,supplemental materials,validity generalization},
mendeley-tags = {article1},
number = {1},
pages = {24--42},
pmid = {19271846},
title = {{Meta-analysis of correlations revisited: attempted replication and extension of Field's (2001) simulation studies.}},
volume = {14},
year = {2009}
}
@article{Gorsuch2010,
abstract = {Non-zero correlation coefficients have non-normal distributions, affecting both means and standard deviations. Previous research suggests that z transformation may effectively correct mean bias for N's less than 30. In this study, simulations with small (20 and 30) and large (50 and 100) N's found that mean bias adjustments for larger N's are seldom needed. However, z transformations improved confidence intervals even for N = 100. The improvement was not in the estimated standard errors so much as in the asymmetrical CI's estimates based upon the z transformation. The resulting observed probabilities were generally accurate to within 1 point in the first non-zero digit. These issues are an order of magnitude less important for accuracy than design issues influencing the accuracy of the results, such as reliability, restriction of range, and N. Keywords: Confidence intervals; Correlation coefficient; Fisher’s z transformation; Monte Carlo study; Mean bias in correlation coefficients},
author = {Gorsuch, Rl and Lehmann, Cs},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gorsuch, Lehmann - 2010 - Correlation Coefficients Mean Bias and Confidence Interval Distortions.pdf:pdf},
issn = {2159-7855},
journal = {Journal of Methods and Measurement in the Social Sciences},
keywords = {article1,because the distribution of,coefficients,confidence intervals,correlation coefficient,estimate the population correlation,fisher,is known to slightly,mean bias in correlation,monte carlo,r,r is,s z transformation,study,the observed correlation coefficient,under,$\rho$},
mendeley-tags = {article1},
number = {2},
pages = {52--65},
title = {{Correlation Coefficients: Mean Bias and Confidence Interval Distortions}},
url = {https://journals.uair.arizona.edu/index.php/jmmss/article/download/114/118},
volume = {1},
year = {2010}
}
@article{Renaud2010,
abstract = {To assess the quality of the fit in a multiple linear regression, the coefficient of determination or R2 is a very simple tool, yet the most used by practitioners. Indeed, it is reported in most statistical analyzes, and although it is not recommended as a final model selection tool, it provides an indication of the suitability of the chosen explanatory variables in predicting the response. In the classical setting, it is well known that the least-squares fit and coefficient of determination can be arbitrary and/or misleading in the presence of a single outlier. In many applied settings, the assumption of normality of the errors and the absence of outliers are difficult to establish. In these cases, robust procedures for estimation and inference in linear regression are available and provide a suitable alternative. In this paper we present a companion robust coefficient of determination that has several desirable properties not shared by others. It is robust to deviations from the specified regression model (like the presence of outliers), it is efficient if the errors are normally distributed, it does not make any assumption on the distribution of the explanatory variables (and therefore no assumption on the unconditional distribution of the responses). We also show that it is a consistent estimator of the population coefficient of determination. A simulation study and two real datasets support the appropriateness of this estimator, compared with classical (least-squares) and several previously proposed robust R2, even for small sample sizes. © 2010 Elsevier B.V. All rights reserved.},
author = {Renaud, Olivier and Victoria-Feser, Maria Pia},
doi = {10.1016/j.jspi.2010.01.008},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Consistency,Correlation,Efficiency,Outliers,R-squared,article1},
mendeley-tags = {article1},
number = {7},
pages = {1852--1862},
title = {{A robust coefficient of determination for regression}},
volume = {140},
year = {2010}
}
@article{Shieh2010,
abstract = {This article investigates some unfamiliar properties of the Pearson product-moment correlation coefficient for the estimation of simple correlation coefficient. Although Pearson's r is biased, except for limited situations, and the minimum variance unbiased estimator has been proposed in the literature, researchers routinely employ the sample correlation coefficient in their practical applications, because of its simplicity and popularity. In order to support such practice, this study examines the mean squared errors of r and several prominent formulas. The results reveal specific situations in which the sample correlation coefficient performs better than the unbiased and nearly unbiased estimators, facilitating recommendation of r as an effect size index for the strength of linear association between two variables. In addition, related issues of estimating the squared simple correlation coefficient are also considered.},
author = {Shieh, Gwowen},
doi = {10.3758/BRM.42.4.906},
isbn = {1554-3528 (Electronic)$\backslash$r1554-351X (Linking)},
issn = {1554-351X},
journal = {Behavior research methods},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {4},
pages = {906--917},
pmid = {21139158},
title = {{Estimation of the simple correlation coefficient.}},
volume = {42},
year = {2010}
}
@article{distrMod,
author = {Kohl, Matthias and Ruckdeschel, Peter},
doi = {10.1002/wics.10},
file = {:C$\backslash$:/Users/eribu/Downloads/distrMod.pdf:pdf},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {article1,maximum likelihood estimators,minimum criterion estimators,minimum distance estimators,probability models,s4 classes,s4 methods},
mendeley-tags = {article1},
number = {10},
pages = {1--27},
title = {{R Package distrMod: S4 Classes and Methods for Probability Models}},
volume = {35},
year = {2010}
}
@misc{Dieppe2011,
abstract = {Knee joint replacement is an effective and cost-effective intervention for severe symptomatic osteoarthritis of the knee joint. However, utilisation rates vary hugely, there are no indications, it is difficult to know when (in the course of arthritis) it is best to operate, and some 10-20{\%} of people who have this surgery are unhappy with the outcome, and have persistent pain. In this article we briefly discuss the variations in utilization of knee joint replacement, and then outline four different approaches to the selection and prioritisation of patients for this procedure. Consensus criteria, including appropriateness criteria are available, but if produced by professionals alone, they may conflict with the views of patients and the public. Databases and cohort studies can be used to attempt relating outcomes to baseline characteristics, but at present we can only account for a small percentage of the variance with this technique. Finally, we propose use of the 'capacity to benefit framework' to attempt providing guidance to both patients and healthcare professionals.},
author = {Dieppe, Paul and Lim, Keith and Lohmander, Stefan},
booktitle = {International Journal of Rheumatic Diseases},
doi = {10.1111/j.1756-185X.2011.01611.x},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dieppe, Lim, Lohmander - 2011 - Who should have knee joint replacement surgery for osteoarthritis.pdf:pdf},
isbn = {17561841},
issn = {17561841},
keywords = {Indications,Joint replacement,Knee,Osteoarthritis,Variations},
pmid = {21518317},
title = {{Who should have knee joint replacement surgery for osteoarthritis?}},
year = {2011}
}
@article{Rolfson2011,
abstract = {We present the development and results of a nationwide, prospective, observational follow-up programme including patient-reported outcome measures (PROMs) for the Swedish Hip Arthroplasty Register. The programme started in 2002 and has gradually expanded to include all units performing total hip replacement in Sweden. The self-administered PROMs protocol comprises the EQ-5D instrument, the Charnley class categorisation and visual analogue scales for pain and satisfaction. These current analyses include 34 960 total hip replacements with complete pre-and one-year post-operative questionnaires. Patients eligible for total hip replacement generally report low health-related quality of life and suffer from pain. One year post-operatively the mean EQ-5D index increased to above the level of an age-and gender-matched population, with a considerable reduction of pain (p < 0.001). Females, younger patients and those with Charnley category C reported a lower EQ-5D index pre-operatively than males, older patients and Charnley category A or B, respectively (all p < 0.001). In a multivariable regression analysis Charnley category C, male gender and higher age were associated with less improvement in health-related quality of life (p < 0.001). Nationwide implementation of a PROMs programme requires a structured organisation and effective data capture. Patients' response rates to the Registry are good. The continuous collection of PROMs permits local and national improvement work and allows for further health-economic evaluation.},
author = {Rolfson, O and K{\"{a}}rrholm, J and Dahlberg, L E and Garellick, G and Rolfson,  O and Surgeon, Orthopaedic and K{\"{a}}rrholm,  J and Dahlberg,  L E and Garellick,  G},
doi = {10.1302/0301-620X.93B7},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rolfson et al. - 2011 - Patient-reported outcomes in the Swedish Hip Arthroplasty Register RESULTS OF A NATIONWIDE PROSPECTIVE OBSERVATI.pdf:pdf},
journal = {J Bone Joint Surg [Br]},
number = {7},
pages = {867--75},
title = {{Patient-reported outcomes in the Swedish Hip Arthroplasty Register RESULTS OF A NATIONWIDE PROSPECTIVE OBSERVATIONAL STUDY}},
volume = {9393},
year = {2011}
}
@article{Skidmore2011,
annote = {stj{\"{a}}rnmarkerad d{\aa} uppl{\"{a}}gget f{\"{o}}r studien {\"{a}}r v{\"{a}}ldigt lik v{\aa}r. Dock har det sedan visat sig att det f{\"{o}}reslagna resultatet inte var s{\aa} bra som man hoppades.},
author = {Skidmore, Susan Troncoso and Thompson, Bruce},
doi = {10.1080/00220973.2010.484437},
file = {:C$\backslash$:/Users/eribu/Downloads/Choosing the Best Correction Formula for the Pearson r 2Effect Size.pdf:pdf},
issn = {0022-0973},
journal = {The Journal of Experimental Education},
keywords = {article1},
mendeley-tags = {article1},
number = {3},
pages = {257--278},
title = {{Choosing the Best Correction Formula for the Pearson r 2 Effect Size}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00220973.2010.484437},
volume = {79},
year = {2011}
}
@book{Kullenberg2012,
author = {Kullenberg, Christopher},
file = {:C$\backslash$:/Users/eribu/Downloads/gupea{\_}2077{\_}28807{\_}1.pdf:pdf},
isbn = {9789162884581},
keywords = {bredvidlasning},
mendeley-tags = {bredvidlasning},
title = {{The Quantification of Society. A Study of a Swedish Research Institute and Survey-based Social Science}},
year = {2012}
}
@article{Exam2012,
author = {Exam, Final},
file = {:C$\backslash$:/Users/eribu/Downloads/Dr{\_}Alodat{\_}STAT{\_}459{\_}L01{\_}Spring{\_}2012.pdf:pdf},
title = {{College of Arts and Science Department of Mathematics , Statistics and Physics Syllabus for Stat . 459 Course Information Textbook and References . Schedule of Classes : Week Topics to be covered}},
year = {2012}
}
@article{Mukaka2012,
abstract = {Correlation is a statistical method used to assess a possible linear association between two continuous variables. It is simple both to calculate and to interpret. However, misuse of correlation is so common among researchers that some statisticians have wished that the method had never been devised at all. The aim of this article is to provide a guide to appropriate use of correlation in medical research and to highlight some misuse. Examples of the applications of the correlation coefficient have been provided using data from statistical simulations as well as real data. Rule of thumb for interpreting size of a correlation coefficient has been provided.},
author = {Mukaka, M. M.},
file = {:C$\backslash$:/Users/eribu/Downloads/MMJ2403-0069.pdf:pdf},
issn = {19957262},
journal = {Malawi Medical Journal},
keywords = {article1,multiple correlation},
mendeley-tags = {article1,multiple correlation},
number = {3},
pages = {69--71},
pmid = {23638278},
title = {{Statistics corner: A guide to appropriate use of correlation coefficient in medical research}},
volume = {24},
year = {2012}
}
@article{Schonbrodt2013,
abstract = {Sample correlations converge to the population value with increasing sample size, but the estimates are often inaccurate in small samples. In this report we use Monte-Carlo simulations to determine the critical sample size from which on the magnitude of a correlation can be expected to be stable. The necessary sample size to achieve stable estimates for correlations depends on the effect size, the width of the corridor of stability (i.e., a corridor around the true value where deviations are tolerated), and the requested confidence that the trajectory does not leave this corridor any more. Results indicate that in typical scenarios the sample size should approach 250 for stable estimates.},
author = {Sch{\"{o}}nbrodt, Felix D. and Perugini, Marco},
doi = {10.1016/j.jrp.2013.05.009},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sch{\"{o}}nbrodt, Perugini - 2013 - At what sample size do correlations stabilize(2).pdf:pdf},
issn = {00926566},
journal = {Journal of Research in Personality},
keywords = {Accuracy,Correlation,Sample size,Simulation},
month = {oct},
number = {5},
pages = {609--612},
title = {{At what sample size do correlations stabilize?}},
url = {http://www.sciencedirect.com/science/article/pii/S0092656613000858},
volume = {47},
year = {2013}
}
@article{Schonbrodt2013a,
abstract = {Sample correlations converge to the population value with increasing sample size, but the estimates are often inaccurate in small samples. In this report we use Monte-Carlo simulations to determine the critical sample size from which on the magnitude of a correlation can be expected to be stable. The necessary sample size to achieve stable estimates for correlations depends on the effect size, the width of the corridor of stability (i.e., a corridor around the true value where deviations are tolerated), and the requested confidence that the trajectory does not leave this corridor any more. Results indicate that in typical scenarios the sample size should approach 250 for stable estimates. © 2013 Elsevier Inc.},
author = {Sch{\"{o}}nbrodt, Felix D. and Perugini, Marco},
doi = {10.1016/j.jrp.2013.05.009},
isbn = {00926566},
issn = {00926566},
journal = {Journal of Research in Personality},
number = {5},
pages = {609--612},
title = {{At what sample size do correlations stabilize?}},
volume = {47},
year = {2013}
}
@article{Nemes2014,
abstract = {Background and purpose — The continuously increasing demand for joint replacement surgery in the past decades imposes higher constraints on the budgets of hospitals and healthcare providers. We undertook an analysis of historical trends in total hip replace-ment performed in Sweden between 1968 and 2012 in order to provide projections of future demand. Data and methods — We obtained data on total hip replace-ments registered every year and on the evolution of the Swedish population between 1968 and 2012. We assumed the existence of a maximum incidence. So we adopted a regression framework that assumes the existence of an upper limit of total hip replacement incidence. Results — We found that the incidence of total hip replacement will continue to increase until a projected upper incidence level of about 400 total hip replacements per 10 5 Swedish residents aged 40 years and older will be reached around the year 2107. In 2020, the estimated incidence of total hip replacement will be 341 (95{\%} prediction interval (PI): 302–375) and in 2030 it will be 358 (PI: 317–396). Using official forecasted population growth data, about 18,000 operations would be expected to be performed in 2020 and 20,000 would be expected to be performed in 2030. Interpretation — Growing incidence, population growth, and increasing life expectancy will probably result in increased demand for hip replacement surgery. Our findings could serve as a basis for decision making. },
author = {Nemes, Szil{\'{a}}rd and Gordon, Max and Rogmark, Cecilia and Rolfson, Ola},
doi = {10.3109/17453674.2014.913224},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nemes et al. - 2014 - Projections of total hip replacement in Sweden from 2013 to 2030.pdf:pdf},
journal = {Acta Orthopaedica},
number = {3},
pages = {238--243},
title = {{Projections of total hip replacement in Sweden from 2013 to 2030}},
volume = {85},
year = {2014}
}
@article{Husted2014,
abstract = {BACKGROUND AND PURPOSE: Traditions are passed on from experienced surgeons to younger fellows and become "the right way to do it". Traditions associated with arthroplasty surgery may, however, not be evidence-based and may be potentially deleterious to both patients and society, increasing morbidity and mortality, slowing early functional recovery, and increasing cost.$\backslash$n$\backslash$nMETHODS: We identified selected traditions and performed a literature search using relevant search criteria (June 2014). We present a narrative review grading the studies according to evidence, and we suggest some lines of future research.$\backslash$n$\backslash$nRESULTS: We present traditions and evaluate them against the published evidence. Preoperative removal of hair, urine testing for bacteria, use of plastic adhesive drapes intraoperatively, and prewarming of the operation room should be abandoned-as should use of a tourniquet, a space suit, a urinary catheter, and closure of the knee in extension. The safety and efficacy of tranexamic acid is supported by meta-analyses. Postoperatively, there is no evidence to support postponement of showering or postponement of changing of dressings to after 48 h. There is no evidence to recommend routine dental antibiotic prophylaxis, continuous passive motion (CPM), the use of compression stockings, cooling for pain control or reduction of swelling, flexion of at least 90 degrees as a discharge criterion following TKA, or having restrictions after THA. We present evidence supporting the use of NSAIDs, early mobilization, allowing early travel, and a low hemoglobin trigger for transfusion.$\backslash$n$\backslash$nINTERPRETATION: Revision of traditions and myths surrounding hip and knee arthroplasty towards more contemporary evidence-based principles can be expected to improve early functional recovery, thus reducing morbidity, mortality, and costs.},
author = {Husted, Henrik and Gromov, Kirill and Malchau, Henrik and Freiberg, Andrew and Gebuhr, Peter and Troelsen, Anders},
doi = {10.3109/17453674.2014.971661},
file = {:C$\backslash$:/Users/eribu/Downloads/17453674{\%}2E2014{\%}2E971661.pdf:pdf},
issn = {1745-3674},
journal = {Acta Orthopaedica},
keywords = {Arthroplasty, Replacement, Hip,Arthroplasty, Replacement, Hip: standards,Arthroplasty, Replacement, Knee,Arthroplasty, Replacement, Knee: standards,Attitude of Health Personnel,Evidence-Based Medicine,Hip,Hip: standards,Humans,Knee,Knee: standards,Practice Guidelines as Topic,Replacement,intro},
mendeley-tags = {intro},
number = {6},
pages = {548--555},
pmid = {25285615},
title = {{Traditions and myths in hip and knee arthroplasty}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4259040{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {85},
year = {2014}
}
@article{Labar??re2014,
author = {Labar??re, Jos?? and Bertrand, Renaud and Fine, Michael J.},
doi = {10.1007/s00134-014-3227-6},
isbn = {0013401432},
issn = {14321238},
journal = {Intensive Care Medicine},
number = {4},
pmid = {24570265},
title = {{How to derive and validate clinical prediction models for use in intensive care medicine}},
volume = {40},
year = {2014}
}
@article{Cross2014,
abstract = {Objective To estimate the global burden of hip and knee osteoarthritis (OA) as part of the Global Burden of Disease 2010 study and to explore how the burden of hip and knee OA compares with other conditions. Methods Systematic reviews were conducted to source age-specific and sex-specific epidemiological data for hip and knee OA prevalence, incidence and mortality risk. The prevalence and incidence of symptomatic, radiographic and self-reported hip or knee OA were included. Three levels of severity were defined to derive disability weights (DWs) and severity distribution (proportion with mild, moderate and severe OA). The prevalence by country and region was multiplied by the severity distribution and the appropriate disability weight to calculate years of life lived with disability (YLDs). As there are no deaths directly attributed to OA, YLDs equate disability-adjusted life years (DALYs). Results Globally, of the 291 conditions, hip and knee OA was ranked as the 11th highest contributor to global disability and 38th highest in DALYs. The global age-standardised prevalence of knee OA was 3.8{\%} (95{\%} uncertainty interval (UI) 3.6{\%} to 4.1{\%}) and hip OA was 0.85{\%} (95{\%} UI 0.74{\%} to 1.02{\%}), with no discernible change from 1990 to 2010. Prevalence was higher in females than males. YLDs for hip and knee OA increased from 10.5 million in 1990 (0.42{\%} of total DALYs) to 17.1 million in 2010 (0.69{\%} of total DALYs). Conclusions Hip and knee OA is one of the leading causes of global disability. Methodological issues within this study make it highly likely that the real burden of OA has been underestimated. With the aging and increasing obesity of the world's population, health professions need to prepare for a large increase in the demand for health services to treat hip and knee OA.},
author = {Cross, Marita and Smith, Emma and Hoy, Damian and Nolte, Sandra and Ackerman, Ilana and Fransen, Marlene and Bridgett, Lisa and Williams, Sean},
doi = {10.1136/annrheumdis-2013-204763},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cross et al. - 2014 - The global burden of hip and knee osteoarthritis estimates from the Global Burden of Disease 2010 study.pdf:pdf},
journal = {Ann Rheum Dis},
pages = {1323--1330},
title = {{The global burden of hip and knee osteoarthritis: estimates from the Global Burden of Disease 2010 study}},
url = {http://dx.doi.org/10.1136/},
volume = {73},
year = {2014}
}
@misc{Steyerberg2014,
abstract = {Clinical prediction models provide risk estimates for the presence of disease (diagnosis) or an event in the future course of disease (prognosis) for individual patients. Although publications that present and evaluate such models are becoming more frequent, the methodology is often suboptimal. We propose that seven steps should be considered in developing prediction models: (i) consideration of the research question and initial data inspection; (ii) coding of predictors; (iii) model specification; (iv) model estimation; (v) evaluation of model performance; (vi) internal validation; and (vii) model presentation. The validity of a prediction model is ideally assessed in fully independent data, where we propose four key measures to evaluate model performance: calibration-in-the-large, or the model intercept (A); calibration slope (B); discrimination, with a concordance statistic (C); and clinical usefulness, with decision-curve analysis (D). As an application, we develop and validate prediction models for 30-day mortality in patients with an acute myocardial infarction. This illustrates the usefulness of the proposed framework to strengthen the methodological rigour and quality for prediction models in cardiovascular research.},
author = {Steyerberg, Ewout W. and Vergouwe, Yvonne},
booktitle = {European Heart Journal},
doi = {10.1093/eurheartj/ehu207},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Steyerberg, Vergouwe - 2014 - Towards better clinical prediction models Seven steps for development and an ABCD for validation.pdf:pdf},
isbn = {1522-9645 (Electronic)$\backslash$r0195-668X (Linking)},
issn = {15229645},
keywords = {Calibration,Clinical usefulness,Discrimination,Missing values,Non-linearity,Prediction model,Shrinkage},
pmid = {24898551},
title = {{Towards better clinical prediction models: Seven steps for development and an ABCD for validation}},
year = {2014}
}
@article{Nemes2015,
abstract = {Background and purpose — The incidence of knee osteoarthritis will most likely increase. We analyzed historical trends in the inci-dence of knee arthroplasty in Sweden between 1975 and 2013, in order to be able to provide projections of future demand. Patients and methods — We obtained information on all knee arthroplasties in Sweden in the period 1975–2013 from the Swed-ish Knee Arthroplasty Register, and used public domain data from Statistics Sweden on the evolution of and forecasts for the Swedish population. We forecast the incidence, presuming the existence of a maximum incidence. Results — We found that the incidence of knee arthroplasty will continue to increase until a projected upper incidence level of about 469 total knee replacements per 10 5 Swedish residents aged 40 years and older is reached around the year 2130. In 2020, the estimated incidence of total knee arthroplasties per 10 5 Swed-ish residents aged 40 years and older will be 334 (95{\%} prediction interval (PI): 281–374) and in 2030 it will be 382 (PI: 308–441). Using officially forecast population growth data, around 17,500 operations would be expected to be performed in 2020 and around 21,700 would be expected to be performed in 2030. Interpretation — Today's levels of knee arthroplasty are well below the expected maximum incidence, and we expect a contin-ued annual increase in the total number of knee arthroplasties performed. },
author = {Nemes, Szil{\'{a}}rd and Rolfson, Ola and Dahl, Annette W- and Garellick, G{\"{o}}ran and Sundberg, Martin and K{\"{a}}rrholm, Johan and Robertsson, Otto},
doi = {10.3109/17453674.2015.1034608},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nemes et al. - 2015 - Historical view and future demand for knee arthroplasty in Sweden.pdf:pdf},
journal = {Acta Orthopaedica},
number = {4},
pages = {426--431},
title = {{Historical view and future demand for knee arthroplasty in Sweden}},
volume = {86},
year = {2015}
}
@article{Emilsson2015,
abstract = {BACKGROUND AND OBJECTIVES: In the past two decades, an increasing number of nationwide, Swedish Healthcare Quality Registries (QRs) focusing on specific disorders have been initiated, mostly by physicians. Here, we describe the purpose, organization, variables, coverage and completeness of 103 Swedish QRs. METHODS: From March to September 2013, we examined the 2012 applications of 103 QRs to the Swedish Association of Local Authorities and Regions (SALAR) and also studied the annual reports from the same QRs. After initial data abstraction, the coordinator of each QR was contacted at least twice between June and October 2013 and asked to confirm the accuracy of the data retrieved from the applications and reports. RESULTS: About 60{\%} of the QRs covered ≥80{\%} of their target population (completeness). Data recorded in Swedish QRs include aspects of disease management (diagnosis, clinical characteristics, treatment and lead times). In addition, some QRs retrieve data on self-reported quality of life (EQ5D, SF-36 and disease-specific measures), lifestyle (smoking) and general health status (World Health Organization performance status, body mass index and blood pressure). CONCLUSION: Detailed clinical data available in Swedish QRs complement information from government-administered registries and provide an important source not only for assessment and development of quality of care but also for research.},
author = {Emilsson, L. and Lindahl, B. and K??ster, M. and Lambe, M. and Ludvigsson, J. F.},
doi = {10.1111/joim.12303},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Emilsson et al. - 2015 - Review of 103 Swedish Healthcare Quality Registries.pdf:pdf},
issn = {13652796},
journal = {Journal of Internal Medicine},
keywords = {Adult,Child,Life quality,Morbidity,Register,Registry},
pmid = {25174800},
title = {{Review of 103 Swedish Healthcare Quality Registries}},
year = {2015}
}
@article{Paxton2015,
abstract = {Background Considering the cost and risk associated with revision Total knee arthroplasty (TKAs) and Total hip arthroplasty (THAs), steps to prevent these operations will help patients and reduce healthcare costs. Revision risk calculators for patients may reduce revision surgery by supporting clinical decision-making at the point of care. Questions/purposes We sought to develop a TKA and THA revision risk calculator using data from a large health-maintenance organization's arthroplasty registry and determine the best set of predictors for the revision risk calculator. Methods Revision risk calculators for THAs and TKAs were developed using a patient cohort from a total joint replacement registry and data from a large US integrated healthcare system. The cohort included all patients who had primary procedures performed in our healthcare system between April 2001 and July 2008 and were followed until January 2014 (TKAs, n = 41,750; THAs, n = 22,721), During the study period, 9{\%} of patients (TKA = 3066/34,686; THA=1898/20,285) were lost to followup and 7{\%} died (TKA= 2350/41,750; THA=1419/20,285). The outcome of interest was revision surgery and was defined as replacement of any component for any reason within 5 years postoperatively. Candidate predictors for the revision risk calculator were limited to preoperative patient demographics, comorbidities, and procedure diagnoses. Logistic regression models were used to identify predictors and the Hosmer-Lemeshow goodness-of-fit test and c-statistic were used to choose final models for the revision risk calculator. Results The best predictors for the TKA revision risk calculator were age (odds ratio [OR], 0.96; 95{\%} CI, 0.95-0.97; p < 0.001), sex (OR, 0.84; 95{\%} CI, 0.75-0.95; p = 0.004), square-root BMI (OR, 1.05; 95{\%} CI, 0.99-1.11; p = 0.140), diabetes (OR, 1.32; 95{\%} CI, 1.17-1.48; p < 0.001), osteoarthritis (OR, 1.16; 95{\%} CI, 0.84-1.62; p = 0.368), posttraumatic arthritis (OR, 1.66; 95{\%} CI, 1.07-2.56; p = 0.022), and osteonecrosis (OR, 2.54; 95{\%} CI, 1.31-4.92; p = 0.006). The best predictors for the THA revision risk calculator were sex (OR, 1.24; 95{\%} CI, 1.05-1.46; p = 0.010), age (OR, 0.98; 95{\%} CI, 0.98-0.99; p < 0.001), square-root BMI (OR, 1.07; 95{\%} CI, 1.00-1.15; p = 0.066), and osteoarthritis (OR, 0.85; 95{\%} CI, 0.66-1.09; p = 0.190). Conclusions Study model parameters can be used to create web-based calculators. Surgeons can enter personalized patient data in the risk calculators for identification of risk of revision which can be used for clinical decision making at the point of care. Future prospective studies will be needed to validate these calculators and to refine them with time.},
author = {Paxton, Elizabeth W. and Inacio, Maria C S and Khatod, Monti and Yue, Eric and Funahashi, Tadashi and Barber, Thomas},
doi = {10.1007/s11999-015-4506-4},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Paxton et al. - 2015 - Risk Calculators Predict Failures of Knee and Hip Arthroplasties Findings from a Large Health Maintenance Organiz.pdf:pdf},
isbn = {0009-921x},
issn = {15281132},
journal = {Clinical Orthopaedics and Related Research},
pmid = {26324831},
title = {{Risk Calculators Predict Failures of Knee and Hip Arthroplasties: Findings from a Large Health Maintenance Organization}},
year = {2015}
}
@article{Patel2015,
abstract = {Total knee arthroplasty (TKA) and total hip arthroplasty (THA) are recognised and proven interventions for patients with advanced arthritis. Studies to date have demonstrated a steady increase in the requirement for primary and revision procedures. Projected estimates made for the United States show that by 2030 the demand for primary TKA will grow by 673{\%} and for revision TKA by 601{\%} from the level in 2005. For THA the projected estimates are 174{\%} and 137{\%} for primary and revision surgery, respectively. The purpose of this study was to see if those predictions were similar for England and Wales using data from the National Joint Registry and the Office of National Statistics. Analysis of data for England and Wales suggest that by 2030, the volume of primary and revision TKAs will have increased by 117{\%} and 332{\%}, respectively between 2012 and 2030. The data for the United States translates to a 306{\%} cumulative rate of increase between 2012 and 2030 for revision surgery, which is similar to our predictions for England and Wales. The predictions from the United States for primary TKA were similar to our upper limit projections. For THA, we predicted an increase of 134{\%} and 31{\%} for primary and revision hip surgery, respectively. Our model has limitations, however, it highlights the economic burden of arthroplasty in the future in England and Wales as a real and unaddressed problem. This will have significant implications for the provision of health care and the management of orthopaedic services in the future.},
author = {Patel, A. and Pavlou, G. and M??jica-Mota, R. E. and Toms, A. D.},
doi = {10.1302/0301-620X.97B8.35170},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Patel et al. - 2015 - The epidemiology of revision total knee and hip arthroplasty in England and Wales A comparative analysis with proj.pdf:pdf},
issn = {20494408},
journal = {Bone and Joint Journal},
pmid = {26224824},
title = {{The epidemiology of revision total knee and hip arthroplasty in England and Wales: A comparative analysis with projections for the United States. a study using the national joint registry dataset}},
year = {2015}
}
@article{fitdistrplus,
abstract = {The package fitdistrplus provides functions for fitting univariate distributions to different types of data (continuous censored or non-censored data and discrete data) and allowing different estimation methods (maximum likelihood, moment matching, quantile matching and maximum goodness-of-fit estimation). Outputs of fitdist and fitdistcens functions are S3 objects, for which kind generic methods are provided, including summary, plot and quantile. This package also provides various functions to compare the fit of several distributions to a same data set and can handle bootstrap of parameter estimates. Detailed examples are given in food risk assessment, ecotoxicology and insurance contexts.},
author = {Delignette-muller, Marie Laure and Dutang, Christophe},
doi = {10.18637/jss.v064.i04},
file = {:C$\backslash$:/Users/eribu/Downloads/paper2JSS.pdf:pdf},
isbn = {9781420065213},
issn = {1548-7660},
journal = {Journal of Statistical Software},
keywords = {article1,bootstrap,censored data,distributions,maximum goodness-of-fit,maximum likelihood,moment matching,probability distribution fitting,quantile matching,r},
mendeley-tags = {article1},
number = {4},
pages = {1--34},
title = {{fitdistrplus : An R Package for Fitting Distributions}},
volume = {64},
year = {2015}
}
@article{Journal2016,
author = {Journal, The Indian},
file = {:C$\backslash$:/Users/eribu/Downloads/ref{\_}till{\_}coop1916/25047705.pdf:pdf},
number = {4},
pages = {383--400},
title = {{All use subject to JSTOR Terms and Conditions COEFFICIENT IN SAMPLES FROM NON-NORMAL POPULATIONS}},
volume = {5},
year = {2016}
}
@article{Barrett2016,
author = {Barrett, James P},
file = {:C$\backslash$:/Users/eribu/Downloads/2683523.pdf:pdf},
number = {1},
pages = {19--20},
title = {{The Coefficient of Determination-Some Limitations Author ( s ): James P . Barrett Published by : Taylor {\&} Francis , Ltd . on behalf of the American Statistical Association Stable URL : http://www.jstor.org/stable/2683523 Accessed : 29-02-2016 12 : 00 UTC }},
volume = {28},
year = {2016}
}
@article{Crocker2016,
author = {Crocker, Douglas C},
file = {:C$\backslash$:/Users/eribu/Downloads/2683460.pdf:pdf},
number = {2},
pages = {31--33},
title = {{Some Interpretations of the Multiple Correlation Coefficient Author ( s ): Douglas C . Crocker Published by : Taylor {\&} Francis , Ltd . on behalf of the American Statistical Association Stable URL : http://www.jstor.org/stable/2683460 Accessed : 07-03-2016 08 : 49 UTC Your use of the JSTOR archive indicates your acceptance of the Terms {\&} Conditions of Use , available at http://www.jstor.org/page/ info / about / policies / terms . jsp JSTOR is a not-for-profit service that helps scholars , researchers , and students discover , use , and build upon a wide range of content in a trusted digital archive . We use information technology and tools to increase productivity and facilitate new forms of scholarship . For more information about JSTOR , please contact support@jstor.org . Taylor {\&} Francis , Ltd . and American Statistical Association are collaborating with JSTOR to digitize , preserve and extend access to The American Statistician . All use subject to JSTOR Terms and Conditions Some Interpretations of the Multiple Correlation Coefficient All use subject to JSTOR Terms and Conditions}},
volume = {26},
year = {2016}
}
@article{,
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - 17{\_}bigpdfE2014pdfE0068.{\%}3:{\%}3},
title = {{17{\_}big{\%}2E2014{\%}2E0068}}
}
@article{Vogl,
abstract = {Background: To facilitate the discussion on the increasing number of total hip replacements (THR) and their effectiveness, we apply a joint evaluation of hospital case costs and health outcomes at the patient level to enable comparative effectiveness research (CER) based on the preoperative health state. Methods: In 2012, 292 patients from a German orthopedic hospital participated in health state evaluation before and 6 months after THR, where health-related quality of life (HRQoL) and disease specific pain and dysfunction were analyzed using EQ-5D and WOMAC scores. Costs were measured with a patient-based DRG costing scheme in a prospective observation of a cohort. Costs per quality-adjusted life year (QALY) were calculated based on the preoperative WOMAC score, as preoperative health states were found to be the best predictors of QALY gains in multivariate linear regressions. Results: Mean inpatient costs of THR were 6,310 Euros for primary replacement and 7,730 Euros for inpatient lifetime costs including revisions. QALYs gained using the U.K. population preference-weighted index were 5.95. Lifetime costs per QALY were 1,300 Euros. Conclusions: The WOMAC score and the EQ-5D score before operation were the most important predictors of QALY gains. The poorer the WOMAC score or the EQ-5D score before operation, the higher the patient benefit. Costs per QALY were far below common thresholds in all preoperative utility score groups and with all underlying calculation methodologies.},
author = {Vogl, Matthias and Wilkesmann, Rainer and Lausmann, Christian and Pl{\"{o}}tz, Werner},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Vogl et al. - Unknown - The impact of preoperative patient characteristics on the cost-effectiveness of total hip replacement a cohort s.pdf:pdf},
keywords = {Cost-effectiveness,Cost-utility,Costs,EQ-5D,Health-related quality of life,Hip Background,QALY,Total hip replacement,WOMAC},
title = {{The impact of preoperative patient characteristics on the cost-effectiveness of total hip replacement: a cohort study}}
}
@article{Havelin,
abstract = {Background: The Nordic (Scandinavian) countries have had working arthroplasty registers for several years. However,},
author = {Havelin, Leif I and Robertsson, Otto and Fenstad, Anne M and Overgaard, S{\o}ren and Garellick, G{\"{o}}ran and Furnes, Ove},
doi = {10.2106/JBJS.K.00951},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Havelin et al. - Unknown - A Scandinavian Experience of Register Collaboration The Nordic Arthroplasty Register Association (NARA).pdf:pdf},
keywords = {JBJS-A,The Journal of Bone and Joint Surgery},
title = {{A Scandinavian Experience of Register Collaboration: The Nordic Arthroplasty Register Association (NARA)}}
}
@article{,
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - 18{\_}bigpdfE2014pdfE1525.{\%}3:{\%}3},
title = {{18{\_}big{\%}2E2014{\%}2E1525}}
}
@article{,
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - BIO 176.pdf:pdf},
title = {{BIO 176}}
}
@article{Solka,
abstract = {Given i.i.d. observations x 1 Y x 2 Y x 3 Y F F F Y x n drawn from a mixture of normal terms, one is often interested in determining the number of terms in the mixture and their de®ning parameters. Although the problem of determining the number of terms is intractable under the most general assumptions, there is hope of elucidating the mixture structure given appropriate caveats on the underlying mixture. This paper examines a new approach to this problem based on the use of Akaike Information Criterion (AIC) based pruning of data driven mixture models which are obtained from resampled data sets. Results of the application of this pro-cedure to arti®cially generated data sets and a real world data set are provided.},
author = {Solka, Jeffrey L and Wegman, Edward J and Priebe, Carey E and Poston, Wendy L and Rogers, George W},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Solka et al. - Unknown - Mixture structure analysis using the Akaike Information Criterion and the bootstrap.pdf:pdf},
keywords = {AIC,bootstrap,cluster analysis,mixture models},
title = {{Mixture structure analysis using the Akaike Information Criterion and the bootstrap}}
}
@article{Hankin,
abstract = {This paper introduces the hypergeo package of R routines for numerical calculation of hypergeometric functions. The package is focussed on efficient and accurate evaluation of the Gauss hypergeometric function over the whole of the complex plane within the constraints of fixed-precision arithmetic. The hypergeometric series is convergent only within the unit circle, so analytic continuation must be used to define the function outside the unit circle. This short document outlines the numerical and conceptual methods used in the package; and justifies the package philosophy, which is to maintain transparent and verifiable links between the software and Abramowitz and Stegun (1965). Most of the package functionality is accessed via the single function hypergeo(), which dispatches to one of several methods depending on the value of its arguments. The package is demonstrated in the context of game theory.},
author = {Hankin, Robin K S},
file = {:C$\backslash$:/Users/eribu/Downloads/hypergeometric.pdf:pdf},
issn = {20734859},
keywords = {bredvidlasning,complex plane,hypergeometric functions,numerical evaluation,r,residue theo-},
mendeley-tags = {bredvidlasning},
number = {1},
pages = {1--7},
title = {{Numerical evaluation of the Gauss hypergeometric function with the hypergeo package}}
}
@article{Vogla,
abstract = {Background: The aim of the study was to analyze the effect of preoperative patient characteristics on health outcomes 6 months after total hip replacement (THR), to support patient's decision making in daily practice with predicted health states and satisfaction thresholds. By giving incremental effects for different patient subgroups, we support comparative effectiveness research (CER) on osteoarthritis interventions. Methods: In 2012, 321 patients participated in health state evaluation before and 6 months after THR. Health-related quality of life (HRQoL) was measured with the EQ-5D questionnaire. Hip-specific pain, function, and mobility were measured with the WOMAC in a prospective observation of a cohort. The predictive capability of preoperative patient characteristics – classified according to socio-demographic factors, medical factors, and health state variables – for changes in health outcomes is tested by correlation analysis and multivariate linear regressions. Related satisfaction thresholds were calculated with the patient acceptable symptom state (PASS) concept. Results: The mean WOMAC and EQ-5D scores before operation were 52 and 60 respectively (0 worst, 100 best). At the 6-month follow-up, scores improved by 35 and 19 units. On average, patients reported satisfaction with the operation if postoperative (change) WOMAC scores were higher than 85 (32) and postoperative (change) EQ-5D scores were higher than 79 (14). Conclusions: Changes in WOMAC and EQ-5D scores can mainly be explained by preoperative scores. The lower the preoperative WOMAC or EQ-5D scores, the higher the change in the scores. Very good or very poor preoperative scores lower the probability of patient satisfaction with THR. Shared decision making using a personalized risk assessment approach provides predicted health states and satisfaction thresholds.},
author = {Vogl, Matthias and Wilkesmann, Rainer and Lausmann, Christian and Hunger, Matthias and Pl{\"{o}}tz, Werner},
doi = {10.1186/s12955-014-0108-1},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Vogl et al. - Unknown - The impact of preoperative patient characteristics on health states after total hip replacement and related sati.pdf:pdf},
keywords = {EQ-5D,Health-related quality of life,Patient acceptable symptom state,Satisfaction,Total hip replacement,WOMAC},
title = {{The impact of preoperative patient characteristics on health states after total hip replacement and related satisfaction thresholds: a cohort study}}
}
@article{Frosch,
abstract = {Content: Shared medical decision making is a process by which patients and providers consider outcome probabilities and patient preferences and reach a health care decision based on mutual agreement. Shared decision making is best used for problems involving medical uncertainty. During the process the provider-patient dyad considers treatment options and consequences and explores the fit of expected benefits and consequences of treatment with patient preferences for various outcomes. This paper reviews the literature on shared medical decision making. Several questions are considered. Although several studies suggest that patients do not want to be involved in decision making, these studies typically fail to separate decisions about technical aspects of treatment from preferences for outcomes. There is considerable evidence that patients want to be consulted about the impact of treatment. Studies on the acceptability of shared decision making for physicians have produced inconsistent results. Shared decision making is more acceptable to younger and better-educated patients. It remains unclear whether shared decision making requires expensive video presentations or whether the same results can be obtained with simpler methods, such as the decision board. We conclude that shared medical decision making is an important development in health care. More research is necessary to identify the effects of shared decision making on patient satisfaction and health outcomes. Further, more research is necessary in order to evaluate the most effective methods for engaging patients in decisions about their own health care. Medical Subject Headings (MeSH): decision making, outcome assessment, research, patient satisfaction, probability, decision aid (Am J Prev Med 1999;17(4):285–294) © 1999 American Journal of Preventive Medicine O ver the last decades, there has been an increas-ing emphasis on patient participation in med-ical decision making. An alternative to the paternalistic model in which the physician makes all treatment decisions is " shared decision making. " Shared decision making must not be confused with obtaining informed consent from a patient. While ethical guidelines mandate informed consent, espe-cially when a recommendation involves a potentially harmful intervention, shared decision making goes several steps further. Beyond presenting the patient with facts about a procedure, shared decision making is a process by which doctor and patient consider avail-able information about the medical problem in ques-tion, including treatment options and consequences, and then consider how these fit with the patient's preferences for health states and outcomes. After con-sidering the options, a treatment decision is made based on mutual agreement. 1 Several conditions must be met for shared decision making to occur. First, the atmosphere must be conducive to active patient partic-ipation. The attending physician must make patients feel that their contributions are valued. Patients in turn need to be frank about their preferences and goals for treatment. The physician then helps the patient deter-mine how these goals and preferences fit with the available treatment options and a shared decision is reached.},
author = {Frosch, Dominick L and Kaplan, Robert M},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Frosch, Kaplan - Unknown - Shared Decision Making in Clinical Medicine Past Research and Future Directions.pdf:pdf},
title = {{Shared Decision Making in Clinical Medicine: Past Research and Future Directions}}
}
@article{,
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - 24{\_}Modeling{\_}Valuations{\_}for{\_}EuroQol{\_}Health{\_}States.html:html},
title = {{24{\_}Modeling{\_}Valuations{\_}for{\_}EuroQol{\_}Health{\_}States.}}
}
@article{Voglb,
abstract = {Purpose We compare pre-and post-operative health-related quality of life (HRQoL) and length of stay after total hip replacement (THR) in matched German and English patient cohorts to test for differences in admission thresholds, clinical effectiveness and resource utilisation between the healthcare systems. Methods German data (n = 271) were collected in a large orthopaedic hospital in Munich, Germany; English data (n = 26,254) were collected as part of the national patient-reported outcome measures programme. HRQoL was measured using the EuroQoL-5D instrument. Propen-sity score matching was used to construct two patient cohorts that are comparable in terms of preoperative patient characteristics. Results Before matching, patients in England showed lower preoperative EQ-5D scores (0.35 vs 0.52, p $\backslash$ 0.001) and experienced a larger improvement in HRQoL (0.43 vs 0.33, p $\backslash$ 0.001) than German patients. Patients in the German cohort were more likely to report no or only moderate problems with mobility and pain preoperatively than their English counterparts. After matching, improve-ments in HRQoL were comparable (0.32 vs 0.33, p = 0.638); post-operative scores were slightly higher in the German cohort (0.82 vs 0.85, p = 0.585). Length of stay was substantially lower in England than in Germany (4.5 vs 9.0 days, p $\backslash$ 0.001). Conclusions Our results highlight differences in preop-erative health status between countries, which may arise due to different admission thresholds and access to surgery. In terms of quality of life, THR surgery is equally effective in both countries when performed on similar patients, but hospital stay is shorter in England.},
author = {Vogl, Matthias and Leidl, Reiner and Pl{\"{o}}tz, Werner and Gutacker, Nils},
doi = {10.1007/s11136-014-0782-9},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Vogl et al. - Unknown - Comparison of pre-and post-operative health-related quality of life and length of stay after primary total hip r.pdf:pdf},
keywords = {England {\'{A}},Germany,Health-related quality of life {\'{A}} EQ-5D {\'{A}},Introduction,Total hip replacement {\'{A}}},
title = {{Comparison of pre-and post-operative health-related quality of life and length of stay after primary total hip replacement in matched English and German patient cohorts}}
}
@article{Rolfson,
abstract = {There is increasing interest in measuring patient-reported outcomes as part of routine medical practice, partic-ularly in fields like total joint replacement surgery, where pain relief, satisfaction, function, and health-related quality of life, as perceived by the patient, are primary outcomes. We review some well-known outcome instruments, measurement issues, and early experiences with large-scale collection of patient-reported outcome measures in joint registries. The patient-reported outcome measures are reviewed in the context of multidimensional outcome assessment that includes the traditional clinical outcome parameters as well as disease-specific and general patient-reported outcome measures.},
author = {Rolfson, Ola and Rothwell, Alastair and Sedrakyan, Art and {Eresian Chenok}, Kate and Bohm, Eric and Bozic, Kevin J and Garellick, G{\"{o}}ran},
doi = {10.2106/JBJS.K.01021},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rolfson et al. - Unknown - Use of Patient-Reported Outcomes in the Context of Different Levels of Data Why Patient-Reported Outcome Meas.pdf:pdf},
keywords = {The Journal of Bone and Joint Surgery},
title = {{Use of Patient-Reported Outcomes in the Context of Different Levels of Data* Why Patient-Reported Outcome Measures (PROMs) Data Are Needed}}
}
@article{Davison,
abstract = {◮ Bootstrap: simulation methods for frequentist inference. ◮ Useful when • standard assumptions invalid (n small, data not normal, . . .); • standard problem has non-standard twist; • complex problem has no (reliable) theory; • or (almost) anywhere else.},
author = {Davison, Anthony},
file = {:C$\backslash$:/Users/eribu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Davison - Unknown - Bootstrap Methods and their Application.pdf:pdf},
keywords = {2 Motivation,@BULLET confidence intervals,@BULLET tests,Bootstrap Methods and their Application,◮ Aim to describe @BULLET basic ideas},
title = {{Bootstrap Methods and their Application}}
}
@misc{,
file = {:C$\backslash$:/Users/eribu/Downloads/ref{\_}till{\_}coop1916/15679.pdf:pdf},
title = {15679.pdf}
}
@misc{,
file = {:C$\backslash$:/Users/eribu/Downloads/ref{\_}till{\_}coop1916/15679.pdf:pdf},
title = {15679.pdf}
}
