\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={Erik Bulow},
            pdftitle={Arbetslogg 2016 vecka 9},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\ImportTok}[1]{{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{{#1}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{{#1}}}}
\newcommand{\BuiltInTok}[1]{{#1}}
\newcommand{\ExtensionTok}[1]{{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{Arbetslogg 2016 vecka 9}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \author{Erik Bulow}
  \preauthor{\centering\large\emph}
  \postauthor{\par}
  \predate{\centering\large\emph}
  \postdate{\par}
  \date{29 februari 2016}


% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\begin{document}
\maketitle

{
\hypersetup{linkcolor=black}
\setcounter{tocdepth}{2}
\tableofcontents
}
\section{FÃ¶rberedelser}\label{farberedelser}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Try it out!}
\KeywordTok{memory.limit}\NormalTok{(}\DecValTok{50000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 50000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{options}\NormalTok{(}\DataTypeTok{samplemetric.log =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{2016-02-29}\label{section}

Har udner helgen roat mig med at lÃ¤sa Sigma och bl a den fÃ¶rst kÃ¤nda
publicerade artikeln om statistik (frÃ¥n 1600-talet). Intressant
kuriositet Ã¤ven om det kanske inte har ngn direkt nytta fÃ¶r jobbet
just nu.

\subsection{LÃ¤sning av (Pearson 1895)}\label{lasning-av-pearson1895}

(LÃ¤ste egentligen denna fÃ¶rra veckan.)

Ã„r lite okklar Ã¶ver referenserna. Tror jag hittade referens som pekade
pÃ¥ denna artikel som upphov till korrelationskoefficienten (men hittade
ocksÃ¥ annan referens som ist pekade pÃ¥ (Pearson 1895)). Men den nÃ¤mns
i denna arikel ocsÃ¥ och dÃ¥ denna publicerades fÃ¶re den senare sÃ¥
bÃ¶r det kanske vaar sant. Men hÃ¤r hÃ¤nvisas ocksÃ¥ till Galtons formel
sÃ¥ egentligen var det inte helt nytt.

VÃ¤ldigt kort note som egentligen Ã¤r del av lÃ¤ngre paper som inte han
fÃ¤rdigstÃ¤llas pga hÃ¤lsoproblem.

\subsection{LÃ¤sning av (Pearson 1896)}\label{lasning-av-pearson1896}

SÃ¤gs vara kÃ¤llan till korrelationskoefficienten. Framkommer dock att
konceptet de facto var kÃ¤nt sedan tidigare. Texten utgÃ¥r frÃ¥n ganska
praktiska exempel med heriditet och sexuel reproduktion etc. Ger Ã¤ran
till Bravais och delvis ocksÃ¥ till Edgeworth, Galton och Weldon.
InnehÃ¥ller rtedan hÃ¤r en del teori om fÃ¶rdelning baserat pÃ¥
\(\chi^2\) etc. Refereras ocksÃ¥ till \(r\) som Galtons funktion (Galton
myntade f.Ã¶. Ã¤ven uttrycket regression). Redan dÃ¥ anvÃ¤ndes
normalapproximation. Texten utgÃ¥r frÃ¥n ganska teoretiska berÃ¤kningar
men konstateras att den praktiska formeln fÃ¶r att berÃ¤kna \(r\) Ã¤r
den Bravais fÃ¶reslagit men utan att ha visat att det verkligen var den
bÃ¤sta formeln. Se s 265 fÃ¶r formeln.

Konstaterar redan hÃ¤r att:

\begin{quote}
Thus we may say that with sufficient accuracy for most cases the
standard deviation of a coefficient of correlation is:
\end{quote}

\begin{quote}
\[\frac{1 - r^2}{\sqrt{n(1 + r^2)}}\]
\end{quote}

\begin{quote}
or its probable error = \[.674506 \frac{1- r^2}{\sqrt{n(1 +r^2)}}\]
{[}\ldots{}{]} It will be sufficient therefore, for most practical
purposes to assume that the probable error of a coefficient of
correlation
\end{quote}

\[= .674506 \frac{1 - r^2}{\sqrt{n(1+r^2)}}\].

HÃ¤r talas dock ocksÃ¥ om ganska stora stickprovsstorlekar sÃ¥som
\(n = 1000\). Skriver om ett dataset med 200 samlpes att:

\begin{quote}
The number is not sufficientlty great to make the probable error of
quite small enough dimensions in several cases, and so allow of definite
conclusions.
\end{quote}

(F.Ã¶. ett sample baserat pÃ¥ Ã¶vre medelklass sÃ¥ kudne dÃ¤rav inte
heller nyttjas fÃ¶r generella slutsatser om populationen.
Ã\ldots{}terkmmer Ã¤ven pÃ¥ s 273 till att vi inte kan anta
normalfÃ¶rdelning hÃ¤r. Refererar till att normalfÃ¶rdelning kunde antas
vid studie av 900 kraniemÃ¤tningar utfÃ¶rda vid tidigare studie.)

f.Ã¶. undersÃ¶ks i artikeln relationen mellan fÃ¶rÃ¤ldrars lÃ¤ngd och
kÃ¶n pÃ¥ avkomma. Konstateras (med viss reservation) att t ex lÃ¤ngre
fÃ¤der tenderar fÃ¥ dÃ¶ttrar i ngt hÃ¶gre utstrÃ¤ckning Ã¤n sÃ¶ner. Dock
svÃ¥rare att se mÃ¶nster fÃ¶r mÃ¶drar. Ser Ã¤ven att korrelation fÃ¶r
lÃ¤ngder tycks Ã¤rvas starkare pÃ¥ fÃ¤dernet Ã¤n mÃ¶dernet Ã¤ven sett
Ã¶ver flera generationsled.

F.Ã¶. intressant att artikeln blandar bÃ¥de teori men ocksÃ¥ ganska
utfÃ¶rliga praktiska beskrivningar. KÃ¤nns bÃ¥de konrekt och vÃ¤l
underbyggt pÃ¥ samma gÃ¥ng.

GÃ¶r inget fÃ¶rdelningsantagande fÃ¶r data vi samplar ifrÃ¥n.

Noterar f.Ã¶. att han nÃ¤mner korrelation och standradavvikelse etc men
gÃ¶r inga referenser til kovarians.

Behandlar ocksÃ¥ fallet med tre grupper att jÃ¤mfÃ¶ra och dÃ¤rmed tre
parvisa korrelationer.

GÃ¶rs ocksÃ¥ studier av korraltion av ansiktsbehÃ¥ring, dvs
Ã¤rftligheten av detta. Ã„ven referenser till att fÃ¤rgblindhet Ã¤rvs
frÃ¥n morfar till dotterson.

Behandlar Ã¤ven fall med 4 korrelationer. Denna teknik tycks anvÃ¤ndas
dÃ¤r man idag istÃ¤llet skulle anvÃ¤nda regression i modern mening.

Efter ett par generationer kommer familjÃ¤ra sÃ¤rdrag suddas ut varpÃ¥
slÃ¤kten alltmer liknar populationen. Detta gÃ¤ller Ã¤ven vid selektive
breeding. Skulle behÃ¶vas experiment fÃ¶r att empiriskt utrÃ¶na effekten
av selektive breeding etc! :-)

\subsection{LÃ¤sning av (Nemes et al. 2009)}\label{lasning-av-nemes2009}

Tipsad av denna av SN. Inte fÃ¶r att Ã¤mnet i sig Ã¤r direkt relevant
men dÃ¥ upplÃ¤gget pÃ¥ sjÃ¤lva artikeln kan antas liknande nu
fÃ¶religgande fÃ¶rutsÃ¤ttningar. Konstaterar bias fÃ¶r mindre
stickprovsstorlekar. Ã„ven hÃ¤r ses approximatil normalfÃ¶rdelning av
oddskvoten fÃ¶r stora n. Finns Ã¤ven hÃ¤r en skev bakomliggande
fÃ¶rdelning. Ã„ven hÃ¤r Ã¤r problemen kÃ¤nda teoretiskt men inte bland
praktiker. Fnins ocksÃ¥ fÃ¶rslag pÃ¥ bias-korrected versioner.

Ger ingen rekommendation om sample size men konstaterar att andra
fÃ¶reslagit minst 100 och helst mer Ã¤n 500. Diskret data krÃ¤ver
stÃ¶rre smaple, liksom starkt korrelerade data.

Biasen pÃ¥verkar pÃ¥ sÃ¥ sÃ¤tt att smÃ¥ stickprovsstorlekar pÃ¥visar
stÃ¶rre effekt Ã¤n fÃ¶r stÃ¶rre samples.

Beskriver risken med detta att man publicerar material som inte stÃ¤mmer
med verkligheten. Ã„ven problem vid metastudier dÃ¥ man inte tnker pÃ¥
detta dÃ¥ flera studier jÃ¤mfÃ¶rs.

PÃ¥ det hela taget mkt intressant och viktigt!

\subsection{LÃ¤sning av (Cowden 1952)}\label{lasning-av-cowden1952}

Handlar om multipel-partial correlation coefficient. FÃ¶rklarar att
``multiple correlation coefficient'' Ã¤r vÃ¥r koefficient dÃ¤r
observerad vs predicted values korreleras och dÃ¤r pred beror pÃ¥ en
eller flera variabler. Artikeln infÃ¶r ocksÃ¥ ``multiple-partial
correleation coefficient'', en justerad correlation mellan utfall samt
tvÃ¥ eller fler oberoende variabler.

InnehÃ¥ller mkt hÃ¤rledningar och teori. KÃ¤nns dock inte helt relevant
i sammanhangert sÃ¥ lÃ¤mnar den ej fÃ¤rdiglÃ¤st.

\subsection{LÃ¤sning av (Kymn 1968)}\label{lasning-av-kymn1968}

Det Ã¤r kÃ¤nt sedan tidigare att:

\[ F = r^2\frac{n-2}{1-r^2} \sim F_{1, n-2} \]

samt

\[ t = r\frac{\sqrt{n-2}}{1-r^2} \sim t_{n-2} \]

Denna artikel visar nu att

\[ S = \frac{1+r}{1-r} \sim F_{n-2, n-2} \]

FÃ¶rdelen med denna Ã¤r att fÃ¶rdelningen Ã¤r symmetrisk samt ev att
\(S\) inte beror pÃ¥ \(n\) (men det gÃ¶r ju Ã¥ andra sidan \(F\) sÃ¥ jag
vet inte riktigt varfÃ¶r det skulle vara sÃ¥ stor skillnad).

\textbf{OBS!} Bygger pÃ¥ att \(x, y\) Ã¤r bivariat normalfÃ¶rdelade och
oberoende \(\rho = 0\) sÃ¥ nyttan av detta kanske Ã¤r begrÃ¤nsad?

Noterar hÃ¤r att enligt (Hotelling 1953) krÃ¤vs dock inte bivariat
normalfÃ¶rdelning just dÃ¥ \(\rho = 0\)

\subsection{UndersÃ¶ker icke-central
betafÃ¶rdelning}\label{undersaker-icke-central-betafardelning}

Tar en avstickare och fÃ¶rsÃ¶ker skapa funktion fÃ¶r icke-central
betafÃ¶rdelning. Noterar att \(x\) ska antas fix och har dÃ¤rmed ingen
kÃ¤nd fÃ¶rdelning

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#' Parameters for the noncentral beta distribution of R2}
\CommentTok{#'}
\CommentTok{#' @param ncp1 first part of the con centrality parameter }
\CommentTok{#' as given by \textbackslash{}code\{\textbackslash{}link\{ncp1\}\}}
\CommentTok{#' @param x object of class \textbackslash{}code\{\textbackslash{}link\{sim_data\}\}}
\CommentTok{#' @return List with "shape1", "shape2" and "npc" parameters }
\CommentTok{#' as used for corresponding arguments in the \textbackslash{}code\{\textbackslash{}link\{Beta\}\}}
\CommentTok{#' functions.}
\CommentTok{#' @export}
\NormalTok{r2_beta_param <-}\StringTok{ }\NormalTok{function(ncp1, x) \{}
  \KeywordTok{stopifnot}\NormalTok{(}\KeywordTok{ncol}\NormalTok{(x) ==}\StringTok{ }\DecValTok{2}\NormalTok{)}
  \KeywordTok{list}\NormalTok{(}
    \DataTypeTok{shape1 =} \NormalTok{.}\DecValTok{5}\NormalTok{,}
    \DataTypeTok{shape2 =} \NormalTok{(}\KeywordTok{nrow}\NormalTok{(x) -}\StringTok{ }\DecValTok{2}\NormalTok{) /}\StringTok{ }\DecValTok{2}\NormalTok{,}
    \DataTypeTok{ncp =} \NormalTok{ncp1 *}\StringTok{ }\KeywordTok{sum}\NormalTok{((x$X1 -}\StringTok{ }\KeywordTok{mean}\NormalTok{(x$X1)) ^}\StringTok{ }\DecValTok{2}\NormalTok{)}
  \NormalTok{)}
\NormalTok{\} }


\CommentTok{#' Calculate the first half of the non centrally parameter of R2}
\CommentTok{#'}
\CommentTok{#' Calculate the non observal dependent part of the }
\CommentTok{#' centrality parameter used as argument }
\CommentTok{#' "ncp" in the \textbackslash{}code\{\textbackslash{}link\{Beta\}\} family of functions}
\CommentTok{#'}
\CommentTok{#' @param x object of class \textbackslash{}code\{\textbackslash{}link\{sim_data\}\}}
\CommentTok{#' @return numeric vector of length one}
\CommentTok{#' @export}
\CommentTok{#' @examples}
\CommentTok{#' ncp1 <- ncp1(sim_data())}
\NormalTok{ncp1 <-}\StringTok{ }\NormalTok{function(x) \{}
  \KeywordTok{stopifnot}\NormalTok{(}\KeywordTok{ncol}\NormalTok{(x) ==}\StringTok{ }\DecValTok{2}\NormalTok{)}
  \NormalTok{fit    <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(Y ~}\StringTok{ }\NormalTok{., }\DataTypeTok{data =} \NormalTok{x)}
  \NormalTok{beta   <-}\StringTok{ }\NormalTok{fit$coefficients[}\DecValTok{2}\NormalTok{]}
  \NormalTok{sigma2 <-}\StringTok{ }\KeywordTok{var}\NormalTok{(fit$residuals)}
 \NormalTok{(beta ^}\StringTok{ }\DecValTok{2}\NormalTok{) /}\StringTok{ }\NormalTok{(}\DecValTok{2} \NormalTok{*}\StringTok{ }\NormalTok{sigma2)}
\NormalTok{\}}

\CommentTok{#' The R2 disrtibution based on the Beta distribution}
\CommentTok{#'}
\CommentTok{#' @param fun one of the functions listed at \textbackslash{}code\{\textbackslash{}link\{Beta\}\}}
\CommentTok{#' @param ncp1 value given by \textbackslash{}code\{\textbackslash{}link\{ncp1\}\}}
\CommentTok{#' @param d object of class \textbackslash{}code\{\textbackslash{}link\{sim_data\}\} with columns }
\CommentTok{#' \textbackslash{}code\{Y\} and \textbackslash{}code\{X1\}.}
\CommentTok{#' @param ... arguments passed to \textbackslash{}code\{fun\} }
\CommentTok{#' @return Value returned by call to \textbackslash{}code\{fun\}}
\NormalTok{r2_beta <-}\StringTok{ }\NormalTok{function(fun, ncp1, d, ...) \{}
  \KeywordTok{do.call}\NormalTok{(fun, }\KeywordTok{c}\NormalTok{(}\KeywordTok{r2_beta_param}\NormalTok{(ncp1, d), }\KeywordTok{list}\NormalTok{(...)))}
\NormalTok{\}}


\NormalTok{d <-}\StringTok{ }\KeywordTok{sim_data}\NormalTok{(}\DataTypeTok{r2 =} \NormalTok{.}\DecValTok{5}\NormalTok{, }\DataTypeTok{p =} \DecValTok{1}\NormalTok{)}
\NormalTok{dsample <-}\StringTok{ }\NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{50}\NormalTok{)}
\NormalTok{ncp_1 <-}\StringTok{ }\KeywordTok{ncp1}\NormalTok{(d)}
\CommentTok{# r2_beta(dbeta, ncp_1, d = dsample, x = seq(0.01,1,.01))}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dsample, }\DataTypeTok{x =} \NormalTok{x))}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{v =} \NormalTok{.}\DecValTok{5}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(pbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dsample, }\DataTypeTok{q =} \NormalTok{x))}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{v =} \NormalTok{.}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_files/figure-latex/unnamed-chunk-3-1.pdf}

Ã„r detta enligt fÃ¶rvÃ¤ntan? Ser ut som att vi underskattar \(r^2\)
vÃ¤ldigt grovt \ldots{}?

\section{2016-03-01}\label{section-1}

FortsÃ¤tter titta pÃ¥ simuleringarna ovan. GÃ¶r om nÃ¥gra ggr och finner
att det nog bara var slump att det blve sÃ¥ biased. BeÃ¶hver simulera
flera ggr men lite osÃ¤ker pÃ¥ hur. Det bli rju olika fÃ¶rdelningar
varje gÃ¥ng. Ska jag berÃ¤kna medelvÃ¤rden fÃ¶r \texttt{npc} eller pÃ¥
ngt sÃ¤tt fÃ¶r hela fÃ¶rdelningen?

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x)); }\KeywordTok{abline}\NormalTok{(}\DataTypeTok{v =} \NormalTok{.}\DecValTok{5}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{curve}\NormalTok{(}\KeywordTok{r2_beta}\NormalTok{(dbeta, ncp_1, }\DataTypeTok{d =} \NormalTok{dplyr::}\KeywordTok{sample_n}\NormalTok{(d, }\DecValTok{30}\NormalTok{), }\DataTypeTok{x =} \NormalTok{x), }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_files/figure-latex/unnamed-chunk-4-1.pdf}

\subsection{Diskussion med SN}\label{diskussion-med-sn}

Ã„r ovanligt och lite konstigt att fÃ¶rdelningen i detta fall beror pÃ¥
observerade data. FÃ¶r t ex t- och F-fÃ¶rdelning finns ju ett beroende
av frihetsgrad (stickprovsstorlek) men inte av sjÃ¤lva datapunkterna.
Att ha ett sÃ¥dant beroende kÃ¤nns lite mÃ¤rkligt dÃ¥ man pÃ¥ ngt sÃ¤tt
rÃ¤ttfÃ¤rdigar ett observerat resultat genom teorier byggda pÃ¥ samma
observerade resultat, vilket kÃ¤nns som ett cirkelresonameng. Ã\ldots{}
andra sidan Ã¤r vÃ¤l just detta anledningen till att \(x\) enl teorin
heller inte Ã¤r att betrakta som en slumpvariabel utan som fix.

Slutsatser:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Det gÃ¥r inte att finna en enda teoretisk fÃ¶rdelning (facit) dÃ¥ den
  alltid kommer att bero pÃ¥ slumpen.
\item
  Vad vi kan gÃ¶ra Ã¤r att koncentrera oss pÃ¥ t ex olika moment av
  fÃ¶rdelningen. Vi kan t ex ta ett stickprov och fÃ¶r detta berÃ¤kna
  bÃ¥de den semiteoretiska fÃ¶rdelning detta ger upphov till, samt
  skatta R2 direkt. Vi jÃ¤mfÃ¶r sedan skattningen mot vÃ¤rdet givet av
  vÃ¤ntevÃ¤rdet givet av fÃ¶rdelningen. Vi upprepar mÃ¥nga ggr och
  plottar dessa vÃ¤rden med qqplot fÃ¶r att undersÃ¶ka ev bias.
\item
  Kan ocksÃ¥ vara av vÃ¤rde att undersÃ¶ka ifall det finns metod att
  skatta betafÃ¶rdelningens parametrar utifrÃ¥n data pÃ¥ ngt mer
  generellt sÃ¤tt.
\end{enumerate}

Vi fÃ¶rsÃ¶ker gÃ¶ra enl (2) ovan. Dock behÃ¶ver vi fÃ¶r detta jÃ¤mfÃ¶ra
skattningen inte mot mean utan mot mode fÃ¶r att fÃ¥ det korrekt. Dock
svÃ¥rt att finna ngn formel fÃ¶r mode av icke cenrtal betafÃ¶rdelning.
Finns funktion \texttt{modeest::betaMode} men den funktionen hanterar
Ã¤ndÃ¥ inte detta.

Enl (Park 1964) krÃ¤vs numerisk approximation fÃ¶r skattning av mode
fÃ¶r icke-central beta. Formel presenteras i (3.2) men bygger pÃ¥
antaganden (sÃ¥som att \(r^2 \rightarrow 1\)), vilket gÃ¶r det hela
ointeressant. Ett alternativ blir dÃ¥ att skatta ett numeriskt vÃ¤rde
(sÃ¥som vi ocksÃ¥ gjort vid tidigare simulering), vilket vi lÃ¤tt kan
gÃ¶ra om vi antar att fÃ¶rdelningen Ã¤r unimodal, vilket vi hÃ¤r kan.
Observera dock att vi hÃ¤r inte ska basera mode-skattningen pÃ¥ vÃ¥rt
slumpmÃ¤ssiga urval utan pÃ¥ fÃ¶rdelningens vÃ¤rde fÃ¶r
\(\forall x: x \in [0,1]\) fÃ¶r relevant fÃ¶rdelning. Kanske skulle man
ocksÃ¥ kunna undersÃ¶ka metoder fÃ¶r att finna mode via paketet
\texttt{modehunt}. Jag har Ã¤nnu inte fÃ¶rdjupat mig i det och vet
sÃ¥ledes inte ifall det skulle ge annat resultat Ã¤n min egen
mode-funktion.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{r2_beta_mode <-}\StringTok{ }\NormalTok{function(ncp1, d, ...) \{}
  \NormalTok{x <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\FloatTok{0.001}\NormalTok{, }\DecValTok{1}\NormalTok{, .}\DecValTok{001}\NormalTok{)}
  \NormalTok{y <-}\StringTok{ }\KeywordTok{r2_beta}\NormalTok{(dbeta, }\DataTypeTok{ncp1 =} \NormalTok{ncp1, }\DataTypeTok{d =} \NormalTok{d, }\DataTypeTok{x =} \NormalTok{x, ...)}
  \NormalTok{x[y ==}\StringTok{ }\KeywordTok{max}\NormalTok{(y)]}
\NormalTok{\}}

\CommentTok{# Prepare data sets}
\NormalTok{d <-}\StringTok{ }\KeywordTok{sim_data}\NormalTok{(}\DataTypeTok{r2 =} \NormalTok{.}\DecValTok{5}\NormalTok{, }\DataTypeTok{p =} \DecValTok{1}\NormalTok{)}
\NormalTok{ss <-}\StringTok{ }\KeywordTok{subsamples}\NormalTok{(d, }\DataTypeTok{n.max =} \DecValTok{30}\NormalTok{, }\DataTypeTok{N =} \DecValTok{1000}\NormalTok{)}
\NormalTok{ncp_1 <-}\StringTok{ }\KeywordTok{ncp1}\NormalTok{(d)}

\CommentTok{# Calculate "theoretical modes" and "observed r2"}
\NormalTok{modes <-}\StringTok{ }\KeywordTok{vapply}\NormalTok{(ss, function(d) }\KeywordTok{r2_beta_mode}\NormalTok{(ncp_1, d), }\KeywordTok{numeric}\NormalTok{(}\DecValTok{1}\NormalTok{))}
\NormalTok{r2s <-}\StringTok{ }\KeywordTok{metrics}\NormalTok{(ss, }\DataTypeTok{n.sample =} \DecValTok{30}\NormalTok{)$Rsquared}

\CommentTok{# Plot and compare}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(r2s, modes, }\DataTypeTok{xlim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{8}\NormalTok{), }\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{6}\NormalTok{))}
\KeywordTok{abline}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\KeywordTok{qqplot}\NormalTok{(r2s, modes)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_files/figure-latex/unnamed-chunk-5-1.pdf} Vi ser
hÃ¤r att vÃ¥r teoretiska mode underskattr vÃ¥rt observerade vÃ¤rde. Ã„r
det trots allt sÃ¥ att vi inte bÃ¶r jÃ¤mfÃ¶ra mot mode utan mot mean?
Det finns visserilgen en teoretisk formel fÃ¶r att berÃ¤kna mean av icke
cenrtal betafÃ¶rdelning men den behÃ¶ver i sin tur en confluent
hypergeometric function. Det finns dock fler versioner av detta och de
som finns implementerade i R tycks inte motsvara den hÃ¤r aktuella. Vi
fÃ¥r dÃ¤rfÃ¶r skatta mean pss som vi tidigare skattade mode. Ã\ldots{}
andra sidan har vi ocksÃ¥ en formel fÃ¶r vÃ¤ntevÃ¤rdet av \(r^2\) fÃ¶r
selektive samlpnig given av (Warren 1971) avs 2.2. Ã„ven hÃ¤r refereras
till en confluent hypergeometric function men dÃ¥ denna har endast tre
variabler Ã¤r sannolikheten stÃ¶rre att denna Ã¤r samma som t ex
\texttt{hypergeo::genhypergeo}. Dock krÃ¤vs fler parametrar som jag
inble blir riktigt klok pÃ¥ (tycks smo att man ska slumpa \(n\) vÃ¤rden
frÃ¥n varje punkt tagen med selective samplnig men jag fÃ¥r inte riktigt
ihop det).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{r2_beta_mean <-}\StringTok{ }\NormalTok{function(ncp1, d, ...) \{}
  \NormalTok{x <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\FloatTok{0.001}\NormalTok{, }\DecValTok{1}\NormalTok{, .}\DecValTok{001}\NormalTok{)}
  \NormalTok{y <-}\StringTok{ }\KeywordTok{r2_beta}\NormalTok{(dbeta, }\DataTypeTok{ncp1 =} \NormalTok{ncp1, }\DataTypeTok{d =} \NormalTok{d, }\DataTypeTok{x =} \NormalTok{x, ...)}
  \KeywordTok{sum}\NormalTok{((y /}\StringTok{ }\KeywordTok{sum}\NormalTok{(y)) *}\StringTok{ }\NormalTok{x)}
\NormalTok{\}}

\CommentTok{# Calculate "theoretical modes" and "observed r2"}
\NormalTok{means <-}\StringTok{ }\KeywordTok{vapply}\NormalTok{(ss, function(d) }\KeywordTok{r2_beta_mean}\NormalTok{(ncp_1, d), }\KeywordTok{numeric}\NormalTok{(}\DecValTok{1}\NormalTok{))}

\CommentTok{# Plot and compare}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(r2s, means, }\DataTypeTok{xlim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{8}\NormalTok{), }\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{8}\NormalTok{), }\DataTypeTok{main =} \StringTok{"Comparison to mean"}\NormalTok{)}
  \KeywordTok{abline}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{); }\KeywordTok{points}\NormalTok{(.}\DecValTok{5}\NormalTok{, .}\DecValTok{5}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{5}\NormalTok{, }\DataTypeTok{col =} \StringTok{"red"}\NormalTok{)}
\KeywordTok{qqplot}\NormalTok{(r2s, means, }\DataTypeTok{xlim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{8}\NormalTok{), }\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{8}\NormalTok{), }\DataTypeTok{main =} \StringTok{"Comparison to mean"}\NormalTok{)}
  \KeywordTok{abline}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }
\KeywordTok{plot}\NormalTok{(r2s, modes, }\DataTypeTok{xlim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{8}\NormalTok{), }\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{8}\NormalTok{), }\DataTypeTok{main =} \StringTok{"Comparison to mdoe"}\NormalTok{)}
  \KeywordTok{abline}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{); }\KeywordTok{points}\NormalTok{(.}\DecValTok{5}\NormalTok{, .}\DecValTok{5}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{5}\NormalTok{, }\DataTypeTok{col =} \StringTok{"red"}\NormalTok{)}
\KeywordTok{qqplot}\NormalTok{(r2s, modes, }\DataTypeTok{xlim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{8}\NormalTok{), }\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{8}\NormalTok{), }\DataTypeTok{main =} \StringTok{"Comparison to mode"}\NormalTok{)}
  \KeywordTok{abline}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\includegraphics{test_files/figure-latex/unnamed-chunk-6-1.pdf}

RÃ¶da prickar markerar \(\rho^2\) men observera hÃ¤r att vÃ¤rden pÃ¥
y-axeln (mean resp mode) inte syftar till att approximera det teoretiska
vÃ¤rdet utan vÃ¤rdet fÃ¶r \(r^2\), vilket vi vet underskattar \(\rho^2\)
fÃ¶r varje enskild observation. Om \(r^2\) skulle fÃ¶lja den
ickecenrtala betafÃ¶rdelningen skulle vi dock se observationer
centrerade kring linjen i graferna. Det gÃ¶r vi inte. Vad vi ser Ã¤r
istÃ¤llet att den teoretiska fÃ¶rdelningen tycks underskatta observerade
\(r^2\) systematiskt. Vi ser endast marginell skillnad mellan mode och
mean (tyder vÃ¤l pÃ¥ att den teoretiska fÃ¶rdelningen Ã¤r mindre skev
Ã¤n den verkliga?) men mÃ¶jligt att mode Ã¤r lite bÃ¤ttre (vilket
stÃ¤mmer med teorin).

\textbf{Slutsats:} Den icke centrala betafÃ¶rdelningen enligt (Hogben
1968) underskattar \(r^2\).

Men fÃ¶r att sammanfatta sÃ¥ avviker jag ocksÃ¥ frÃ¥n teorin enl:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Mitt x slumpas (ej fixt). Vet dock inte riktigt hur detta bÃ¶r
  pÃ¥verka resultatet.
\item
  Mode och mean frÃ¥n fÃ¶rdelningen Ã¤r skattade pÃ¥ kanske inte allra
  bÃ¤sta sÃ¤tt? Ett alternativ Ã¤r kanske att nyttja fÃ¶rdelningen till
  att slumpa fram en massa vÃ¤rden och sedan berÃ¤kna mode och mean av
  det. Tycker dock inte det borde bli ngn skillnad \ldots{} men kan ju
  fÃ¶rstÃ¥s testa \ldots{}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mode <-}\StringTok{ }\NormalTok{function(d) \{}
  \NormalTok{z <-}\StringTok{ }\KeywordTok{density}\NormalTok{(d)}
  \NormalTok{z$x[z$y ==}\StringTok{ }\KeywordTok{max}\NormalTok{(z$y)]}
\NormalTok{\}}

\CommentTok{# Mode baserat pÃ¥ simulering}
\NormalTok{r2_beta_mode_r <-}\StringTok{ }\NormalTok{function(ncp1, d, ...) \{}
  \NormalTok{y <-}\StringTok{ }\KeywordTok{r2_beta}\NormalTok{(rbeta, }\DataTypeTok{ncp1 =} \NormalTok{ncp1, }\DataTypeTok{d =} \NormalTok{d, }\DataTypeTok{n =} \FloatTok{1e4}\NormalTok{, ...)}
  \KeywordTok{mode}\NormalTok{(y)}
\NormalTok{\}}
\NormalTok{modesr <-}\StringTok{ }\KeywordTok{vapply}\NormalTok{(ss, function(d) }\KeywordTok{r2_beta_mode_r}\NormalTok{(ncp_1, d), }\KeywordTok{numeric}\NormalTok{(}\DecValTok{1}\NormalTok{))}

\CommentTok{# Kollar om det finns ngn skillnad mellan de tvÃ¥ sÃ¤tten }
\KeywordTok{t.test}\NormalTok{(modes, modesr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Welch Two Sample t-test
## 
## data:  modes and modesr
## t = 0.010579, df = 1997.9, p-value = 0.9916
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.005944838  0.006009319
## sample estimates:
## mean of x mean of y 
## 0.3340960 0.3340638
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Mean baserat pÃ¥ simulering}
\NormalTok{r2_beta_mean_r <-}\StringTok{ }\NormalTok{function(ncp1, d, ...) \{}
  \NormalTok{y <-}\StringTok{ }\KeywordTok{r2_beta}\NormalTok{(rbeta, }\DataTypeTok{ncp1 =} \NormalTok{ncp1, }\DataTypeTok{d =} \NormalTok{d, }\DataTypeTok{n =} \FloatTok{1e4}\NormalTok{, ...)}
  \KeywordTok{mean}\NormalTok{(y)}
\NormalTok{\}}
\NormalTok{meansr <-}\StringTok{ }\KeywordTok{vapply}\NormalTok{(ss, function(d) }\KeywordTok{r2_beta_mode_r}\NormalTok{(ncp_1, d), }\KeywordTok{numeric}\NormalTok{(}\DecValTok{1}\NormalTok{))}

\CommentTok{# Kollar om det finns ngn skillnad mellan de tvÃ¥ sÃ¤tten }
\KeywordTok{t.test}\NormalTok{(means, meansr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Welch Two Sample t-test
## 
## data:  means and meansr
## t = 1.3111, df = 1923.7, p-value = 0.19
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.001819645  0.009159424
## sample estimates:
## mean of x mean of y 
## 0.3393171 0.3356472
\end{verbatim}

AlltsÃ¥ ingen skillnad fÃ¶r mode. Skillanden fÃ¶r mean Ã¤r stÃ¶rre men
fortfarande inte signifikant.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(r2s, meansr, }\DataTypeTok{xlim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{8}\NormalTok{), }\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{8}\NormalTok{), }\DataTypeTok{main =} \StringTok{"Comparison to mean"}\NormalTok{)}
  \KeywordTok{abline}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{); }\KeywordTok{points}\NormalTok{(.}\DecValTok{5}\NormalTok{, .}\DecValTok{5}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{5}\NormalTok{, }\DataTypeTok{col =} \StringTok{"red"}\NormalTok{)}
\KeywordTok{qqplot}\NormalTok{(r2s, meansr, }\DataTypeTok{xlim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{8}\NormalTok{), }\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{8}\NormalTok{), }\DataTypeTok{main =} \StringTok{"Comparison to mean"}\NormalTok{)}
  \KeywordTok{abline}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\includegraphics{test_files/figure-latex/unnamed-chunk-8-1.pdf}

Noterar f.Ã¶. att endast (Warren 1971) (samt en artikel som tycks
irrelevant i sammanhanget) refererar till (Hogben 1968). Gissar dÃ¤rfÃ¶r
att man inte har nyttjat dessa resultat i ngn stÃ¶rre utstrÃ¤ckning. Det
finns fler referenser till (Warren 1971). Jag har gÃ¥tt igenom dem och
lagt till i lÃ¤slistan.

Hade kanske vart intressant att t ex ocksÃ¥ jÃ¤mfÃ¶ra med
normalfÃ¶rdelning fÃ¶r att se vilken fÃ¶rdelning av dessa som Ã¤r bÃ¤st
och i sÃ¥ fall hur stor skillnaden kan vara.

\subsection{\texorpdfstring{LÃ¤sning av
({\textbf{???}})}{LÃ¤sning av (???)}}\label{lasning-av-fitdistrplus}

UtgÃ¥r frÃ¥n ML-skattningar. Kan skatta bÃ¥de fÃ¶rdelning och dess
parametrar. Kan ocksÃ¥ baseras pÃ¥ ``maximum goodness-of-fit''.

\texttt{descdist}-funktionen medger ocksÃ¥ att berÃ¤kningar kan ta
hÃ¤nsyn till bias eller inte. TyvÃ¤rr tycke det inte mÃ¶jligt att
inkludera ickecentraliseringsparametern fÃ¶r skattning utan bara
shape-paramterarna. Har fÃ¶rsÃ¶kt studera koden i paketet men finnser
dÃ¤r ingen klar fÃ¶rklaring till varfÃ¶r. Kan det vara ngn skillnad som
finns inbyggd i sjÃ¤lva betafunktionerna? Samtliga Beta-funktioner
nyttjar intern C-kod men jag kan se att man gÃ¶r tydlig skillnad pÃ¥
just \texttt{ncp}-parametern (dock baserat pÃ¥ om den Ã¤r missing och
inte 0, vilket faktiskt Ã¤r default \ldots{} fÃ¶rstÃ¥r inte riktigt!?)

GÃ¥r app skapa enskilda plottar av \texttt{fitdist}-objekt mha
\texttt{denscomp}, \texttt{cdfcomp}, \texttt{qqcomp}och \texttt{ppcomp}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"fitdistrplus"}\NormalTok{)}
\NormalTok{ss <-}\StringTok{ }\KeywordTok{sim_data}\NormalTok{(}\DataTypeTok{r2 =} \NormalTok{.}\DecValTok{5}\NormalTok{, }\DataTypeTok{p =} \DecValTok{1}\NormalTok{) %>%}\StringTok{ }
\StringTok{  }\KeywordTok{subsamples}\NormalTok{(}\DataTypeTok{n.max =} \DecValTok{500}\NormalTok{, }\DataTypeTok{N =} \DecValTok{1000}\NormalTok{)}
\NormalTok{m <-}\StringTok{ }\KeywordTok{metrics}\NormalTok{(ss, }\DataTypeTok{n.sample =} \KeywordTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{200}\NormalTok{, }\DecValTok{300}\NormalTok{, }\DecValTok{400}\NormalTok{, }\DecValTok{500}\NormalTok{))}
\NormalTok{R2 <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(m$Rsquared)}

\CommentTok{# Tycks hÃ¤r som att vi har en betafÃ¶rdelningt fÃ¶r n upp till ca 30}
\CommentTok{# Dock fÃ¶r n = 200 tycks vi kunna anvÃ¤nda gammafÃ¶rdelning fÃ¶r approximation}
\CommentTok{# FrÃ¥n kanske n = 200 tycks normalapproximation kunna fungera bra. }
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{)); }\KeywordTok{lapply}\NormalTok{(R2, descdist, }\DataTypeTok{boot =} \DecValTok{1000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_files/figure-latex/unnamed-chunk-9-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Jag gÃ¶r en stÃ¶rre plot fÃ¶r just n = 200 fÃ¶r att kolla lite nÃ¤rmare pÃ¥ just detta}
\CommentTok{# Ser hÃ¤r att en gammafÃ¶rdelning verkar kunna passa rÃ¤tt bra.}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)); }\KeywordTok{descdist}\NormalTok{(R2[, }\DecValTok{6}\NormalTok{], }\DataTypeTok{boot =} \DecValTok{10000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_files/figure-latex/unnamed-chunk-9-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Ser hÃ¤r att en normalfÃ¶rdelning verkar kunna passa rÃ¤tt bra vid n = 300}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)); }\KeywordTok{descdist}\NormalTok{(R2[, }\DecValTok{7}\NormalTok{], }\DataTypeTok{boot =} \DecValTok{10000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_files/figure-latex/unnamed-chunk-9-3.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Vill testa att anpassa en betafÃ¶rdelning}
\CommentTok{# Tydligen estimeras bara shape1 och shape2, inte ncp (vilket gÃ¶r att resultatet inte blir jÃ¤ttebra)}

\KeywordTok{lapply}\NormalTok{(R2, function(x) \{}
  \NormalTok{fit <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(x, }\StringTok{"beta"}\NormalTok{)}
  \KeywordTok{plotdist}\NormalTok{(x, }\StringTok{"beta"}\NormalTok{, }\DataTypeTok{para =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{shape1 =} \NormalTok{fit$estimate[}\DecValTok{1}\NormalTok{], }\DataTypeTok{shape2 =} \NormalTok{fit$estimate[}\DecValTok{2}\NormalTok{]))}
\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_files/figure-latex/unnamed-chunk-9-4.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-9-5.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-9-6.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-9-7.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-9-8.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-9-9.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-9-10.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-9-11.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-9-12.pdf}

Vid fÃ¶rsta anblick tycks det hÃ¤r som att den vanliga betafÃ¶rdelningen
trots allt kanske kan passa nÃ¥gorlunda? (Dock inte fÃ¶r alltfÃ¶r smÃ¥
n!)

\begin{itemize}
\tightlist
\item
  Finns det ngn systematik i hur shape1 och shape2 skattas utifrÃ¥n n?
  Hade vart jÃ¤ttenitressant i sÃ¥ fall!
\item
  Kan vi anvÃ¤nda dessa betafÃ¶rdelningar och jÃ¤mfÃ¶ra mot den
  ickecentrala betafÃ¶rdelning pss som ovan?
\end{itemize}

\section{2016-03-02}\label{section-2}

FortsÃ¤tter leka lite med paketet \texttt{fitdistrplus}

\subsection{Testar att modifera beta-funktionerna fÃ¶r att ocksÃ¥ skatta
ncp
(misslyckas)}\label{testar-att-modifera-beta-funktionerna-far-att-ocksa-skatta-ncp-misslyckas}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pbeta <-}\StringTok{ }\NormalTok{function(q, shape1, shape2, }\DataTypeTok{ncp =} \DecValTok{0}\NormalTok{, }\DataTypeTok{lower.tail =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{log.p =} \OtherTok{FALSE}\NormalTok{) }
  \KeywordTok{.Call}\NormalTok{(C_pnbeta, q, shape1, shape2, ncp, lower.tail, log.p)}
\NormalTok{dbeta <-}\StringTok{ }\NormalTok{function(x, shape1, shape2, }\DataTypeTok{ncp =} \DecValTok{0}\NormalTok{, }\DataTypeTok{log =} \OtherTok{FALSE}\NormalTok{)}
  \KeywordTok{.Call}\NormalTok{(C_dnbeta, x, shape1, shape2, ncp, log)}
\NormalTok{qbeta <-}\StringTok{ }\NormalTok{function(p, shape1, shape2, }\DataTypeTok{ncp =} \DecValTok{0}\NormalTok{, }\DataTypeTok{lower.tail =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{log.p =} \OtherTok{FALSE}\NormalTok{)}
  \KeywordTok{.Call}\NormalTok{(C_qnbeta, p, shape1, shape2, ncp, lower.tail, log.p)}
\NormalTok{rbeta <-}\StringTok{ }\NormalTok{function(n, shape1, shape2, }\DataTypeTok{ncp =} \DecValTok{0}\NormalTok{) \{}
        \NormalTok{X <-}\StringTok{ }\KeywordTok{rchisq}\NormalTok{(n, }\DecValTok{2} \NormalTok{*}\StringTok{ }\NormalTok{shape1, }\DataTypeTok{ncp =} \NormalTok{ncp)}
        \NormalTok{X/(X +}\StringTok{ }\KeywordTok{rchisq}\NormalTok{(n, }\DecValTok{2} \NormalTok{*}\StringTok{ }\NormalTok{shape2))}
    \NormalTok{\}}
\KeywordTok{fitdist}\NormalTok{(R2[, }\DecValTok{1}\NormalTok{], }\StringTok{"beta"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Fitting of the distribution ' beta ' by maximum likelihood 
## Parameters:
##        estimate Std. Error
## shape1 1.823046 0.07720639
## shape2 1.881074 0.07998226
\end{verbatim}

Detta upprepades ocksÃ¥ med alla tillgÃ¤ngliga val av method men utan at
lyckas.

\subsection{JÃ¤mfÃ¶r resultat fÃ¶r olika
fÃ¶rdelningar}\label{jamfar-resultat-far-olika-fardelningar}

Vi har sett ovan att beta, gamma och normalfÃ¶rdelning kan funka fÃ¶r
olika stickprovsstorlekar. Vi kan undersÃ¶ka detta.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{))}
\NormalTok{plot.legend <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"beta"}\NormalTok{, }\StringTok{"gamma"}\NormalTok{, }\StringTok{"normal"}\NormalTok{)}
\NormalTok{fitdists <-}\StringTok{ }\NormalTok{function(x, }\DataTypeTok{distr =} \KeywordTok{c}\NormalTok{(}\StringTok{"beta"}\NormalTok{, }\StringTok{"gamma"}\NormalTok{, }\StringTok{"norm"}\NormalTok{)) }
  \KeywordTok{lapply}\NormalTok{(distr, function(d) }\KeywordTok{fitdist}\NormalTok{(x, d))}

\NormalTok{denscomps <-}\StringTok{ }\NormalTok{function(m, }\DataTypeTok{distr =} \KeywordTok{c}\NormalTok{(}\StringTok{"beta"}\NormalTok{, }\StringTok{"gamma"}\NormalTok{, }\StringTok{"norm"}\NormalTok{), ...) \{}
  \NormalTok{R2 <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(m$Rsquared)}
  \KeywordTok{lapply}\NormalTok{(R2, function(r2) \{}
    \KeywordTok{denscomp}\NormalTok{(}\KeywordTok{fitdists}\NormalTok{(r2, }\DataTypeTok{distr =} \NormalTok{distr), ...)}
    \KeywordTok{abline}\NormalTok{(}\DataTypeTok{v =} \KeywordTok{attr}\NormalTok{(m, }\StringTok{"real_Rsquared"}\NormalTok{), }\DataTypeTok{col =} \StringTok{"blue"}\NormalTok{)}
  \NormalTok{\})}
\NormalTok{\}}
\KeywordTok{denscomps}\NormalTok{(m, }\DataTypeTok{legendtext =} \NormalTok{plot.legend)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_files/figure-latex/unnamed-chunk-11-1.pdf}

\begin{verbatim}
## $`10`
## NULL
## 
## $`20`
## NULL
## 
## $`30`
## NULL
## 
## $`50`
## NULL
## 
## $`100`
## NULL
## 
## $`200`
## NULL
## 
## $`300`
## NULL
## 
## $`400`
## NULL
## 
## $`500`
## NULL
\end{verbatim}

KÃ¤ns som att vi efter detta ganska klart kan fÃ¶rkasta
gammafÃ¶rdelningen som lÃ¤mpli kandidat men kanske att den Ã¤ndÃ¥ skulle
passa bÃ¤ttre fÃ¶r mindre \(\rho\) (dÃ¥ den ju har en pos eskevhet).

\textbf{OBS!} Denna chunk sparas fÃ¶r att kunna hÃ¤rleda vad som gjort
men ej visat sig fruktsamt. Koden ska inte behÃ¶va anropas etc pÃ¥ nytt!

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{distplots <-}\StringTok{ }\NormalTok{function(}\DataTypeTok{r2 =} \NormalTok{.}\DecValTok{2}\NormalTok{, }\DataTypeTok{p =} \DecValTok{1}\NormalTok{) \{}
  \NormalTok{ss <-}\StringTok{ }\KeywordTok{sim_data}\NormalTok{(}\DataTypeTok{r2 =} \NormalTok{r2, }\DataTypeTok{p =} \NormalTok{p) %>%}\StringTok{ }
\StringTok{    }\KeywordTok{subsamples}\NormalTok{(}\DataTypeTok{n.max =} \DecValTok{500}\NormalTok{, }\DataTypeTok{N =} \DecValTok{1000}\NormalTok{)}
  \NormalTok{m <-}\StringTok{ }\KeywordTok{metrics}\NormalTok{(ss, }\DataTypeTok{n.sample =} \KeywordTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{200}\NormalTok{, }\DecValTok{300}\NormalTok{, }\DecValTok{400}\NormalTok{, }\DecValTok{500}\NormalTok{))}
  \KeywordTok{denscomps}\NormalTok{(m, }\DataTypeTok{legendtext =} \NormalTok{plot.legend)}
\NormalTok{\}}

\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{))}
\KeywordTok{lapply}\NormalTok{(}\KeywordTok{c}\NormalTok{(.}\DecValTok{2}\NormalTok{, .}\DecValTok{5}\NormalTok{, .}\DecValTok{8}\NormalTok{), distplots)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_files/figure-latex/unnamed-chunk-12-1.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-12-2.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-12-3.pdf} Finner
att gamma de facto passar bÃ¤ttre fÃ¶r just smÃ¥ \(\rho\) men att beta
Ã¤ndÃ¥ Ã¤r ett bÃ¤ttre alternativ. Ser dÃ¤rmed ingen anledning att
fortsÃ¤tta studera gamma-fÃ¶rdelningen i detta sammanhang. Ser ocksÃ¥
att resultaten Ã¤r ganska samstÃ¤mmiga fÃ¶r \(n> 200\) sÃ¥ begrÃ¤nsar
mig dit men tar istÃ¤llet in lite fler mellanliggande vÃ¤rden som kanske
kan vara intressanta. VÃ¤rjer mig nu heller inte fÃ¶r att ta Ã¤nnu fler
\(\rho\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{distplots <-}\StringTok{ }\NormalTok{function(}\DataTypeTok{r2 =} \NormalTok{.}\DecValTok{2}\NormalTok{, }\DataTypeTok{p =} \DecValTok{1}\NormalTok{, }\DataTypeTok{distr =} \KeywordTok{c}\NormalTok{(}\StringTok{"beta"}\NormalTok{, }\StringTok{"norm"}\NormalTok{), }
                      \DataTypeTok{n.sample =} \KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{75}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{150}\NormalTok{, }\DecValTok{200}\NormalTok{), ...) \{}
  \NormalTok{ss <-}\StringTok{ }\KeywordTok{sim_data}\NormalTok{(}\DataTypeTok{r2 =} \NormalTok{r2, }\DataTypeTok{p =} \NormalTok{p) %>%}\StringTok{ }
\StringTok{    }\KeywordTok{subsamples}\NormalTok{(}\DataTypeTok{n.max =} \KeywordTok{max}\NormalTok{(n.sample), }\DataTypeTok{N =} \DecValTok{1000}\NormalTok{)}
  \NormalTok{m <-}\StringTok{ }\KeywordTok{metrics}\NormalTok{(ss, }\DataTypeTok{n.sample =} \NormalTok{n.sample)}
  \KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\KeywordTok{floor}\NormalTok{(}\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{length}\NormalTok{(n.sample))), }\KeywordTok{ceiling}\NormalTok{(}\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{length}\NormalTok{(n.sample)))))}
  \KeywordTok{denscomps}\NormalTok{(m, }\DataTypeTok{distr =} \NormalTok{distr, }\DataTypeTok{legendtext =} \NormalTok{distr, }\DataTypeTok{main =} \KeywordTok{paste}\NormalTok{(}\StringTok{"rho = "}\NormalTok{, r2, }\StringTok{". p = "}\NormalTok{, p), ...)}
\NormalTok{\}}

\KeywordTok{lapply}\NormalTok{(}\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{9}\NormalTok{, .}\DecValTok{1}\NormalTok{), distplots)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_files/figure-latex/unnamed-chunk-13-1.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-13-2.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-13-3.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-13-4.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-13-5.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-13-6.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-13-7.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-13-8.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-13-9.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-13-10.pdf}

\textbf{Slutsatser:} Vi kan se att beta-fÃ¶rdelningen ger alldeles fÃ¶r
hÃ¶ga skattningar fÃ¶r vÃ¤ldigt smÃ¥ \(\rho\). Problemet Ã¤r alltsÃ¥
inte att det inte blir nÃ¥gra data men att y-axeln dras ut sÃ¥ mkt att
dessa vÃ¤rden inte syns. NÃ¤r \(\rho\) blir stÃ¶rre blir det lÃ¤ttare
att anpassa fÃ¶rdelning Ã¤vendÃ¥ \(n\) mindre. I nÃ¥gra fall kan
normalfÃ¶rdelningen tyckas t o m bÃ¤ttre Ã¤n beta men gissar att detta
trots allt beror pÃ¥ slumpen. NÃ¤r \(\rho\) dock Ã¶kar till att ligga
nÃ¤rmare \(.5\) bÃ¶rjar fÃ¶rdelningen krumbukta sig ganska ordentligt
Ã¶r Ã¶kande \(n<20\). FÃ¶r \(\rho > .6\) tycks det som att
betafÃ¶rdelningen inte riktigt nÃ¥r upp till hÃ¶gsta vÃ¤rdena i
histogrammet. I detta avseende Ã¤r t o m normalfÃ¶rdelningen bÃ¤ttre.
FÃ¶r \(n> 20\) tycks det dessutom som att beta och normal Ã¤r
approximativt likvÃ¤rdiga. Att hÃ¶gsta stapeln ligger Ã¶ver
betafÃ¶rdelningens mode tycks f.Ã¶. hÃ¥lla i sig fÃ¶r vÃ¤xande \(\rho\)
men effekten avtar med mindre \(n\) fÃ¶r Ã¶kade \(\rho\).

\subsection{FÃ¶r Ã¶kande p}\label{far-akande-p}

Vi vill ocksÃ¥ undersÃ¶ka effekten om vi Ã¶kar antalet oberoende
variabler (p)

\subsubsection{p = 2}\label{p-2}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{lapply}\NormalTok{(}\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{9}\NormalTok{, .}\DecValTok{1}\NormalTok{), distplots, }\DataTypeTok{p =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_files/figure-latex/unnamed-chunk-14-1.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-14-2.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-14-3.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-14-4.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-14-5.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-14-6.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-14-7.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-14-8.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-14-9.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-14-10.pdf}

\subsubsection{p = 3}\label{p-3}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{lapply}\NormalTok{(}\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{9}\NormalTok{, .}\DecValTok{1}\NormalTok{), distplots, }\DataTypeTok{p =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_files/figure-latex/unnamed-chunk-15-1.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-15-2.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-15-3.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-15-4.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-15-5.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-15-6.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-15-7.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-15-8.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-15-9.pdf}
\includegraphics{test_files/figure-latex/unnamed-chunk-15-10.pdf}

\subsubsection{\texorpdfstring{\(p > 3\)}{p \textgreater{} 3}}\label{p-3-1}

NÃ¤r jag provar med stÃ¶rre p fÃ¥r jag konvergensproblem av
\texttt{optim} enl kod 100 pÃ¥ \texttt{?mle}

Sedan Ã¤r det fÃ¶rstÃ¥s viktigt att ocksÃ¥ titta pÃ¥ CDF, QQ och
PP-plottar dÃ¤r QQ illustrerar lack of fit i svansarna och PP i mitten
({\textbf{???}}). Funktionen \texttt{gofstat} kan ocksÃ¥ anvÃ¤ndas fÃ¶r
att fÃ¥ fram en del teoretiska vÃ¤rden som beskriver goodness of fit. I
sÃ¥ fall kan Anderson-Darling statistican vara bra att undersÃ¶ka dÃ¥
den ger vikt till svansarna. Men finns ocksÃ¥ brister. AIC/BIC kan
rekommenderas vid jÃ¤mfÃ¶relse mellan olika fÃ¶rdelningar.

GÃ¥r ocksÃ¥ lÃ¤tt att fÃ¥ konfidensnitervall fÃ¶r paremeterskattningarna
gm bootstrap via funktionne \texttt{bootdist}.

\subsection{\texorpdfstring{LÃ¤sning av
({\textbf{???}})}{LÃ¤sning av (???)}}\label{lasning-av-distrmod}

VÃ¤ldigt lÃ¤tt att t ex plotta en ickecenrtal betafÃ¶rdelning (hÃ¤r med
defaultparametervÃ¤rden).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(distrMod)}
\NormalTok{B <-}\StringTok{ }\KeywordTok{Beta}\NormalTok{()}
\KeywordTok{plot}\NormalTok{(B)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_files/figure-latex/unnamed-chunk-16-1.pdf}

Skattningar sker via \texttt{MCEstimator} (\texttt{MLEstimator}) men
fÃ¶r detta krÃ¤vs en familj att skatta emot. Det fnins en
\texttt{BetaFamily} men den omfattar inte ickecentral beta. Man kan
defeniera en egen familj via \texttt{L2ParamFamily} (se t ex kÃ¤llkoden
fÃ¶r \texttt{BetaFamily}). Dock Ã¤r jag osÃ¤ker pÃ¥ argumentet
\texttt{L2deriv.fct}. Det ska bestÃ¥ av tre funktioner i en lista dÃ¤r
varje funktion av \(x\) beskriver vÃ¤nsterledet i
\(\frac{\partial \alpha}{\partial f} \ln{\hat{l}} = 0\) dÃ¤r \(f\) Ã¤r
fÃ¶rdelningsfunktionen fÃ¶r beta, dvs ett uttryck fÃ¶r att finna maximum
likelihood-estimatet (digamma = derivatan av gammafÃ¶rdelningen). Dessa
funktioner gÃ¥r att berÃ¤kna analytiskt fÃ¶r betafÃ¶rdelningen men gÃ¥r
det fÃ¶r ickecentral beta? FÃ¶rdelningsfunktionen finns hÃ¤r:
\url{https://en.wikipedia.org/wiki/Noncentral_beta_distribution\#Probability_density_function}

Om vi sedan deriverar Betafunktionen fnins det uttrycket hÃ¤r:
\url{https://en.wikipedia.org/wiki/Beta_function\#Derivatives}

\section{2016-03-03}\label{section-3}

Jobbar hemifrÃ¥n med att lÃ¤sa.

\subsection{LÃ¤sning av (Kowalski 1972)}\label{lasning-av-kowalski1972}

Behandlar sampling frÃ¥n icke bivariat normalfÃ¶rdelning.JÃ¤mfÃ¶rr (ej
\(r^2\)) mot normalfÃ¶rdelning.UndersÃ¶ker tidigare konflikter om
robusthet hos \(r\). NÃ¤mner att Fisher redan 1915 utvecklade en exakt
formel fÃ¶r samplingsfÃ¶rdelningen av \(r\) dÃ¥ underliggande data
bivariat normalfÃ¶rdelad.

\[f_N(r|\rho) = \frac{2^{N-3}(1-\rho^2)^{(N-1)/2}(1-r^2)^{(N-4)/2}}{\Gamma(N-2)\pi} \sum_{j = 0}^\infty \frac{(2r)^j}{j!}\Gamma^2[(N+j-1)/2]\]

och dÃ¥ \(\rho = 0\):

\[f_N(r|\rho=0) = \frac{\Gamma[(N-1)/2]}{\Gamma[(N-2)/2]\sqrt{\pi}}(1-r^2)^{(N-4)/2} \]

Tycker dok inte det Ã¤r sÃ¥ tydligt att just (Fisher and Fisher 1915)
anger detta men Ã¤r fÃ¶rmodligen bara lost in notation. I vilket fall
som helst alltsÃ¥ oÃ¤ndlig serie och bara fÃ¶r \(r\), ej \(r^2\). Detta
anges ocksÃ¥ av (Hotelling 1953) men det Ã¤r fÃ¶rst i (Hogben 1968) som
resultatet utvecklas fÃ¶r \(r^2\).

Redan Ã¥ren efter (Fisher and Fisher 1915) gjordes en del studierav
fÃ¶rdelningens robusthet. Ibland baserat pÃ¥ teoretiska formler, ibland
pÃ¥ monte carlo-simuleringar. Ã\ldots{}sikterna gick brett isÃ¤r
huruvida fÃ¶rdelningen var robust eller inte. Detta gÃ¥s igenom med
referernser till olika artiklar i avs 2.1. Observera dock att
jÃ¤mfÃ¶relserna endast avser normalfÃ¶rdelning och ej beta. HÃ¤r finns
alltsÃ¥ kanske fortfarande ett utrymme fÃ¶r att jÃ¤mfÃ¶ra mot vanlig
betafÃ¶rdelning. De flesata dock Ã¶verrens om att svÃ¥righeter uppstÃ¥r
frÃ¤mst dÃ¥ \(|\rho| \lesssim 1\). LÃ¤ttast att finna likheterna dÃ¥
\(\rho \approx 0\).

\textbf{AlltsÃ¥:} de flesta Ã¤r Ã¶verrens om att \(r|\rho=0 \sim N\) men
\$r\textbar{}\rho \neq 0 \nsim N \$. Skulle motsv att
\(r^2|\rho=0 \sim \Chi^2_1\)

FÃ¶rklarar att tidiagre resultat som pekat pÃ¥icke robust
fÃ¶rdelningsantagande i sjÃ¤lva verket kan hÃ¤rledas till att man pÃ¥
den tiden saknade hjkÃ¤lpmedel (datorer) fÃ¶r att kunna berÃ¤kna saker
ordentligt. Nu vill han kolla pÃ¥ detta igen med hjÃ¤lp av modern
teknik. I slutet av 1960-talet undersÃ¶ktes ocksÃ¥ approximationer mha
fouriertransformer. HÃ¤r skapas en sÃ¥dan formel (men den Ã¤r
fortfarande ganska icke intuitiv) fÃ¶r att kunna anvÃ¤ndas vid fortsatta
studier.

Resultatet visar att fÃ¶rdelningen alls icke var sÃ¥ robust som man
tidigare antagit. UNdersÃ¶kning gÃ¶rs med flera olika typer av data
frÃ¥n olika fÃ¶rdelningar (mixade normal, exponential etc). MotsÃ¤ger
ocksÃ¥ t ex tidigarte studie som pÃ¥stÃ¥tt sig funnit robust resultat i
intervallet \(\rho \em [.1, .8], n = 5\). KOnstateras ocksÃ¥ att andra
korrelationsmÃ¥tt sÃ¥som kendals och Spearman Ã¤r att fÃ¶redra i en del
fall (vi har ju fÃ¶rstÃ¥s inte motsvarande situation hos oss dÃ¥ vi
betraktar \(r^2\)).

\subsection{LÃ¤snig av (Barrett 1974)}\label{lasnig-av-barrett1974}

Handlar nu Ã¤ntligen om \(r^2\). VÃ¤ldigt kort artikel, 2 sidor med
endast 4 referenser (innehÃ¥ller f.Ã¶. en annons \ldots{} fÃ¶r en
statistikkurs).

Kritiserar att man tar \(R^2 = r^2\) som enda mÃ¥tt fÃ¶r regressionens
giltighet. FÃ¶reslÃ¥r att man ocksÃ¥ anvÃ¤nder konfidensintervall etc
fÃ¶r att undersÃ¶ka goodnes-of-fit etc. Menar att mÃ¥nga Ã¶vertolkar
nyttan av koefficienten och ger den mening som den egentligen saknar.

Menar att en linjÃ¤r regressionsmodell med brant lutning kan ha hÃ¶gt
\(r^2\) utan att man fÃ¶r den sakens skullfÃ¥r bÃ¤ttre prediktioner Ã¤n
fÃ¶r en modell med lÃ¤gre \(r^2\) men mindre brant lutning. StÃ¤ller
ocksÃ¥ upp en tabell Ã¶ver hur \(r^2\) Ã¶kar med Ã¶kad lutning (rotation
av data). GÃ¥r mot 1 dÃ¥ vinkeln pÃ¥ slop gÃ¥r mot 90 grader.

InnehÃ¥ller inget som Ã¤r av direkt relevansjust nu men en lite
intressant side note.

\subsection{LÃ¤sning av (Claudy 1978)}\label{lasning-av-claudy1978}

Behandlar studie av empiriskt utvecklad ekvation fÃ¶r multiple
regression coefficient. NÃ¤mnar avvÃ¤gningsproblem med stickprovsstorlek
i fÃ¶rhÃ¥llande till validering fÃ¶r cross-validation. Beskriver att
regression utvecklades fÃ¶r designade experiment med fixt X och att det
inte riktigt stÃ¤mmer med fÃ¶rutsÃ¤ttningarna inomsurvey eller
psykologisk forskning. I dessa fall mÃ¥ste man rÃ¤kna med sampling och
measurement errors Ã¤ven pÃ¥ de oberoende parametrarna. NÃ¤mner att det
ocksÃ¥ finns metoder att hantera dÃ¥ \(x\) Ã¤r stokastisk variabel men
att formler etc fÃ¶r detta Ã¤r sÃ¥ komplexa att de sÃ¤llan anvÃ¤nds
(kallas Random-X model istf Fixed-X model).

\textbf{OBS!!!} HÃ¤r stÃ¥r att:

\begin{quote}
Application of estimatiojn procedures based on the Fixed -X model to
Random-X data causes an over-fitting of the regression surface to the
available data. The regression surface is fitted to the sample specific
error varianceas well as to the systematic trends of the population.
This over-fitting, or error-fitting, results in the sample multiple
correlation coefficient overestimating the actual population multiple
correlation.
\end{quote}

Detta Ã¤r kanske vad vi ser dÃ¥ vi Ã¶verskattar \(r^2\) med \(p> 1\)?
Dvs fÃ¶rklaring till att vÃ¥r bias inte bara Ã¤r additiv utan dessutom
Ã¶kar lite mer Ã¤n sÃ¥ fÃ¶r varje Ã¶kning av \(p\)?

Detta Ã¤r bakgrunden till adjusted \(R^2\) enl (Larson 1931) (tillskrevs
B Smith), sedan modifierad till dagens form av (Wherry 1931). Men som ju
senare visade sig vara biased och ist leda till underskattning av
\(\rho\) (nÃ¤mner ocksÃ¥ nya versionen av (Olkin and Pratt 1958) etc).
Ã„ven senare approximationer av dessa diskuteras.

NÃ¤mner ocksÃ¥ att cross-validation tenderar underskatta \(\rho\) (se
{[}5{]}).

NÃ¤mner speciella formler fÃ¶r skattning av \(\rho\) vid korsvalidering!
(Man hade Ã¤nnu inte 10-fold etc men Ã¥tm 2-fold). Intressant! Finns
fÃ¶r bÃ¥de fixed och random x.

Visar fig 1 som pÃ¥minner om vÃ¥ra liknande resultat med jÃ¤mfÃ¶relse av
\(\rho, r\) dÃ¤r \(r\) Ã¶verskattar \(\rho\) men nÃ¤rmar sig
assymptotiskt. Dock med crass-validerings-\(r/\rho\) istf adjusted
\(R^2\) som vi hade.

GÃ¶r en simuleringsstudie som tycks vÃ¤ldigt lik vÃ¥r. AnvÃ¤nder olika
typer av fÃ¶rdelningar, interkorrelationsmatris och antal oberoende
variabler (max 5). Dock populationer med 500 fall istf 1e6. Endast 400
samples totalt frÃ¥n ursprungspopulationen, 100 av varje storlek 20, 40,
80 och 160.

Man antar hÃ¤r att 500 Ã¤r tillrÃ¤ckligt fÃ¶r att approximera
oÃ¤ndligheten (var det Fisher eller t om Pearson som tyckte man skulle
ha Ã¥tm 1000 i stickprovet.)?

\textbf{OBS!} HÃ¤r tillÃ¥ter man alltsÃ¥ en variation av
correlationsmatrisen som kan vara intressant och som kanske kan
underskÃ¶as Ã¤ven hos oss?

Resultat visar att korsvalidering ger bÃ¤st resultat. PÃ¥ den tiden
ifrÃ¥gasatte man dock om det var vÃ¤rt den extra tiden och kraften att
tillÃ¤pa korsvalidering. Ett argument som antagligen Ã¤r mindre relevant
idag.

FÃ¶reslÃ¥r (pÃ¥ empirisk grund) en kompromiss som dels ska var lika
unbias som vid korsvalidering men som inte ska krÃ¤va just
korsvalidering dÃ¥ det anses fÃ¶r krÃ¥ngligt. Formeln funkar bra fÃ¶r
stÃ¶rre stickprov men fÃ¶r upp till 20 Ã¤r Ã¤ndÂ¨korsvalidering bÃ¤ttre.

\[\hat{\rho} = \sqrt{1 - \frac{(N-4)(1-r^2)}{N-n-1}(1 + \frac{2(1-r^2)}{N-n+1})}\]

Dock saknas en parentes i formeln men jag tror det Ã¤r sÃ¥ den ska se
ut.

FÃ¶reslÃ¥r att denna formel anvÃ¤nds vid tillrÃ¤cklig stickprovsstorlek
men kan inte erbjuda ngn teoretisk motivering.

PÃ¥minner docj att (Skidmore and Thompson 2011) ej fann denna formel
Ã¶verlÃ¤gsen utan istÃ¤llet hÃ¥ller fast vid (Olkin and Pratt 1958).
PÃ¥minner f.Ã¶. om intressant uppstÃ¤llning i tabell 3 (Olkin and Pratt
1958) som ocksÃ¥ jÃ¤mfÃ¶r fÃ¶r \(r^2=.01\).

Noteras f.Ã¶. att studien sponsrats av NASA avseende datorresurser :-)

\subsection{\texorpdfstring{LÃ¤sning av
({\textbf{???}})}{LÃ¤sning av (???)}}\label{lasning-av-konisho1978}

FÃ¶reslÃ¥r approximativ fÃ¶rdelning fÃ¶r sample correlation coefficient,
dvs \(r\), inte \(r^2\) (frÃ¥n Hiroshima!).

Avser endast dÃ¥ grunddata bivariat normalfÃ¶rdelad. SÃ¤gs vara bÃ¤ttre
Ã¤n tidigare fÃ¶rsÃ¶k och ganska enkel. Tycker dok Ã¤ndÃ¥ att den ges av
en hyfsat komplex formel. Kan heller inte bevisas teoretiskt att detta
Ã¤r den bÃ¤sta lÃ¶sningen. Involverar Fishers z-transform.

\subsection{LÃ¤sning av en blogg}\label{lasning-av-en-blogg}

Enligt Dave Giles gÃ¤ller att
\url{http://davegiles.blogspot.se/2013/10/more-on-distribution-of-r-squared.html}

\[r^2|\rho = 0 \sim Beta(\frac{k-1}{2}, \frac{n-k}{2})\] dÃ¤r \$k = \$
vÃ¥rt \(p+1\) och \$n = \$ stickprovsstorlek. NÃ¤mner dock bara i
fÃ¶rbigÃ¥ende (som svar pÃ¥ en kommentar att det blir ickecentral beta
dÃ¥ \(\rho \neq 0\)).

Samme Gilers noterar ocksÃ¥
(\url{http://davegiles.blogspot.se/2013/05/good-old-r-squared.html})
\textgreater{} Whenever the bias of R2 is noticeable, its standard
deviation is several times larger than this bias.

\begin{quote}
First, the coefficient of determination is a sample statistic, and as
such it is a random variable with a sampling distribution. Second, the
form of this sampling distribution depends on the X data, and on the
unknown beta and sigma parameters. Third, this sampling distribution
gets distorted if the regression errors are autocorrelated. Finally,
even if we have a very large sample of data, R2 converges in probability
to a value less than one, regardless of the data values or the values of
the unknown parameters.
\end{quote}

\subsection{LÃ¤sning av (Alam 1979)}\label{lasning-av-alam1979}

Denna artikel finns publicerad men kostar dÃ¥ pengar. Den version jag
lÃ¤st tycks vara digitalisering av mikrofilm och originalet skrivet pÃ¥
skrivmaskin.DÃ¤rmed lite svÃ¥rlÃ¤st.

Behandlar \(r\), ej \(r^2\). Begr till bivariat normalfÃ¶rdelning.

Ã„rligt talat en inte sÃ¥ vÃ¤rst angenÃ¤m lÃ¤sning. Teoretiskt fÃ¶rslag
som jsg tvivlar pÃ¥ blivit sÃ¥ uppmÃ¤rksammat.

\subsection{LÃ¤sning av (Huberty and Mourad
1980)}\label{lasning-av-huberty1980}

Behandlar just multiple correlation och \(R^2\)! Dock frÃ¤mst en
jÃ¤mfÃ¶relse mellan sedan tidigare kÃ¤nda formler sÃ¥som
({\textbf{???}}) och (Olkin and Pratt 1958).

NÃ¤mner att fÃ¶r \(\rho = 0\) gÃ¤ller:

\[E[R^2] = \frac{p}{N-1}\]

KÃ¤ns som att denn artikel gÃ¶r mkt av det vi vill gÃ¶ra. VÃ¤lskriven
och pedagogisk. TillÃ¤mpas pÃ¥ verklig fata (ej simulerat).

Man skiljer pÃ¥ modeller fÃ¶r att fÃ¶rstÃ¥ samband eller fÃ¶r predektion
pÃ¥ sÃ¤tt som jag inte riktigt sett tidigare.

\textbf{OBS!} HÃ¤r noteras ocksÃ¥ (vilket jag sjÃ¤lv tidiagre ocksÃ¥
nÃ¤mnt) att ({\textbf{???}}) fÃ¶rst anvÃ¤nde \(N\) dÃ¤r han senare
anvÃ¤nde \(N - 1\).

NÃ¤mner jack-knife som alternativ till adjusted \(R^2\).

AnvÃ¤nder lÃ¥nade data set med betyg och olika elevdata som predektorer.
TvÃ¥ dataset varav fÃ¶rsta med \(p = 9\).

Stickprovsstorlek pÃ¥ 50.

SKriver att om \(N/p>20\) sÃ¥ kan ``shrinkage'' negligeras.

Endast tio upprepade fÃ¶rsÃ¶k per stickprovsstorlek.

Tra olika \(\rho^2\), samtliga mellan 0,3 och 0,4.

FrÃ¥n dessa stickprov mÃ¤ttes:

\begin{itemize}
\tightlist
\item
  precision via standardavvikelse av avvikelse mellan \(\rho^2\) och
  \(\hat{rho}\).
\item
  accuracy via dess medelvÃ¤rde.
\end{itemize}

Slutsatser: ({\textbf{???}}) och (Olkin and Pratt 1958) hyfsat lika
resultat. Mer bias fÃ¶r hÃ¶gre \(p\). Biasen var vÃ¤ldigt liten (notera
n = 50) och saknade signifikant avvikelse frÃ¥n 0. Alla adjusted \(R^2\)
kan bedÃ¶mas likvÃ¤rdiga.

Noterar att adjusted \(R^2\) kan bli negativt men att detta motsvarar en
riktigt dÃ¥lig passning (vÃ¤ldigt litet \(R^2\) och \(n\)).

\subsection{\texorpdfstring{LÃ¤sning av
({\textbf{???}})}{LÃ¤sning av (???)}}\label{lasning-av-wood1986}

Kritiserar generaliseringen att kvadrera \(\rho\) berÃ¤knat fÃ¶r
korrelation fÃ¶r att fÃ¥ ett vÃ¤rde som motsvarar \(R^2\) vid
regression. SÃ¤ger alltsÃ¥ inte emot att coefficient of determination
berÃ¤knas sÃ¥ men menar att man inte kan alltid kan tolka \(\rho^2\) som
sÃ¥dan koefficient ifall det inte var syftet frÃ¥n bÃ¶rjan. Detta
eftersom korrelation baseras pÃ¥ stokastiskt X medan regression baseras
pÃ¥ fixt X.HÃ¤nvisar ocksÃ¥ til (Warren 1971) ang detta.

Wood kallar dessa felaktiga resonemang fÃ¶r ``vulgarised knowledge''.

\begin{quote}
``bias (for correlation) and precision (for regression) tend to work
against each other. One should determine which of correlation or
regression is appropriate to the problem and select the sampling method
accordingly
\end{quote}

Hela artikeln kÃ¤nns polemisk och lite ``von oben'' men kommunicerar Ã¥
andra sidan ganska klart sin stÃ¥ndpunkt.

Argumenterar ocksÃ¥ fÃ¶r att korrelationsvÃ¤rden inte ska tillmÃ¤tas
alltfÃ¶r stort vÃ¤rde rakt av utan att man mÃ¥ste undersÃ¶ka hela
fÃ¶rdelningen grafiskt. Detta kan fÃ¶rstÃ¥s vara svÃ¥rt vid publicering
men det bÃ¶r Ã¥tm ske i explorativt syfte.

\subsection{LÃ¤sning av (Hawkins 1989)}\label{lasning-av-hawkins1989}

VÃ¤ldigt kort. Handlar om Fisher z. Teoretisk, mÃ¥nga formler. Kopierar
abstract:

\begin{quote}
A simple derivation of the asymptotic distribution of Fish- er's Z
statistic for general bivariate parent distributions F is obtained using
U-statistic theory. This method easily reveals that the asymptotic
variance of Z generally depends on the correlation \(\rho\) and on
certain moments of F. It also reveals the particular structure of F that
makes the asymptotic variance of Z independent of \(\rho\), and shows
that there are many distributions F with this property. The bivariate
normal is only one such F.
\end{quote}

Refererar till (Gayen 1951) som visade samma sak men dÃ¥ endast fÃ¶r
Edgeworth-fÃ¶rdelningar. Detta bevis gÃ¤ller alla fÃ¶rdelningar med
Ã¤ndligt fjÃ¤rdemoment (kurtosis) men bara approximativt dÃ¥
\(n \rightarrow \infty\)

\subsection{LÃ¤sning av (Nagelkerke
1991)}\label{lasning-av-nagelkerke1991}

Kort. 2 sidor och fgÃ¥ referenser. Teoretisk.

Tar hÃ¤r fÃ¶r givet att coefficient of determination = multiple
correlation coefficient.

Beskriver generalisering som kan anvÃ¤ndas utanfÃ¶r linjÃ¤r regression.
Baseras pÃ¥ maximum likelihood. Har egentligen introducerats redan
tidigare av bl a Cox et al. Beskriver mÃ¥nga fina egenskaper men ocksÃ¥
ett problem som dock gÃ¥r att Ã¶verkomma.

\section*{Referenser}\label{referenser}
\addcontentsline{toc}{section}{Referenser}

\hypertarget{refs}{}
\hypertarget{ref-Alam1979}{}
Alam, Kursheed. 1979. ``Distribution of sample correlation
coefficients.'' \emph{Naval Research Logistics Quarterl}.

\hypertarget{ref-Barrett1974}{}
Barrett, James P. 1974. ``The Coefficient of Determination---Some
Limitations.'' \emph{The American Statistician} 28 (1): 19--20.
doi:\href{https://doi.org/10.1080/00031305.1974.10479056}{10.1080/00031305.1974.10479056}.

\hypertarget{ref-Claudy1978}{}
Claudy, J. G. 1978. ``Multiple Regression and Validity Estimation in One
Sample.'' \emph{Applied Psychological Measurement} 2 (4): 595--607.
doi:\href{https://doi.org/10.1177/014662167800200414}{10.1177/014662167800200414}.

\hypertarget{ref-Cowden1952}{}
Cowden, Dudley J. 1952. ``The Multiple-Partial Correlation
Coefficient.'' \emph{Journal of the American Statistical Association} 47
(259): 442--56.
doi:\href{https://doi.org/10.1080/01621459.1952.10501183}{10.1080/01621459.1952.10501183}.

\hypertarget{ref-Fisher1915}{}
Fisher, R.a., and R.a. Fisher. 1915. ``Frequency distribution of the
values of the correlation coefficient in samples from an indefinitely
large population.'' \emph{Biometrika} 10 (4): 507--21.
doi:\href{https://doi.org/10.2307/2331838}{10.2307/2331838}.

\hypertarget{ref-Gayen1951}{}
Gayen, A. K. 1951. ``The Frequency Distribution of the Product-Moment
Correlation Coefficient in Random Samples of Any Size Drawn from
Non-Normal Universes.'' \emph{Biometrika} 38 (1/2): 219--47.

\hypertarget{ref-Hawkins1989}{}
Hawkins, D. 1989. ``Using U statistics to derive the asymptotic
distribution of Fisher's Z statistic.'' \emph{American Statistician} 43
(4): 235--37.
doi:\href{https://doi.org/10.2307/2685369}{10.2307/2685369}.

\hypertarget{ref-Hogben1968}{}
Hogben, David. 1968. ``The distribution of the sample correlation
coefficient with one variable fixed.'' \emph{Journal of Research of the
National Bureau of Standards, Section B: Mathematical Sciences} 72B (1):
33.
doi:\href{https://doi.org/10.6028/jres.072B.007}{10.6028/jres.072B.007}.

\hypertarget{ref-Hotelling1953}{}
Hotelling, Harold. 1953. ``New Light on the Correlation Coefficient and
its Transforms Author(s): Harold Hotelling.'' \emph{Journal of the Royal
Statistical Society. Series B (Methodological),} 15 (2): 296--193--232.

\hypertarget{ref-Huberty1980}{}
Huberty, Carl J, and Salah A Mourad. 1980. ``Estimation in multiple
correlation/prediction.'' \emph{Educational and Psychological
Measurement} 40: 101--12.

\hypertarget{ref-Kowalski1972}{}
Kowalski, Charles J. 1972. ``On the Effects of Non-Normality on the
Distribution of the Sample Product-Moment Correlation Coefficient.''
\emph{Journal of the Royal Statistical Society} 21 (1): 1--12.
doi:\href{https://doi.org/10.2307/2346598}{10.2307/2346598}.

\hypertarget{ref-Kymn1968}{}
Kymn, Kern O . 1968. ``The Distribution of the Sample Correlation
Coefficient Under the Null Hypothesis.'' \emph{Econometrica} 36 (1):
187--89.

\hypertarget{ref-Larson1931}{}
Larson, S C. 1931. ``The shrinkage of the coefficient of multiple
correlation.'' \emph{Journal of Educational Psychology} 22 (1): 45--55.
doi:\href{https://doi.org/10.1037/h0072400}{10.1037/h0072400}.

\hypertarget{ref-Nagelkerke1991}{}
Nagelkerke, N. J D. 1991. ``A note on a general definition of the
coefficient of determination.'' \emph{Biometrika} 78 (3): 691--92.
doi:\href{https://doi.org/10.1093/biomet/78.3.691}{10.1093/biomet/78.3.691}.

\hypertarget{ref-Nemes2009}{}
Nemes, Szilard, Junmei Miao Jonasson, Anna Genell, and Gunnar Steineck.
2009. ``Bias in odds ratios by logistic regression modelling and sample
size.'' \emph{BMC Medical Research Methodology} 9: 56.
doi:\href{https://doi.org/10.1186/1471-2288-9-56}{10.1186/1471-2288-9-56}.

\hypertarget{ref-Olkin1958}{}
Olkin, Ingram, and J.W. Pratt. 1958. ``Unbiased estimation of certain
correlation coefficients.'' \emph{The Annals of Mathematical Statistics}
29 (1): 201--11.
doi:\href{https://doi.org/10.2307/2237306}{10.2307/2237306}.

\hypertarget{ref-Park1964}{}
Park, John H Jr. 1964. ``Variations of the Non-central t and Beta
Distributions.'' \emph{The Annals of Mathematical Statistics} 35 (4):
1583--93.

\hypertarget{ref-Pearson1895}{}
Pearson, Karl. 1895. ``Note on Regression and Inheritance in the Case of
Two Parents.'' \emph{Proceedings of the Royal Society of London
(1854-1905)} 58: 240--42.
doi:\href{https://doi.org/10.1098/rspl.1895.0041}{10.1098/rspl.1895.0041}.

\hypertarget{ref-Pearson1896}{}
---------. 1896. ``Mathematical Contributions to the Theory of
Evolution. III. Regression, Heredity, and Panmixia.''
\emph{Philosophical Transactions of the Royal Society A} 187.

\hypertarget{ref-Skidmore2011}{}
Skidmore, Susan Troncoso, and Bruce Thompson. 2011. ``Choosing the Best
Correction Formula for the Pearson r 2 Effect Size.'' \emph{The Journal
of Experimental Education} 79 (3): 257--78.
doi:\href{https://doi.org/10.1080/00220973.2010.484437}{10.1080/00220973.2010.484437}.

\hypertarget{ref-Warren1971}{}
Warren, W. G. 1971. ``Correlation or Regression: Bias or Precision.''
\emph{Applied Statistics} 20 (2): 148.
doi:\href{https://doi.org/10.2307/2346463}{10.2307/2346463}.

\hypertarget{ref-Wherry1931}{}
Wherry, R. 1931. ``A new formula for predicting the shrinkage of the
coefficient of multiple correlation.'' \emph{The Annals of Mathematical
Statistics} 2 (4): 440--57.
\url{http://www.jstor.org/stable/2957681$/backslash$npapers2://publication/uuid/F3D4916B-BB98-4094-A459-DF4387AC9610}.

\end{document}
