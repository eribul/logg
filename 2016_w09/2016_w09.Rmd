---
title: "Arbetslogg 2016 vecka 9"
author: "Erik Bulow"
date: "29 februari 2016"
output: 
  pdf_document: 
    fig_height: 7
    fig_width: 7
    keep_tex: yes
    number_sections: yes
    toc: yes
bibliography: ../article1.bib
---


# Förberedelser

```{r echo=FALSE, results='hide'}
suppressPackageStartupMessages(library(dplyr))
library(r2samplesize)
knitr::opts_chunk$set(autodep = TRUE, cache = TRUE)
```
```{r}
# Try it out!
memory.limit(50000)
options(samplemetric.log = TRUE)
set.seed(123)
```


# 2016-02-29

Har udner helgen roat mig med at läsa Sigma och bl a den först kända publicerade artikeln om statistik (från 1600-talet). Intressant kuriositet även om det kanske inte har ngn direkt nytta för jobbet just nu.



## Läsning av [@Pearson1895]

(Läste egentligen denna förra veckan.)

Är lite okklar över referenserna. Tror jag hittade referens som pekade på denna artikel som upphov till korrelationskoefficienten (men hittade också annan referens som ist pekade på [@Pearson1895]). Men den nämns i denna arikel ocså och då denna publicerades före den senare så bör det kanske vaar sant. Men här hänvisas också till Galtons formel så egentligen var det inte helt nytt.

Väldigt kort note som egentligen är del av längre paper som inte han färdigställas pga hälsoproblem.



## Läsning av [@Pearson1896]

Sägs vara källan till korrelationskoefficienten. Framkommer dock att konceptet de facto var känt sedan tidigare. Texten utgår från ganska praktiska exempel med heriditet och sexuel reproduktion etc. Ger äran till Bravais och delvis också till Edgeworth, Galton och Weldon.
Innehåller rtedan här en del teori om fördelning baserat på $\chi^2$ etc. Refereras också till $r$ som Galtons funktion (Galton myntade f.ö. även uttrycket regression). Redan då användes normalapproximation. Texten utgår från ganska teoretiska beräkningar men konstateras att den praktiska formeln för att beräkna $r$ är den Bravais föreslagit men utan att ha visat att det verkligen var den bästa formeln. Se s 265 för formeln. 

Konstaterar redan här att:

> Thus we may say that with sufficient accuracy for most cases the standard deviation of a coefficient of correlation is:

> $$\frac{1 - r^2}{\sqrt{n(1 + r^2)}}$$

> or its probable error = 
$$.674506 \frac{1- r^2}{\sqrt{n(1 +r^2)}}$$
[...]
It will be sufficient therefore, for most practical purposes to assume that the probable error of a coefficient of correlation 

$$= .674506 \frac{1 - r^2}{\sqrt{n(1+r^2)}}$$.

Här talas dock också om ganska stora stickprovsstorlekar såsom $n = 1000$. Skriver om ett dataset med 200 samlpes att:

> The number is not sufficientlty great to make the probable error of quite small enough dimensions in several cases, and so allow of definite conclusions. 

(F.ö. ett sample baserat på övre medelklass så kudne därav inte heller nyttjas för generella slutsatser om populationen. Återkmmer även på s 273 till att vi inte kan anta normalfördelning här. Refererar till att normalfördelning kunde antas vid studie av 900 kraniemätningar utförda vid tidigare studie.)

f.ö. undersöks i artikeln relationen mellan föräldrars längd och kön på avkomma. Konstateras (med viss reservation) att t ex längre fäder tenderar få döttrar i ngt högre utsträckning än söner. Dock svårare att se mönster för mödrar. Ser även att korrelation för längder tycks ärvas starkare på fädernet än mödernet även sett över flera generationsled. 


F.ö. intressant att artikeln blandar både teori men också ganska utförliga praktiska beskrivningar. Känns både konrekt och väl underbyggt på samma gång.

Gör inget fördelningsantagande för data vi samplar ifrån. 

Noterar f.ö. att han nämner korrelation och standradavvikelse etc men gör inga referenser til kovarians. 

Behandlar också fallet med tre grupper att jämföra och därmed tre parvisa korrelationer. 

Görs också studier av korraltion av ansiktsbehåring, dvs ärftligheten av detta. Även referenser till att färgblindhet ärvs från morfar till dotterson. 

Behandlar även fall med 4 korrelationer. Denna teknik tycks användas där man idag istället skulle använda regression i modern mening. 

Efter ett par generationer kommer familjära särdrag suddas ut varpå släkten alltmer liknar populationen. Detta gäller även vid selektive breeding. Skulle behövas experiment för att empiriskt utröna effekten av selektive breeding etc! :-)



## Läsning av [@Nemes2009]

Tipsad av denna av SN. Inte för att ämnet i sig är direkt relevant men då upplägget på själva artikeln kan antas liknande nu föreliggande förutsättningar. Konstaterar bias för mindre stickprovsstorlekar. Även här ses approximatil normalfördelning av oddskvoten för stora n.
Finns även här en skev bakomliggande fördelning. Även här är problemen kända teoretiskt men inte bland praktiker. Fnins också förslag på bias-korrected versioner. 

Ger ingen rekommendation om sample size men konstaterar att andra föreslagit minst 100 och helst mer än 500. Diskret data kräver större smaple, liksom starkt korrelerade data.

Biasen påverkar på så sätt att små stickprovsstorlekar påvisar större effekt än för större samples. 

Beskriver risken med detta att man publicerar material som inte stämmer med verkligheten. Även problem vid metastudier då man inte tnker på detta då flera studier jämförs.

På det hela taget mkt intressant och viktigt!



## Läsning av [@Cowden1952]

Handlar om multipel-partial correlation coefficient.
Förklarar att "multiple correlation coefficient" är vår koefficient där observerad vs predicted values korreleras och där pred beror på en eller flera variabler. Artikeln inför också "multiple-partial correleation coefficient", en justerad correlation mellan utfall samt två eller fler oberoende variabler. 

Innehåller mkt härledningar och teori. Känns dock inte helt relevant i sammanhangert så lämnar den ej färdigläst.



## Läsning av [@Kymn1968]

Det är känt sedan tidigare att:

$$ F = r^2\frac{n-2}{1-r^2} \sim F_{1, n-2} $$

samt 

$$ t = r\frac{\sqrt{n-2}}{1-r^2} \sim t_{n-2} $$

Denna artikel visar nu att 

$$ S = \frac{1+r}{1-r} \sim F_{n-2, n-2} $$

Fördelen med denna är att fördelningen är symmetrisk samt ev att $S$ inte beror på $n$ (men det gör ju å andra sidan $F$ så jag vet inte riktigt varför det skulle vara så stor skillnad).

**OBS!** Bygger på att $x, y$ är bivariat normalfördelade och oberoende $\rho = 0$ så nyttan av detta kanske är begränsad?

Noterar här att enligt [@Hotelling1953] krävs dock inte bivariat normalfördelning just då $\rho = 0$




## Undersöker icke-central betafördelning

Tar en avstickare och försöker skapa funktion för icke-central betafördelning. Noterar att $x$ ska antas fix och har därmed ingen känd fördelning

```{r}


#' Parameters for the noncentral beta distribution of R2
#'
#' @param ncp1 first part of the con centrality parameter 
#' as given by \code{\link{ncp1}}
#' @param x object of class \code{\link{sim_data}}
#' @return List with "shape1", "shape2" and "npc" parameters 
#' as used for corresponding arguments in the \code{\link{Beta}}
#' functions.
#' @export
r2_beta_param <- function(ncp1, x) {
  stopifnot(ncol(x) == 2)
  list(
    shape1 = .5,
    shape2 = (nrow(x) - 2) / 2,
    ncp = ncp1 * sum((x$X1 - mean(x$X1)) ^ 2)
  )
} 


#' Calculate the first half of the non centrally parameter of R2
#'
#' Calculate the non observal dependent part of the 
#' centrality parameter used as argument 
#' "ncp" in the \code{\link{Beta}} family of functions
#'
#' @param x object of class \code{\link{sim_data}}
#' @return numeric vector of length one
#' @export
#' @examples
#' ncp1 <- ncp1(sim_data())
ncp1 <- function(x) {
  stopifnot(ncol(x) == 2)
  fit    <- lm(Y ~ ., data = x)
  beta   <- fit$coefficients[2]
  sigma2 <- var(fit$residuals)
 (beta ^ 2) / (2 * sigma2)
}

#' The R2 disrtibution based on the Beta distribution
#'
#' @param fun one of the functions listed at \code{\link{Beta}}
#' @param ncp1 value given by \code{\link{ncp1}}
#' @param d object of class \code{\link{sim_data}} with columns 
#' \code{Y} and \code{X1}.
#' @param ... arguments passed to \code{fun} 
#' @return Value returned by call to \code{fun}
r2_beta <- function(fun, ncp1, d, ...) {
  do.call(fun, c(r2_beta_param(ncp1, d), list(...)))
}


d <- sim_data(r2 = .5, p = 1)
dsample <- dplyr::sample_n(d, 50)
ncp_1 <- ncp1(d)
# r2_beta(dbeta, ncp_1, d = dsample, x = seq(0.01,1,.01))
par(mfrow = c(1, 2))
curve(r2_beta(dbeta, ncp_1, d = dsample, x = x))
abline(v = .5)
curve(r2_beta(pbeta, ncp_1, d = dsample, q = x))
abline(v = .5)
```


Är detta enligt förväntan? Ser ut som att vi underskattar $r^2$ väldigt grovt ...?


# 2016-03-01

Fortsätter titta på simuleringarna ovan. Gör om några ggr och finner att det nog bara var slump att det blve så biased.
Beöhver simulera flera ggr men lite osäker på hur. Det bli rju olika fördelningar varje gång. Ska jag beräkna medelvärden för `npc` eller på ngt sätt för hela fördelningen?

```{r}
par(mfrow = c(1,1))
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x)); abline(v = .5)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)
curve(r2_beta(dbeta, ncp_1, d = dplyr::sample_n(d, 30), x = x), add = TRUE)

```


## Diskussion med SN
Är ovanligt och lite konstigt att fördelningen i detta fall beror på observerade data. 
För t ex t- och F-fördelning finns ju ett beroende av frihetsgrad (stickprovsstorlek) men inte av själva datapunkterna. 
Att ha ett sådant beroende känns lite märkligt då man på ngt sätt rättfärdigar ett observerat resultat genom teorier byggda på samma observerade resultat, vilket känns som ett cirkelresonameng. Å andra sidan är väl just detta anledningen till att $x$ enl teorin heller inte är att betrakta som en slumpvariabel utan som fix.

Slutsatser:


1. Det går inte att finna en enda teoretisk fördelning (facit) då den alltid kommer att bero på slumpen.
2. Vad vi kan göra är att koncentrera oss på t ex olika moment av fördelningen. Vi kan t ex ta ett stickprov och för detta beräkna både den semiteoretiska fördelning detta ger upphov till, samt skatta R2 direkt. Vi jämför sedan skattningen mot värdet givet av väntevärdet givet av fördelningen. Vi upprepar många ggr och plottar dessa värden med qqplot för att undersöka ev bias. 
2. Kan också vara av värde att undersöka ifall det finns metod att skatta betafördelningens parametrar utifrån data på ngt mer generellt sätt. 

Vi försöker göra enl (2) ovan.
Dock behöver vi för detta jämföra skattningen inte mot mean utan mot mode för att få det korrekt. Dock svårt att finna ngn formel för mode av icke cenrtal betafördelning. Finns funktion `modeest::betaMode` men den funktionen hanterar ändå inte detta. 

Enl [@Park1964] krävs numerisk approximation för skattning av mode för icke-central beta. Formel presenteras i (3.2) men bygger på antaganden (såsom att $r^2 \rightarrow 1$), vilket gör det hela ointeressant. Ett alternativ blir då att skatta ett numeriskt värde (såsom vi också gjort vid tidigare simulering), vilket vi lätt kan göra om vi antar att fördelningen är unimodal, vilket vi här kan. Observera dock att vi här inte ska basera mode-skattningen på vårt slumpmässiga urval utan på fördelningens värde för $\forall x: x \in [0,1]$ för relevant fördelning. Kanske skulle man också kunna undersöka metoder för att finna mode via paketet `modehunt`. Jag har ännu inte fördjupat mig i det och vet således inte ifall det skulle ge annat resultat än min egen mode-funktion.


```{r}

r2_beta_mode <- function(ncp1, d, ...) {
  x <- seq(0.001, 1, .001)
  y <- r2_beta(dbeta, ncp1 = ncp1, d = d, x = x, ...)
  x[y == max(y)]
}

# Prepare data sets
d <- sim_data(r2 = .5, p = 1)
ss <- subsamples(d, n.max = 30, N = 1000)
ncp_1 <- ncp1(d)

# Calculate "theoretical modes" and "observed r2"
modes <- vapply(ss, function(d) r2_beta_mode(ncp_1, d), numeric(1))
r2s <- metrics(ss, n.sample = 30)$Rsquared

# Plot and compare
par(mfrow = c(1, 2))
plot(r2s, modes, xlim = c(0, .8), ylim = c(0, .6))
abline(0, 1)
qqplot(r2s, modes)
```
Vi ser här att vår teoretiska mode underskattr vårt observerade värde. Är det trots allt så att vi inte bör jämföra mot mode utan mot mean? Det finns visserilgen en teoretisk formel för att beräkna mean av icke cenrtal betafördelning men den behöver i sin tur en confluent hypergeometric function. Det finns dock fler versioner av detta och de som finns implementerade i R tycks inte motsvara den här aktuella. Vi får därför skatta mean pss som vi tidigare skattade mode. Å andra sidan har vi också en formel för väntevärdet av $r^2$ för selektive samlpnig given av [@Warren1971] avs 2.2. Även här refereras till en confluent hypergeometric function men då denna har endast tre variabler är sannolikheten större att denna är samma som t ex `hypergeo::genhypergeo`. Dock krävs fler parametrar som jag inble blir riktigt klok på (tycks smo att man ska slumpa $n$ värden från varje punkt tagen med selective samplnig men jag får inte riktigt ihop det).


```{r}
r2_beta_mean <- function(ncp1, d, ...) {
  x <- seq(0.001, 1, .001)
  y <- r2_beta(dbeta, ncp1 = ncp1, d = d, x = x, ...)
  sum((y / sum(y)) * x)
}

# Calculate "theoretical modes" and "observed r2"
means <- vapply(ss, function(d) r2_beta_mean(ncp_1, d), numeric(1))

# Plot and compare
par(mfrow = c(2, 2))
plot(r2s, means, xlim = c(0, .8), ylim = c(0, .8), main = "Comparison to mean")
  abline(0, 1); points(.5, .5, lwd = 5, col = "red")
qqplot(r2s, means, xlim = c(0, .8), ylim = c(0, .8), main = "Comparison to mean")
  abline(0, 1) 
plot(r2s, modes, xlim = c(0, .8), ylim = c(0, .8), main = "Comparison to mdoe")
  abline(0, 1); points(.5, .5, lwd = 5, col = "red")
qqplot(r2s, modes, xlim = c(0, .8), ylim = c(0, .8), main = "Comparison to mode")
  abline(0, 1) 
```

Röda prickar markerar $\rho^2$ men observera här att värden på y-axeln (mean resp mode) inte syftar till att approximera det teoretiska värdet utan värdet för $r^2$, vilket vi vet underskattar $\rho^2$ för varje enskild observation. Om $r^2$ skulle följa den ickecenrtala betafördelningen skulle vi dock se observationer centrerade kring linjen i graferna. Det gör vi inte. Vad vi ser är istället att den teoretiska fördelningen tycks underskatta observerade $r^2$ systematiskt. Vi ser endast marginell skillnad mellan mode och mean (tyder väl på att den teoretiska fördelningen är mindre skev än den verkliga?) men möjligt att mode är lite bättre (vilket stämmer med teorin).

**Slutsats:** Den icke centrala betafördelningen enligt [@Hogben1968] underskattar $r^2$.

Men för att sammanfatta så avviker jag också från teorin enl:

1. Mitt x slumpas (ej fixt). Vet dock inte riktigt hur detta bör påverka resultatet.
2. Mode och mean från fördelningen är skattade på kanske inte allra bästa sätt? Ett alternativ är kanske att nyttja fördelningen till att slumpa fram en massa värden och sedan beräkna mode och mean av det. Tycker dock inte det borde bli ngn skillnad ... men kan ju förstås testa ...

```{r}

mode <- function(d) {
  z <- density(d)
  z$x[z$y == max(z$y)]
}

# Mode baserat på simulering
r2_beta_mode_r <- function(ncp1, d, ...) {
  y <- r2_beta(rbeta, ncp1 = ncp1, d = d, n = 1e4, ...)
  mode(y)
}
modesr <- vapply(ss, function(d) r2_beta_mode_r(ncp_1, d), numeric(1))

# Kollar om det finns ngn skillnad mellan de två sätten 
t.test(modes, modesr)

# Mean baserat på simulering
r2_beta_mean_r <- function(ncp1, d, ...) {
  y <- r2_beta(rbeta, ncp1 = ncp1, d = d, n = 1e4, ...)
  mean(y)
}
meansr <- vapply(ss, function(d) r2_beta_mode_r(ncp_1, d), numeric(1))

# Kollar om det finns ngn skillnad mellan de två sätten 
t.test(means, meansr)
```

Alltså ingen skillnad för mode. Skillanden för mean är större men fortfarande inte signifikant.

```{r}
par(mfrow = c(1, 2))
plot(r2s, meansr, xlim = c(0, .8), ylim = c(0, .8), main = "Comparison to mean")
  abline(0, 1); points(.5, .5, lwd = 5, col = "red")
qqplot(r2s, meansr, xlim = c(0, .8), ylim = c(0, .8), main = "Comparison to mean")
  abline(0, 1) 
```

Noterar f.ö. att endast [@Warren1971] (samt en artikel som tycks irrelevant i sammanhanget) refererar till [@Hogben1968]. Gissar därför att man inte har nyttjat dessa resultat i ngn större utsträckning. Det finns fler referenser till [@Warren1971]. Jag har gått igenom dem och lagt till i läslistan.

Hade kanske vart intressant att t ex också jämföra med normalfördelning för att se vilken fördelning av dessa som är bäst och i så fall hur stor skillnaden kan vara. 



## Läsning av [@fitdistrplus]

Utgår från ML-skattningar. Kan skatta både fördelning och dess parametrar. Kan också baseras på "maximum goodness-of-fit".

`descdist`-funktionen medger också att beräkningar kan ta hänsyn till bias eller inte.
Tyvärr tycke det inte möjligt att inkludera ickecentraliseringsparametern för skattning utan bara shape-paramterarna. Har försökt studera koden i paketet men finnser där ingen klar förklaring till varför. Kan det vara ngn skillnad som finns inbyggd i själva betafunktionerna?
Samtliga Beta-funktioner nyttjar intern C-kod men jag kan se att man gör tydlig skillnad på just `ncp`-parametern (dock baserat på om den är missing och inte 0, vilket faktiskt är default ... förstår inte riktigt!?)

Går app skapa enskilda plottar av `fitdist`-objekt mha `denscomp`, `cdfcomp`, `qqcomp`och `ppcomp`.


```{r, results="hide"}
library("fitdistrplus")
ss <- sim_data(r2 = .5, p = 1) %>% 
  subsamples(n.max = 500, N = 1000)
m <- metrics(ss, n.sample = c(10, 20, 30, 50, 100, 200, 300, 400, 500))
R2 <- as.data.frame(m$Rsquared)

# Tycks här som att vi har en betafördelningt för n upp till ca 30
# Dock för n = 200 tycks vi kunna använda gammafördelning för approximation
# Från kanske n = 200 tycks normalapproximation kunna fungera bra. 
par(mfrow = c(3, 3)); lapply(R2, descdist, boot = 1000)

# Jag gör en större plot för just n = 200 för att kolla lite närmare på just detta
# Ser här att en gammafördelning verkar kunna passa rätt bra.
par(mfrow = c(1, 1)); descdist(R2[, 6], boot = 10000)

# Ser här att en normalfördelning verkar kunna passa rätt bra vid n = 300
par(mfrow = c(1, 1)); descdist(R2[, 7], boot = 10000)

# Vill testa att anpassa en betafördelning
# Tydligen estimeras bara shape1 och shape2, inte ncp (vilket gör att resultatet inte blir jättebra)

lapply(R2, function(x) {
  fit <- fitdist(x, "beta")
  plotdist(x, "beta", para = list(shape1 = fit$estimate[1], shape2 = fit$estimate[2]))
})
```

Vid första anblick tycks det här som att den vanliga betafördelningen trots allt kanske kan passa någorlunda? (Dock inte för alltför små n!) 

* Finns det ngn systematik i hur shape1 och shape2 skattas utifrån n? Hade vart jättenitressant i så fall!
* Kan vi använda dessa betafördelningar och jämföra mot den ickecentrala betafördelning pss som ovan?



# 2016-03-02

Fortsätter leka lite med paketet `fitdistrplus`

## Testar att modifera beta-funktionerna för att också skatta ncp (misslyckas)

```{r}
pbeta <- function(q, shape1, shape2, ncp = 0, lower.tail = TRUE, log.p = FALSE) 
  .Call(C_pnbeta, q, shape1, shape2, ncp, lower.tail, log.p)
dbeta <- function(x, shape1, shape2, ncp = 0, log = FALSE)
  .Call(C_dnbeta, x, shape1, shape2, ncp, log)
qbeta <- function(p, shape1, shape2, ncp = 0, lower.tail = TRUE, log.p = FALSE)
  .Call(C_qnbeta, p, shape1, shape2, ncp, lower.tail, log.p)
rbeta <- function(n, shape1, shape2, ncp = 0) {
        X <- rchisq(n, 2 * shape1, ncp = ncp)
        X/(X + rchisq(n, 2 * shape2))
    }
fitdist(R2[, 1], "beta")

```

Detta upprepades också med alla tillgängliga val av method men utan at lyckas. 



## Jämför resultat för olika fördelningar

Vi har sett ovan att beta, gamma och normalfördelning kan funka för olika stickprovsstorlekar. 
Vi kan undersöka detta.


```{r}
par(mfrow = c(3, 3))
plot.legend <- c("beta", "gamma", "normal")
fitdists <- function(x, distr = c("beta", "gamma", "norm")) 
  lapply(distr, function(d) fitdist(x, d))

denscomps <- function(m, distr = c("beta", "gamma", "norm"), ...) {
  R2 <- as.data.frame(m$Rsquared)
  lapply(R2, function(r2) {
    denscomp(fitdists(r2, distr = distr), ...)
    abline(v = attr(m, "real_Rsquared"), col = "blue")
  })
}
denscomps(m, legendtext = plot.legend)
```
Käns som att vi efter detta ganska klart kan förkasta gammafördelningen som lämpli kandidat men kanske att den ändå skulle passa bättre för mindre $\rho$ (då den ju har en pos eskevhet).


**OBS!** Denna chunk sparas för att kunna härleda vad som gjort men ej visat sig fruktsamt. 
Koden ska inte behöva anropas etc på nytt!
```{r, results = "hide"}
distplots <- function(r2 = .2, p = 1) {
  ss <- sim_data(r2 = r2, p = p) %>% 
    subsamples(n.max = 500, N = 1000)
  m <- metrics(ss, n.sample = c(10, 20, 30, 50, 100, 200, 300, 400, 500))
  denscomps(m, legendtext = plot.legend)
}

par(mfrow = c(3, 3))
lapply(c(.2, .5, .8), distplots)
```
Finner att gamma de facto passar bättre för just små $\rho$ men att beta ändå är ett bättre alternativ. Ser därmed ingen anledning att fortsätta studera gamma-fördelningen i detta sammanhang.
Ser också att resultaten är ganska samstämmiga för $n> 200$ så begränsar mig dit men tar istället in lite fler mellanliggande värden som kanske kan vara intressanta. Värjer mig nu heller inte för att ta ännu fler $\rho$.

```{r, results = "hide"}
distplots <- function(r2 = .2, p = 1, distr = c("beta", "norm"), 
                      n.sample = c(5, 10, 20, 30, 50, 75, 100, 150, 200), ...) {
  ss <- sim_data(r2 = r2, p = p) %>% 
    subsamples(n.max = max(n.sample), N = 1000)
  m <- metrics(ss, n.sample = n.sample)
  par(mfrow = c(floor(sqrt(length(n.sample))), ceiling(sqrt(length(n.sample)))))
  denscomps(m, distr = distr, legendtext = distr, main = paste("rho = ", r2, ". p = ", p), ...)
}

lapply(seq(0, .9, .1), distplots)
```

**Slutsatser:** Vi kan se att beta-fördelningen ger alldeles för höga skattningar för väldigt små $\rho$. Problemet är alltså inte att det inte blir några data men att y-axeln dras ut så mkt att dessa värden inte syns. När $\rho$ blir större blir det lättare att anpassa fördelning ävendå $n$ mindre. I några fall kan normalfördelningen tyckas t o m bättre än beta men gissar att detta trots allt beror på slumpen. 
När $\rho$ dock ökar till att ligga närmare $.5$ börjar fördelningen krumbukta sig ganska ordentligt ör ökande $n<20$. För $\rho > .6$ tycks det som att betafördelningen inte riktigt når upp till högsta värdena i histogrammet. I detta avseende är t o m normalfördelningen bättre. För $n> 20$ tycks det dessutom som att beta och normal är approximativt likvärdiga. Att högsta stapeln ligger över betafördelningens mode tycks f.ö. hålla i sig för växande $\rho$ men effekten avtar med mindre $n$ för ökade $\rho$.

## För ökande p

Vi vill också undersöka effekten om vi ökar antalet oberoende variabler (p)

### p = 2
```{r, results = "hide"}
lapply(seq(0, .9, .1), distplots, p = 2)
```


### p = 3
```{r, results = "hide"}
lapply(seq(0, .9, .1), distplots, p = 3)
```

### $p > 3$ 

När jag provar med större p får jag konvergensproblem av `optim` enl kod 100 på `?mle`

Sedan är det förstås viktigt att också titta på CDF, QQ och PP-plottar där QQ illustrerar lack of fit i svansarna och PP i mitten [@fitdistrplus]. Funktionen `gofstat` kan också användas för att få fram en del teoretiska värden som beskriver goodness of fit. I så fall kan Anderson-Darling statistican vara bra att undersöka då den ger vikt till svansarna. Men finns också brister. AIC/BIC kan rekommenderas vid jämförelse mellan olika fördelningar. 

Går också lätt att få konfidensnitervall för paremeterskattningarna gm bootstrap via funktionne `bootdist`.


## Läsning av [@distrMod]

Väldigt lätt att t ex plotta en ickecenrtal betafördelning (här med defaultparametervärden).
```{r}
library(distrMod)
B <- Beta()
plot(B)
```

Skattningar sker via `MCEstimator` (`MLEstimator`) men för detta krävs en familj att skatta emot. Det fnins en `BetaFamily` men den omfattar inte ickecentral beta. Man kan defeniera en egen familj via `L2ParamFamily` (se t ex källkoden för `BetaFamily`). Dock är jag osäker på argumentet `L2deriv.fct`. Det ska bestå av tre funktioner i en lista där varje funktion av $x$ beskriver vänsterledet i $\frac{\partial \alpha}{\partial f} \ln{\hat{l}} = 0$ där $f$ är fördelningsfunktionen för beta, dvs ett uttryck för att finna maximum likelihood-estimatet (digamma = derivatan av gammafördelningen). Dessa funktioner går att beräkna analytiskt för betafördelningen men går det för ickecentral beta? 
Fördelningsfunktionen finns här: https://en.wikipedia.org/wiki/Noncentral_beta_distribution#Probability_density_function

Om vi sedan deriverar Betafunktionen fnins det uttrycket här: https://en.wikipedia.org/wiki/Beta_function#Derivatives






# 2016-03-03

Jobbar hemifrån med att läsa. 



## Läsning av [@Kowalski1972]

Behandlar sampling från icke bivariat normalfördelning.Jämförr (ej $r^2$) mot normalfördelning.Undersöker tidigare konflikter om robusthet hos $r$.
Nämner att Fisher redan 1915 utvecklade en exakt formel för samplingsfördelningen av $r$ då underliggande data bivariat normalfördelad. 

$$f_N(r|\rho) = \frac{2^{N-3}(1-\rho^2)^{(N-1)/2}(1-r^2)^{(N-4)/2}}{\Gamma(N-2)\pi} \sum_{j = 0}^\infty \frac{(2r)^j}{j!}\Gamma^2[(N+j-1)/2]$$

och då $\rho = 0$:

$$f_N(r|\rho=0) = \frac{\Gamma[(N-1)/2]}{\Gamma[(N-2)/2]\sqrt{\pi}}(1-r^2)^{(N-4)/2} $$

Tycker dok inte det är så tydligt att just [@Fisher1915] anger detta men är förmodligen bara lost in notation. I vilket fall som helst alltså oändlig serie och bara för $r$, ej $r^2$.
Detta anges också av [@Hotelling1953] men det är först i [@Hogben1968] som resultatet utvecklas för $r^2$.

Redan åren efter [@Fisher1915] gjordes en del studierav fördelningens robusthet. Ibland baserat på teoretiska formler, ibland på monte carlo-simuleringar. Åsikterna gick brett isär huruvida fördelningen var robust eller inte. Detta gås igenom med referernser till olika artiklar i avs 2.1. Observera dock att jämförelserna endast avser normalfördelning och ej beta. Här finns alltså kanske fortfarande ett utrymme för att jämföra mot vanlig betafördelning. De flesata dock överrens om att svårigheter uppstår främst då $|\rho| \lesssim 1$. Lättast att finna likheterna då $\rho \approx 0$.

**Alltså:** de flesta är överrens om att $r|\rho=0 \sim N$ men $r|\rho \neq 0 \nsim N$. Skulle motsv att $r^2|\rho=0 \sim \chi^2_1$

Förklarar att tidiagre resultat som pekat påicke robust fördelningsantagande i själva verket kan härledas till att man på den tiden saknade hjkälpmedel (datorer) för att kunna beräkna saker ordentligt. Nu vill han kolla på detta igen med hjälp av modern teknik. I slutet av 1960-talet undersöktes också approximationer mha fouriertransformer. Här skapas en sådan formel (men den är fortfarande ganska icke intuitiv) för att kunna användas vid fortsatta studier. 

Resultatet visar att fördelningen alls icke var så robust som man tidigare antagit. UNdersökning görs med flera olika typer av data från olika fördelningar (mixade normal, exponential etc).
Motsäger också t ex tidigarte studie som påstått sig funnit robust resultat i intervallet $\rho \in [.1, .8], n = 5$. KOnstateras också att andra korrelationsmått såsom kendals och Spearman är att föredra i en del fall (vi har ju förstås inte motsvarande situation hos oss då vi betraktar $r^2$).




## Läsnig av [@Barrett1974]

Handlar nu äntligen om $r^2$. Väldigt kort artikel, 2 sidor med endast 4 referenser (innehåller f.ö. en annons ... för en statistikkurs).

Kritiserar att man tar $R^2 = r^2$ som enda mått för regressionens giltighet. Föreslår att man också använder konfidensintervall etc för att undersöka goodnes-of-fit etc. Menar att många övertolkar nyttan av koefficienten och ger den mening som den egentligen saknar.

Menar att en linjär regressionsmodell med brant lutning kan ha högt $r^2$ utan att man för den sakens skullfår bättre prediktioner än för en modell med lägre $r^2$ men mindre brant lutning. Ställer också upp en tabell över hur $r^2$ ökar med ökad lutning (rotation av data). Går mot 1 då vinkeln på slop går mot 90 grader. 

Innehåller inget som är av direkt relevansjust nu men en lite intressant side note.



## Läsning av [@Claudy1978]

Behandlar studie av empiriskt utvecklad ekvation för multiple regression coefficient. Nämnar avvägningsproblem med stickprovsstorlek i förhållande till validering för cross-validation. Beskriver att regression utvecklades för designade experiment med fixt X och att det inte riktigt stämmer med förutsättningarna inomsurvey eller psykologisk forskning. I dessa fall måste man räkna med sampling och measurement errors även på de oberoende parametrarna. Nämner att det också finns metoder att hantera då $x$ är stokastisk variabel men att formler etc för detta är så komplexa att de sällan används (kallas Random-X model istf Fixed-X model).

**OBS!!!** Här står att:

> Application of estimatiojn procedures based on the Fixed -X model to Random-X data causes an over-fitting of the regression surface to the available data. The regression surface is fitted to the sample specific error varianceas well as to the systematic trends of the population. This over-fitting, or error-fitting, results in the sample multiple correlation coefficient overestimating the actual population multiple correlation. 

Detta är kanske vad vi ser då vi överskattar $r^2$ med $p> 1$? Dvs förklaring till att vår bias inte bara är additiv utan dessutom ökar lite mer än så för varje ökning av $p$?

Detta är bakgrunden till adjusted $R^2$ enl [@Larson1931] (tillskrevs B Smith), sedan modifierad till dagens form av [@Wherry1931]. Men som ju senare visade sig vara biased och ist leda till underskattning av $\rho$ (nämner också nya versionen av [@Olkin1958] etc). Även senare approximationer av dessa diskuteras. 

Nämner också att cross-validation tenderar underskatta $\rho$ (se [5]).

Nämner speciella formler för skattning av $\rho$ vid korsvalidering! (Man hade ännu inte 10-fold etc men åtm 2-fold). Intressant! Finns för både fixed och random x.

Visar fig 1 som påminner om våra liknande resultat med jämförelse av $\rho, r$ där $r$ överskattar $\rho$ men närmar sig assymptotiskt. Dock med crass-validerings-$r/\rho$ istf adjusted $R^2$ som vi hade. 


Gör en simuleringsstudie som tycks väldigt lik vår. Använder olika typer av fördelningar, interkorrelationsmatris och antal oberoende variabler (max 5). Dock populationer med 500 fall istf 1e6. Endast 400 samples totalt från ursprungspopulationen, 100 av varje storlek 20, 40, 80 och 160.

Man antar här att 500 är tillräckligt för att approximera oändligheten (var det Fisher eller t om Pearson som tyckte man skulle ha åtm 1000 i stickprovet.)?

**OBS!** Här tillåter man alltså en variation av correlationsmatrisen som kan vara intressant och som kanske kan undersköas även hos oss?

Resultat visar att korsvalidering ger bäst resultat. På den tiden ifrågasatte man dock om det var värt den extra tiden och kraften att tilläpa korsvalidering. Ett argument som antagligen är mindre relevant idag. 

Föreslår (på empirisk grund) en kompromiss som dels ska var lika unbias som vid korsvalidering men som inte ska kräva just korsvalidering då det anses för krångligt. Formeln funkar bra för större stickprov men för upp till 20 är änd¨korsvalidering bättre.

$$\hat{\rho} = \sqrt{1 - \frac{(N-4)(1-r^2)}{N-n-1}(1 + \frac{2(1-r^2)}{N-n+1})}$$

Dock saknas en parentes i formeln men jag tror det är så den ska se ut. 

Föreslår att denna formel används vid tillräcklig stickprovsstorlek men kan inte erbjuda ngn teoretisk motivering.

Påminner docj att [@Skidmore2011] ej fann denna formel överlägsen utan istället håller fast vid [@Olkin1958]. Påminner f.ö. om intressant uppställning i tabell 3 [@Olkin1958] som också jämför för $r^2=.01$.

Noteras f.ö. att studien sponsrats av NASA avseende datorresurser :-)




## Läsning av [@Konishi1978]

Föreslår approximativ fördelning för sample correlation coefficient, dvs $r$, inte $r^2$ (från Hiroshima!).

Avser endast då grunddata bivariat normalfördelad. Sägs vara bättre än tidigare försök och ganska enkel. Tycker dok ändå att den ges av en hyfsat komplex formel. Kan heller inte bevisas teoretiskt att detta är den bästa lösningen. Involverar Fishers z-transform.



## Läsning av en blogg

Enligt Dave Giles gäller att
http://davegiles.blogspot.se/2013/10/more-on-distribution-of-r-squared.html

$$r^2|\rho = 0 \sim Beta(\frac{k-1}{2}, \frac{n-k}{2})$$ där $k = $ vårt $p+1$ och $n = $ stickprovsstorlek. Nämner dock bara i förbigående (som svar på en kommentar att det blir ickecentral beta då $\rho \neq 0$).

Samme Gilers noterar också (http://davegiles.blogspot.se/2013/05/good-old-r-squared.html)
> Whenever the bias of R2 is noticeable, its standard deviation is several times larger than this bias.

> First, the coefficient of determination is a sample statistic, and as such it is a random variable with a sampling distribution. Second, the form of this sampling distribution depends on the X data, and on the unknown beta and sigma parameters. Third, this sampling distribution gets distorted if the regression errors are autocorrelated. Finally, even if we have a very large sample of data, R2 converges in probability to a value less than one, regardless of the data values or the values of the unknown parameters.




## Läsning av [@Alam1979]

Denna artikel finns publicerad men kostar då pengar. Den version jag läst tycks vara digitalisering av mikrofilm och originalet skrivet på skrivmaskin.Därmed lite svårläst.

Behandlar $r$, ej $r^2$. Begr till bivariat normalfördelning. 

Ärligt talat en inte så värst angenäm läsning. Teoretiskt förslag som jsg tvivlar på blivit så uppmärksammat. 




## Läsning av [@Huberty1980]

Behandlar just multiple correlation och $R^2$! Dock främst en jämförelse mellan sedan tidigare kända formler såsom [@Ezekei1929] och [@Olkin1958].

Nämner att för $\rho = 0$ gäller:

$$E[R^2] = \frac{p}{N-1}$$

Käns som att denn artikel gör mkt av det vi vill göra. Välskriven och pedagogisk. Tillämpas på verklig fata (ej simulerat).

Man skiljer på modeller för att förstå samband eller för predektion på sätt som jag inte riktigt sett tidigare.

**OBS!** Här noteras också (vilket jag själv tidiagre också nämnt) att [@Ezekei1929] först använde $N$ där han senare använde $N - 1$.

Nämner jack-knife som alternativ till adjusted $R^2$.

Använder lånade data set med betyg och olika elevdata som predektorer. Två dataset varav första med $p = 9$.

Stickprovsstorlek på 50.

SKriver att om $N/p>20$ så kan "shrinkage" negligeras.

Endast tio upprepade försök per stickprovsstorlek. 

Tra olika $\rho^2$, samtliga mellan 0,3 och 0,4.  

Från dessa stickprov mättes:

* precision via standardavvikelse av avvikelse mellan $\rho^2$ och $\hat{rho}$.
* accuracy via dess medelvärde.

Slutsatser: [@Ezekei1929] och [@Olkin1958] hyfsat lika resultat.
Mer bias för högre $p$. Biasen var väldigt liten (notera n = 50) och saknade signifikant avvikelse från 0. Alla adjusted $R^2$ kan bedömas likvärdiga.

Noterar att adjusted $R^2$ kan bli negativt men att detta motsvarar en riktigt dålig passning (väldigt litet $R^2$ och $n$).




## Läsning av [@Wood1986]

Kritiserar generaliseringen att kvadrera $\rho$ beräknat för korrelation för att få ett värde som motsvarar $R^2$ vid regression. Säger alltså inte emot att coefficient of determination beräknas så men menar att man inte kan alltid kan tolka $\rho^2$ som sådan koefficient ifall det inte var syftet från början. Detta eftersom korrelation baseras på stokastiskt X medan regression baseras på fixt X.Hänvisar också til [@Warren1971] ang detta.

Wood kallar dessa felaktiga resonemang för "vulgarised knowledge".

> "bias (for correlation) and precision (for regression) tend to work against each other. One should determine which of correlation or regression is appropriate to the problem and select the sampling method accordingly 

Hela artikeln känns polemisk och lite "von oben" men kommunicerar å andra sidan ganska klart sin ståndpunkt.

Argumenterar också för att korrelationsvärden inte ska tillmätas alltför stort värde rakt av utan att man måste undersöka hela fördelningen grafiskt. Detta kan förstås vara svårt vid publicering men det bör åtm ske i explorativt syfte. 



## Läsning av [@Hawkins1989]

Väldigt kort. Handlar om Fisher z. Teoretisk, många formler. Kopierar abstract:

> A simple derivation of the asymptotic distribution of Fish- er's Z statistic for general bivariate parent distributions F is obtained using U-statistic theory. This method easily reveals that the asymptotic variance of Z generally depends on the correlation $\rho$ and on certain moments of F. It also reveals the particular structure of F that makes the asymptotic variance of Z independent of $\rho$, and shows that there are many distributions F with this property. The bivariate normal is only one such F.

Refererar till [@Gayen1951] som visade samma sak men då endast för Edgeworth-fördelningar. 
Detta bevis gäller alla fördelningar med ändligt fjärdemoment (kurtosis) men bara approximativt då $n \rightarrow \infty$




## Läsning av [@Nagelkerke1991]

Kort. 2 sidor och fgå referenser. Teoretisk.

Tar här för givet att coefficient of determination = multiple correlation coefficient.

Beskriver generalisering som kan användas utanför linjär regression. Baseras på maximum likelihood. Har egentligen introducerats redan tidigare av bl a Cox et al. Beskriver många fina egenskaper men också ett problem som dock går att överkomma. 



# Referenser
