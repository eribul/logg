\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\PassOptionsToPackage{usenames,dvipsnames}{color} % color is loaded by hyperref
\hypersetup{unicode=true,
            pdftitle={Arbetslogg 2016 vecka 11},
            pdfauthor={Erik Bulow},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\ImportTok}[1]{{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{{#1}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{{#1}}}}
\newcommand{\BuiltInTok}[1]{{#1}}
\newcommand{\ExtensionTok}[1]{{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{Arbetslogg 2016 vecka 11}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \author{Erik Bulow}
  \preauthor{\centering\large\emph}
  \postauthor{\par}
  \predate{\centering\large\emph}
  \postdate{\par}
  \date{14 mars 2016}



% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\begin{document}
\maketitle

{
\setcounter{tocdepth}{2}
\tableofcontents
}
\section{Förberedelser}\label{forberedelser}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Try it out!}
\KeywordTok{memory.limit}\NormalTok{(}\DecValTok{50000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 50000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{options}\NormalTok{(}\DataTypeTok{samplemetric.log =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{2016-03-21}\label{section}

\subsection{Läsning av (Algina and Moulder
2001)}\label{lasning-av-algina2001}

Om stickprovsstorlek för KI för multipel korr coeff. Avser KI för
dskillnad i \(R^3\), dvs \(\Delta R^2\) mellan olika modeller vid
tillägg av ytterligare kovariat. Om man lägger till kovariat \(X_i\)
kallas \(\Delta R^2\) squared semipartial correla- tion coefficient for
\(X_j\).

Skriver att det under de senaste åren blivit allt vanligare att
tidksrifter inom beh science kräver rapportering av effekt sizes och
ibland även KI av dessa. Radar upp ett par tidsskrifter som infört
sådana krav. Nämner äv en task force 1999 med dessa rekommendationer.
Lägger ännu inte in off referens men finns här:

\begin{quote}
Wilkinson, L., \& APA Task Force on Statistical Inference. (1999).
Statistical methods in psy- chology journals. American Psychologist, 54,
594-604.
\end{quote}

Simuleringsstudier med olika \(k, n, \rho^2_r, \rho^2_f\) där
\(\rho^2_r\) för reduced model, dvs model utsan \(X_i\) enl ovan och
\(\rho^2_f\) för den fulla modellen inkl denna. Endast multivariat
normalfördelad data. Totalt 10143 paramterkombinationer. Rättfärdigar
stickprovsstorlek gm referens. Varje kombination upprepas 50000 ggr. 95
\% KI skapades vid varje rep. Ref till artikel som ger gränser för att
utvärdera om en skattad nivå är hög eller inte etc.

\textbf{OBS!} Förklarar ocskå varför det räcker att slumpa data där
varje variabel har varians = 1 då detta lätt kan generaliseras. Kanske
kan vara bra att refera till. Förklarar också på ganska bra sätt hur
kovariansmatrisen och dess element konstrueras.

Skattningen av KI tar ej hänsyn till att underliggande fördelning skev,
vilket ger visst fel. Dessutom blir det lite för brett.

Med stickprovsstorlekar under 600 kommer skapat KI inte upp till en
konfidensgrad på 0.95 även om så är avsikten. För n \textgreater{} 600
blir det bättre men fortfarande långt ifrån bra. KI ger ofta
underskattning av verkligt resultat. OBS! Detta gäller om man vill hitta
ngn gemensam gräns som funkar i de flesta situationer. Då t ex
differensen är större krävs mindre stickprov fär att upptäcka detta.
Artikeln innehåller omfattande tabeller som ger olika värden för olika
parameterkombinationer.

Bekräftar också det vanliga att större p (här k) kräver större n.

\subsection{Läsning av (Zimmerman, Zumbo, and Williams
2003)}\label{lasning-av-zimmerman2003}

Handlar om \(r\), ej \(R^2\).

Undersöker bias samt korrektionsformler. Simuleringar. Testar med
Olkin-Pratt etc och även fisher Z.

Anger att redan (Fisher 1915) fann att
\(E[r] = \rho- \frac{\rho(1-\rho^2)}{2n}\) och därpå föreslåg en
unbiased korrektions-formel:
\(\hat{\rho} = r\left[ 1 + \frac{1-r^2}{2n}\right]\). Denna kallas
``Fisher approximate unbiased estimator''. Sedan kom (Olkin and Pratt
1958) med \[\hat{\rho} = r\left[ 1 + \frac{1-r^2}{2(n-3}\right]\]. Dessa
formler leder till (dirivera etc) att största bias (oberoende av n)
uppnås för \(\rho = \pm .577\) (vars magnitud i sin tur avgörs av
\(n\)). Poängterar att Fishers z introducerades först med tanke på
skattningens varians, inte mean. Poängterar att medan an ofta finner
Fishers Z på formen:

\[Z = \frac{1}{2}\ln[\left[\frac{1+r}{1-r}\right]\] anges formeln åt
andra hållet: \[r = \frac{e^Z - e^{-Z}}{e^Z + e^{-Z}}\] mer sällan
(trots att denna används föfr att bl a skapa konfidensintervall etc).

Ger också förhållandet mellan Perasons och Spearmans
korrelationskoefficienter samt anger att det även föreslagits att även
Spearmans koef transformeras mha Fishers Z. Även mha ytterligare utv
formel. Undersöker även då data inte bivariat normalfördelad. Finner bl
a att Fishers Z inte är robust och ger felaktigt resultat för icke
normalfördelad data.

Slutsats att korrekation bör tillämpas för små stickprov eftersom
resultatet annars kan bli missledande. Dock marginellt problem åtm då
stickprov stort.

\begin{quote}
These consequences {[}bias av \(r\){]} appear to be more severe than
ones typically associated with non-normality in t and F tests of
differences in location.
\end{quote}

\subsection{Läsning av (Shieh 2008)}\label{lasning-av-shieh2008}

Av abstract att döma ytterligare en valideringsstudie som jmför olika
metoder för bias-justering. Även denne med slutsats att Pratt bäst.

Antar N-data.

Föreslår modifierade versioner av bef adjusted values via
\(\max(0, \hat{rho}^2)\) och betecknar dessa med ett plus, t ex
\(\rho^{2+}_X\) där X anger villken justeringsformel som används. Jag
implementerar nu dessai i R-funktionen \texttt{adjusted\_r2} via
argument \texttt{min0}.

Ger också approximation till \$f(R\^{}2)) via ordinal (cenrtal)
betafördelning.

Utvärderar de olika justeringsformlerna och kommer fram till att (Olkin
and Pratt 1958) bäst och bättre ju fler termer som ingår innan den
oändliga summan trunkeras. Dock är Pratts formel också nästan lika bra.
Dessa båda är bättre än \(\hat{\rho}_{ML}^2\) enl (Alf and Graf 2002).

Att Pratt var bättre enl (Yin and Fan 2001) motiveras med att den byggde
på slumpad data medan denna artikel bygger på jämförelser av teoretiska
fördelningar, vilket bör vara mer exakt.

De modifierade versionerna som ger enbart tal \(\geq 0\) ger mer bias än
enl ursprungliga formler. Största skillnader för små \(\rho\). Dock syns
inga sådana skillnader om man istf bias jmfr MSE.

Rekommendationen blir efter sammanvägning av minsta bias/MSE och
beräkningssvårighet att använda \(\hat{\rho}^{2+}_P\), dvs positvt
korrigerade enl Pratt!!!

Nämner själva att det skulle vara önskvärt undersöka detta även för icke
normalfördelad data!!!

\section{2016-03-22}\label{section-1}

\begin{itemize}
\tightlist
\item
  Utforskar nya markdown-format etc och testar dessa i Teds ryggstudie.
\item
  Blir inrtoducerad till nytt projekt avseende adverse events av
  Szilard. Startar eget projekt och därmed egen arbetslogg för det
  arbetet.
\end{itemize}

\subsection{\texorpdfstring{Läsning av ``Winning the publication
game''}{Läsning av Winning the publication game}}\label{lasning-av-winning-the-publication-game}

Rekommenderar att man skapar tankekarta utifrån fyra
huvudgrenarna/frågorna:

\begin{itemize}
\tightlist
\item
  Why did we start?
\item
  What did we do?
\item
  What did we found?
\item
  What does it all mean?
\end{itemize}

Empiriskt har det visat5 sig att artiklar tenderar ha följande antal
stycken per avsnott:

\begin{longtable}[c]{@{}ll@{}}
\toprule
Avsnitt & \# stycken\tabularnewline
\midrule
\endhead
Intro & 2\tabularnewline
Metod & 7\tabularnewline
Resultat & 7\tabularnewline
Diskussion & 6\tabularnewline
\bottomrule
\end{longtable}

s 44 ff ger bra konkreta råd till vad de olika delarna bör innehålla och
hur detta kan struktureras. Fyra meningar är viktigast och de kan flöja
ett ganska fast mönster:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Första i intro: What we looked at
\item
  Sista i intro: What we did
\item
  Första i diskussion: What we found
\item
  Sistai diskussion: what it means - THE MESSAGE!
\end{enumerate}

Se fig 5.6.

Innehåller konkret uppställning över hela artikelns föreslagna upplägg.

\section{2016-03-23}\label{section-2}

Fortsatte läsa bok enl ovan.

\subsection{Läsning av (Alf and Graf 2002)}\label{lasning-av-alf2002}

Föreslår en ny ML-skattning av \(R^2\). Har dock visats enl (Shieh 2008)
att denna inte kan ersätta t ex Pratt etc.

Utgår från fördelningsfunktion enl (Fisher 1928) och använder Excel.

Poängterar att \(R^^2\) inte är en ML-skattning av \(\rho^2\), vilket
däremot den nu konstruerade \(\hat{\rho}^2_{(ML)}\) är.

Skriver att (Ezekiel and Mordecai 1929) var unbiased enbart för
\(\rho^2=0\) medan medan (Olkin and Pratt 1958) alltid unbiased.

Väljher medvetet att visa just den situation för vilken den egna
skattningen är den bästa.

Skattningen är biased men faller inom parameterrummet (dvs ger inga
negativa tal).

Utgår återigen från multivariat N-data. ANväder exempaldata från betyg
inom luftvapnet (data som tycks återkomma, exempelvis från (Raju et al.
1999)).

Nämner också att resultat frpån just (Raju et al. 1999) visade att
skattningarna är ganska robusta, dvs funkar även om dtat skevt etc.
Poängterar dock att det endast rör ett exempel och att man borde
utvärdera fler ggr med lite olika förutsättningar etc.

Själva artikeln helt deskriptiv. Alla formler etc i appendix.

Artikeln känns på det hela taget lite oklar och tror i övrigt inte vi
behöver tillmäta den alltför stort intresse (inledningen är dock
åedagogiskt skriven).

\subsection{Läsning av (Barbiero and Ferrari
2016)}\label{lasning-av-barbiero2016}

Beskriver R-paket för simulering av diskret korrelerad data, vilket jag
tänker kan vara relevant för egna simuleringar. OBS! Helt nytt! Står att
manuskriptet accepterats men osäkert om det publicerats annat än
elektroniskt etc?

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(GenOrd)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: mvtnorm
\end{verbatim}

\begin{verbatim}
## Loading required package: Matrix
\end{verbatim}

\begin{verbatim}
## Loading required package: MASS
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'MASS'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:dplyr':
## 
##     select
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p <-}\StringTok{ }\DecValTok{5}
\NormalTok{r2 <-}\StringTok{ }\FloatTok{0.2}
\NormalTok{n <-}\StringTok{ }\DecValTok{1000}

\NormalTok{cumprob <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.75}\NormalTok{)}
\NormalTok{marginal <-}\StringTok{ }\KeywordTok{replicate}\NormalTok{(p +}\StringTok{ }\DecValTok{1}\NormalTok{, cumprob, }\DataTypeTok{simplify =} \OtherTok{FALSE}\NormalTok{)}
\KeywordTok{corrcheck}\NormalTok{(marginal) }\CommentTok{# check ok}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## 6 x 6 Matrix of class "dsyMatrix"
##      [,1] [,2] [,3] [,4] [,5] [,6]
## [1,]    1   -1   -1   -1   -1   -1
## [2,]   -1    1   -1   -1   -1   -1
## [3,]   -1   -1    1   -1   -1   -1
## [4,]   -1   -1   -1    1   -1   -1
## [5,]   -1   -1   -1   -1    1   -1
## [6,]   -1   -1   -1   -1   -1    1
## 
## [[2]]
## 6 x 6 Matrix of class "dsyMatrix"
##      [,1] [,2] [,3] [,4] [,5] [,6]
## [1,]    1    1    1    1    1    1
## [2,]    1    1    1    1    1    1
## [3,]    1    1    1    1    1    1
## [4,]    1    1    1    1    1    1
## [5,]    1    1    1    1    1    1
## [6,]    1    1    1    1    1    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Sigma <-}\StringTok{ }\KeywordTok{diag}\NormalTok{(p +}\StringTok{ }\DecValTok{1}\NormalTok{)}
\NormalTok{Sigma[}\DecValTok{1}\NormalTok{, -}\DecValTok{1}\NormalTok{] <-}\StringTok{ }\NormalTok{Sigma[-}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{] <-}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(r2 /}\StringTok{ }\NormalTok{p)}
\CommentTok{# generate a sample of size n}
\NormalTok{m <-}\StringTok{ }\KeywordTok{ordsample}\NormalTok{(n, marginal, Sigma)}
\NormalTok{m <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(m)}
\KeywordTok{summary}\NormalTok{(}\KeywordTok{lm}\NormalTok{(V1 ~}\StringTok{ }\NormalTok{., m))$r.squared}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1997067
\end{verbatim}

Jag testar att inkludera detta som del i \texttt{sim\_data}-funktionen i
paketet.

Själva artikeln är längre än vad jag ordkar läsa men paketet i sig tycks
bra!

\section*{Referenser}\label{referenser}
\addcontentsline{toc}{section}{Referenser}

\hypertarget{refs}{}
\hypertarget{ref-Alf2002}{}
Alf, E. F., and R. G. Graf. 2002. ``A New Maximum Likelihood Estimator
for the Population Squared Multiple Correlation.'' \emph{Journal of
Educational and Behavioral Statistics} 27 (3): 223--35.
doi:\href{https://doi.org/10.3102/10769986027003223}{10.3102/10769986027003223}.

\hypertarget{ref-Algina2001}{}
Algina, J., and B. C. Moulder. 2001. ``Sample Sizes for Confidence
Intervals on the Increase in the Squared Multiple Correlation
Coefficient.'' \emph{Educational and Psychological Measurement} 61 (4):
633--49.
doi:\href{https://doi.org/10.1177/00131640121971400}{10.1177/00131640121971400}.

\hypertarget{ref-Barbiero2016}{}
Barbiero, Alessandro, and Pier Alda Ferrari. 2016. ``An R Package for
the Simulation of Correlated Discrete Variables.'' \emph{Communications
in Statistics - Simulation and Computation} 0918 (March): 0--0.
doi:\href{https://doi.org/10.1080/03610918.2016.1146758}{10.1080/03610918.2016.1146758}.

\hypertarget{ref-Ezekiel1929}{}
Ezekiel, and Mordecai. 1929. ``The Application of the Theory of Error to
Multiple and Curvilinear Correlation.'' \emph{Journal of the American
Statistical Association} 24 (165): 99--104.

\hypertarget{ref-Fisher1915}{}
Fisher, R A. 1915. ``Frequency distribution of the values of the
correlation coefficient in samples from an indefinitely large
population.'' \emph{Biometrika} 10 (4): 507--21.
doi:\href{https://doi.org/10.2307/2331838}{10.2307/2331838}.

\hypertarget{ref-Fisher1928}{}
---------. 1928. ``The General Sampling Distribution of the Multiple
Correlation Coefficient.'' \emph{Proceedings of the Royal Society of
London A: Mathematical, Physical and Engineering Sciences} 121 (788):
654--73.
\url{http://rspa.royalsocietypublishing.org/content/121/788/654.abstract}.

\hypertarget{ref-Olkin1958}{}
Olkin, Ingram, and J.W. Pratt. 1958. ``Unbiased estimation of certain
correlation coefficients.'' \emph{The Annals of Mathematical Statistics}
29 (1): 201--11.
doi:\href{https://doi.org/10.2307/2237306}{10.2307/2237306}.

\hypertarget{ref-Raju1999}{}
Raju, N S, R Bilgic, J E Edwards, and P F Fleer. 1999. ``Accuracy of
Population Validity and Cross-Validity Estimation: An Empirical
Comparison of Formula-Based, Traditional Empirical, and Equal Weights
Procedures.'' \emph{Applied Psychological Measurement} 23 (2): 99--115.
doi:\href{https://doi.org/10.1177/01466219922031220}{10.1177/01466219922031220}.

\hypertarget{ref-Shieh2008}{}
Shieh, Gwowen. 2008. ``Improved Shrinkage Estimation of Squared Multiple
Correlation Coefficient and Squared Cross-Validity Coefficient.''
\emph{Organizational Research Methods} 11 (2): 387--407.

\hypertarget{ref-Yin2001}{}
Yin, Ping, and Xitao Fan. 2001. ``Estimating R 2 Shrinkage in Multiple
Regression: A Comparison of Different Analytical Methods.'' \emph{The
Journal of Experimental Education} 69 (2): 203--24.
doi:\href{https://doi.org/10.1080/00220970109600656}{10.1080/00220970109600656}.

\hypertarget{ref-Zimmerman2003}{}
Zimmerman, D, B Zumbo, and R Williams. 2003. ``Bias in estimation and
hypothesis testing of correlation.'' \emph{Psicologica} 24 (24):
133--58.
\href{http://www.redalyc.org/articulo.oa?id=16924109SL\%20http://redalyc.uaemex.mx/redalyc/html/169/16924109/16924109.html$/backslash$nhttp://www.uv.es/psicologica/articulos1.03/9.ZUMBO.pdf}{http://www.redalyc.org/articulo.oa?id=16924109SL http://redalyc.uaemex.mx/redalyc/html/169/16924109/16924109.html\$\textbackslash{}backslash\$nhttp://www.uv.es/psicologica/articulos1.03/9.ZUMBO.pdf}.

\end{document}
